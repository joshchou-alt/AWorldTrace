{
  "metadata": {
    "total_successful": 1,
    "timestamp": "20250925_162047",
    "range": "0-1",
    "split": "validation"
  },
  "traces": [
    {
      "task_id": "4453d6d09a6611f09c2d9f68a1cc114c",
      "task_input": "A paper about AI regulation that was originally submitted to arXiv.org in June 2022 shows a figure with three axes, where each axis has a label word at both ends. Which of these words is used to describe a type of society in a Physics and Society article submitted to arXiv.org on August 11, 2016?",
      "success": true,
      "result": "From the Physics and Society article submitted to arXiv.org on August 11, 2016 (\"Phase transition from egalitarian to hierarchical societies driven by competition between cognitive and social constraints\"), the text repeatedly refers to \"egalitarian\" and \"hierarchical\" as types of societies. Specifically, the article discusses transitions between \"egalitarian\" and \"hierarchical\" societies, and the term \"egalitarian\" is used to describe a type of society.\n\nAmong the six axis-end label words from the June 2022 AI regulation paper:\n- Standardization\n- Localization\n- Utilitarianism\n- Egalitarianism\n- Consequential\n- Deontological\n\nThe word \"egalitarian\" (from \"egalitarianism\") is used in the 2016 Physics and Society article to describe a type of society.\n\n---\n\n**Final Answer:**\n\n<answer>egalitarian</answer>",
      "agent_traces": [
        {
          "agent_id": "gaia_tracing_agent---uuid4453c8uuid",
          "observation": "A paper about AI regulation that was originally submitted to arXiv.org in June 2022 shows a figure with three axes, where each axis has a label word at both ends. Which of these words is used to describe a type of society in a Physics and Society article submitted to arXiv.org on August 11, 2016?",
          "info": {},
          "timestamp": "2025-09-25T16:20:49.431034",
          "success": true,
          "result": [
            {
              "tool_name": "mcp",
              "tool_call_id": "call_lFoCmx682QAbvSxmf0jwyh2U",
              "agent_name": "gaia_tracing_agent---uuid4453c8uuid",
              "action_name": "search__mcp_search_google",
              "params": {
                "query": "arxiv AI regulation June 2022",
                "num_results": 5,
                "safe_search": true,
                "language": "en",
                "output_format": "json"
              },
              "policy_info": "### Task Analysis\n\nLet's break down the task:\n\n1. **Identify the AI regulation paper on arXiv.org submitted in June 2022**  \n   - Find a paper about AI regulation, submitted to arXiv in June 2022, that contains a figure with three axes, each labeled with a word at both ends.\n\n2. **Extract the six axis-end label words from the figure in that paper.**\n\n3. **Check which of these words is used to describe a type of society in a Physics and Society article submitted to arXiv.org on August 11, 2016.**\n   - Find the relevant Physics and Society article from that date.\n   - Identify the words used to describe types of society in that article.\n   - Find the intersection with the six axis-end label words.\n\n### Step-by-Step Plan\n\n1. Search for the AI regulation paper on arXiv.org submitted in June 2022.\n2. Locate the figure with three axes and extract the six label words.\n3. Search for the Physics and Society article submitted on August 11, 2016.\n4. Identify the words used to describe types of society in that article.\n5. Find which of the six axis-end label words is also used in the 2016 article to describe a type of society.\n\n---\n\n#### Step 1: Search for the AI regulation paper on arXiv.org submitted in June 2022\n\nLet's search for AI regulation papers on arXiv from June 2022."
            }
          ],
          "trace_data": {
            "execution_tree": {
              "code": "root",
              "contains_llm_call": true,
              "is_completed": false,
              "is_function_call": false,
              "function_name": null,
              "line_number_start": null,
              "line_number_end": null,
              "children": [
                {
                  "code": "result = Runners.sync_run_task(task=task)",
                  "contains_llm_call": true,
                  "is_completed": false,
                  "is_function_call": true,
                  "function_name": "sync_run_task",
                  "line_number_start": 1,
                  "line_number_end": 1,
                  "children": [
                    {
                      "code": "sync_run_task_execution_block",
                      "contains_llm_call": true,
                      "is_completed": false,
                      "is_function_call": false,
                      "function_name": "sync_run_task",
                      "line_number_start": 59,
                      "line_number_end": 60,
                      "children": []
                    }
                  ]
                }
              ]
            },
            "llm_calls": [
              {
                "function_name": "sync_run_task",
                "code": "result = Runners.sync_run_task(task=task)",
                "line_number": 1
              }
            ],
            "execution_flow": []
          }
        },
        {
          "agent_id": "gaia_tracing_agent---uuid4453c8uuid",
          "observation": "[\"{\\n  \\\"success\\\": true,\\n  \\\"message\\\": {\\n    \\\"query\\\": \\\"arxiv AI regulation June 2022\\\",\\n    \\\"results\\\": [\\n      {\\n        \\\"id\\\": \\\"google-0\\\",\\n        \\\"title\\\": \\\"Fairness in Agreement With European Values: An Interdisciplinary ...\\\",\\n        \\\"url\\\": \\\"https://arxiv.org/pdf/2207.01510\\\",\\n        \\\"snippet\\\": \\\"arXiv:2207.01510v1 [cs.CY] 8 Jun 2022. Page ... technical requirements to deal with bias that would be introduced with the AI Regulation Proposal. 3.1 Non- ...\\\",\\n        \\\"source\\\": \\\"google\\\",\\n        \\\"display_link\\\": \\\"arxiv.org\\\",\\n        \\\"formatted_url\\\": \\\"https://arxiv.org/pdf/2207.01510\\\"\\n      },\\n      {\\n        \\\"id\\\": \\\"google-1\\\",\\n        \\\"title\\\": \\\"(PDF) Fairness in Agreement With European Values: An ...\\\",\\n        \\\"url\\\": \\\"https://www.researchgate.net/publication/361765355_Fairness_in_Agreement_With_European_Values_An_Interdisciplinary_Perspective_on_AI_Regulation\\\",\\n        \\\"snippet\\\": \\\"Jul 5, 2022 ... Fairness in Agreement With European Values: An Interdisciplinary Perspective on AI Regulation. June 2022. DOI:10.48550/arXiv.2207.01510.\\\",\\n        \\\"source\\\": \\\"google\\\",\\n        \\\"display_link\\\": \\\"www.researchgate.net\\\",\\n        \\\"formatted_url\\\": \\\"https://www.researchgate.net/.../361765355_Fairness_in_Agreement_With_...\\\"\\n      },\\n      {\\n        \\\"id\\\": \\\"google-2\\\",\\n        \\\"title\\\": \\\"Frontier AI Regulation: Managing Emerging Risks to Public Safety\\\",\\n        \\\"url\\\": \\\"https://arxiv.org/pdf/2307.03718\\\",\\n        \\\"snippet\\\": \\\"Nov 7, 2023 ... arXiv: 2209.00626 [cs.AI]. [18] Michael K. Cohen, Marcus Hutter, and ... June 2022. URL: https://perma.cc/4XWP-NWK7. [146] Amazon AWS ...\\\",\\n        \\\"source\\\": \\\"google\\\",\\n        \\\"display_link\\\": \\\"arxiv.org\\\",\\n        \\\"formatted_url\\\": \\\"https://arxiv.org/pdf/2307.03718\\\"\\n      },\\n      {\\n        \\\"id\\\": \\\"google-3\\\",\\n        \\\"title\\\": \\\"Oversight for Frontier AI through a Know-Your-Customer Scheme for ...\\\",\\n        \\\"url\\\": \\\"https://cdn.governance.ai/Oversight_for_Frontier_AI_through_a_KYC_Scheme_for_Compute_Providers.pdf\\\",\\n        \\\"snippet\\\": \\\"Oct 20, 2023 ... On 16 June 2022, Canada introduced the Artificial Intelligence and ... “EU AI Act: first regulation on artificial intelligence,” June 2023.\\\",\\n        \\\"source\\\": \\\"google\\\",\\n        \\\"display_link\\\": \\\"cdn.governance.ai\\\",\\n        \\\"formatted_url\\\": \\\"https://cdn.governance.ai/Oversight_for_Frontier_AI_through_a_KYC_Sch...\\\"\\n      },\\n      {\\n        \\\"id\\\": \\\"google-4\\\",\\n        \\\"title\\\": \\\"Responsible Artificial Intelligence--from Principles to Practice\\\",\\n        \\\"url\\\": \\\"https://arxiv.org/pdf/2205.10785\\\",\\n        \\\"snippet\\\": \\\"May 22, 2022 ... arXiv:2205.10785v1 [cs.CY] 22 May 2022. PAPER. Responsible Artificial Intelligence – from. Principles to Practice. Virginia ... 1 June 2022.\\\",\\n        \\\"source\\\": \\\"google\\\",\\n        \\\"display_link\\\": \\\"arxiv.org\\\",\\n        \\\"formatted_url\\\": \\\"https://arxiv.org/pdf/2205.10785\\\"\\n      }\\n    ],\\n    \\\"count\\\": 5\\n  },\\n  \\\"metadata\\\": {\\n    \\\"query\\\": \\\"arxiv AI regulation June 2022\\\",\\n    \\\"search_engine\\\": \\\"google\\\",\\n    \\\"total_results\\\": 5,\\n    \\\"search_time\\\": 0.6970460414886475,\\n    \\\"language\\\": \\\"en\\\",\\n    \\\"country\\\": \\\"us\\\",\\n    \\\"safe_search\\\": true,\\n    \\\"error_type\\\": null,\\n    \\\"api_quota_used\\\": true\\n  }\\n}\"]",
          "info": {},
          "timestamp": "2025-09-25T16:21:21.736559",
          "success": true,
          "result": [
            {
              "tool_name": "mcp",
              "tool_call_id": "call_aJhmYHWrCyEiXAZYibVGg5jK",
              "agent_name": "gaia_tracing_agent---uuid4453c8uuid",
              "action_name": "pdf__mcp_extract_document_content",
              "params": {
                "file_path": "https://arxiv.org/pdf/2207.01510",
                "output_format": "markdown"
              },
              "policy_info": "The most likely candidate for the AI regulation paper submitted to arXiv in June 2022 is:\n\n- **\"Fairness in Agreement With European Values: An Interdisciplinary Perspective on AI Regulation\"**  \n  - arXiv:2207.01510v1 [cs.CY] 8 Jun 2022  \n  - [arXiv PDF link](https://arxiv.org/pdf/2207.01510)\n\n### Next Step\n\nI will extract the figure with three axes from this paper and identify the six axis-end label words.\n\nProceeding to extract the relevant content from the paper."
            }
          ],
          "trace_data": {
            "execution_tree": {
              "code": "root",
              "contains_llm_call": true,
              "is_completed": false,
              "is_function_call": false,
              "function_name": null,
              "line_number_start": null,
              "line_number_end": null,
              "children": [
                {
                  "code": "result = Runners.sync_run_task(task=task)",
                  "contains_llm_call": true,
                  "is_completed": false,
                  "is_function_call": true,
                  "function_name": "sync_run_task",
                  "line_number_start": 1,
                  "line_number_end": 1,
                  "children": [
                    {
                      "code": "sync_run_task_execution_block",
                      "contains_llm_call": true,
                      "is_completed": false,
                      "is_function_call": false,
                      "function_name": "sync_run_task",
                      "line_number_start": 59,
                      "line_number_end": 60,
                      "children": []
                    }
                  ]
                }
              ]
            },
            "llm_calls": [
              {
                "function_name": "sync_run_task",
                "code": "result = Runners.sync_run_task(task=task)",
                "line_number": 1
              }
            ],
            "execution_flow": []
          }
        },
        {
          "agent_id": "gaia_tracing_agent---uuid4453c8uuid",
          "observation": "[\"{\\n  \\\"success\\\": false,\\n  \\\"message\\\": \\\"File not found: File not found: /Users/joshchou/https:/arxiv.org/pdf/2207.01510\\\",\\n  \\\"metadata\\\": {\\n    \\\"error_type\\\": \\\"file_not_found\\\"\\n  }\\n}\"]",
          "info": {},
          "timestamp": "2025-09-25T16:21:32.511712",
          "success": true,
          "result": [
            {
              "tool_name": "mcp",
              "tool_call_id": "call_RraRIT4WVL3QjsGJ3Ty1tMl4",
              "agent_name": "gaia_tracing_agent---uuid4453c8uuid",
              "action_name": "download__mcp_download_file",
              "params": {
                "url": "https://arxiv.org/pdf/2207.01510",
                "output_file_path": "2207.01510.pdf",
                "overwrite": true,
                "timeout": 60,
                "output_format": "json"
              },
              "policy_info": "I cannot directly extract content from the arXiv PDF link without downloading it first. \n\n### Next Step\n\nI will download the PDF file of \"Fairness in Agreement With European Values: An Interdisciplinary Perspective on AI Regulation\" and then extract the content to find the figure with three axes and their label words."
            }
          ],
          "trace_data": {
            "execution_tree": {
              "code": "root",
              "contains_llm_call": true,
              "is_completed": false,
              "is_function_call": false,
              "function_name": null,
              "line_number_start": null,
              "line_number_end": null,
              "children": [
                {
                  "code": "result = Runners.sync_run_task(task=task)",
                  "contains_llm_call": true,
                  "is_completed": false,
                  "is_function_call": true,
                  "function_name": "sync_run_task",
                  "line_number_start": 1,
                  "line_number_end": 1,
                  "children": [
                    {
                      "code": "sync_run_task_execution_block",
                      "contains_llm_call": true,
                      "is_completed": false,
                      "is_function_call": false,
                      "function_name": "sync_run_task",
                      "line_number_start": 59,
                      "line_number_end": 60,
                      "children": []
                    }
                  ]
                }
              ]
            },
            "llm_calls": [
              {
                "function_name": "sync_run_task",
                "code": "result = Runners.sync_run_task(task=task)",
                "line_number": 1
              }
            ],
            "execution_flow": []
          }
        },
        {
          "agent_id": "gaia_tracing_agent---uuid4453c8uuid",
          "observation": "[\"{\\n  \\\"success\\\": true,\\n  \\\"message\\\": \\\"{\\\\n  \\\\\\\"url\\\\\\\": \\\\\\\"https://arxiv.org/pdf/2207.01510\\\\\\\",\\\\n  \\\\\\\"file_path\\\\\\\": \\\\\\\"/Users/joshchou/2207.01510.pdf\\\\\\\",\\\\n  \\\\\\\"success\\\\\\\": true,\\\\n  \\\\\\\"file_size\\\\\\\": 579519,\\\\n  \\\\\\\"duration\\\\\\\": \\\\\\\"0:00:00.139836\\\\\\\",\\\\n  \\\\\\\"timestamp\\\\\\\": \\\\\\\"2025-09-25T16:21:38.211191\\\\\\\",\\\\n  \\\\\\\"error_message\\\\\\\": null\\\\n}\\\",\\n  \\\"metadata\\\": {\\n    \\\"url\\\": \\\"https://arxiv.org/pdf/2207.01510\\\",\\n    \\\"output_path\\\": \\\"/Users/joshchou/2207.01510.pdf\\\",\\n    \\\"timeout_seconds\\\": 60,\\n    \\\"overwrite_enabled\\\": true,\\n    \\\"execution_time\\\": 0.1403048038482666,\\n    \\\"file_size_bytes\\\": 579519,\\n    \\\"content_type\\\": null,\\n    \\\"status_code\\\": null,\\n    \\\"error_type\\\": null,\\n    \\\"headers_used\\\": true\\n  }\\n}\"]",
          "info": {},
          "timestamp": "2025-09-25T16:21:39.750167",
          "success": true,
          "result": [
            {
              "tool_name": "mcp",
              "tool_call_id": "call_Ew19391cfDk4dvqEPJiAICwB",
              "agent_name": "gaia_tracing_agent---uuid4453c8uuid",
              "action_name": "pdf__mcp_extract_document_content",
              "params": {
                "file_path": "2207.01510.pdf",
                "output_format": "markdown"
              },
              "policy_info": ""
            }
          ],
          "trace_data": {
            "execution_tree": {
              "code": "root",
              "contains_llm_call": true,
              "is_completed": false,
              "is_function_call": false,
              "function_name": null,
              "line_number_start": null,
              "line_number_end": null,
              "children": [
                {
                  "code": "result = Runners.sync_run_task(task=task)",
                  "contains_llm_call": true,
                  "is_completed": false,
                  "is_function_call": true,
                  "function_name": "sync_run_task",
                  "line_number_start": 1,
                  "line_number_end": 1,
                  "children": [
                    {
                      "code": "sync_run_task_execution_block",
                      "contains_llm_call": true,
                      "is_completed": false,
                      "is_function_call": false,
                      "function_name": "sync_run_task",
                      "line_number_start": 59,
                      "line_number_end": 60,
                      "children": []
                    }
                  ]
                }
              ]
            },
            "llm_calls": [
              {
                "function_name": "sync_run_task",
                "code": "result = Runners.sync_run_task(task=task)",
                "line_number": 1
              }
            ],
            "execution_flow": []
          }
        },
        {
          "agent_id": "gaia_tracing_agent---uuid4453c8uuid",
          "observation": "[\"{\\n  \\\"success\\\": true,\\n  \\\"message\\\": \\\"# Fairness in Agreement With European Values: An Interdisciplinary Perspective on AI Regulation\\\\n\\\\nAlejandra Bringas Colmenarejo<sup>1</sup> , Luca Nannini<sup>2</sup> , Alisa Rieger<sup>3</sup> , Kristen M. Scott<sup>4</sup> , Xuan Zhao<sup>5</sup> , Gourab K. Patro<sup>6</sup> , Gjergji Kasneci<sup>7</sup> , and Katharina Kinder-Kurlanda<sup>8</sup>\\\\n\\\\nUniversity of Southampton, United Kingdom Minsait - Indra Sistemas and CiTIUS, Universidade de Santiago de Compostela, Spain Delft University of Technology, Netherlands KU Leuven, Belgium SCHUFA Holding AG and University of Tuebingen, Germany 6 IIT Kharagpur, India and L3S Research Center, Germany SCHUFA Holding AG and University of Tuebingen, Germany Digital Age Research Center, University of Klagenfurt, Austria\\\\n\\\\nJuly 5, 2022\\\\n\\\\n#### Abstract\\\\n\\\\nWith increasing digitalization, Artificial Intelligence (AI) is becoming ubiquitous. AI-based systems to identify, optimize, automate, and scale solutions to complex economic and societal problems are being proposed and implemented. This has motivated regulation efforts, including the Proposal of an EU AI Act. This interdisciplinary position paper considers various concerns surrounding fairness and discrimination in AI, and discusses how AI regulations address them, focusing on (but not limited to) the Proposal. We first look at AI and fairness through the lenses of law, (AI) industry, sociotechnology, and (moral) philosophy, and present various perspectives. Then, we map these perspectives along three axes of interests: (i) Standardization vs. Localization, (ii) Utilitarianism vs. Egalitarianism, and (iii) Consequential vs. Deontological ethics which leads us to identify a pattern of common arguments and tensions between these axes. Positioning the discussion within the axes of interest and with a focus on reconciling the key tensions, we identify and propose the roles AI Regulation should take to make the endeavor of the AI Act a success in terms of AI fairness concerns.\\\\n\\\\n# 1 Introduction\\\\n\\\\nAI applications have grown at an unprecedented rate in recent years and have become ubiquitous in our society. While often deployed with the intention to increase efficiency and fairness of decisionmaking, AI has also sparked many debates on (un)fairness [\\\\\\\\[101\\\\\\\\]](#page-23-0). These debates surround, amongst others, unfair treatment of individuals and groups due to the reproduction of systemic, institutional, and societal biases in AI decisions [\\\\\\\\[14\\\\\\\\]](#page-17-0); the opacity of AI decisions [\\\\\\\\[4\\\\\\\\]](#page-16-0); diverse jeopardies to democracy and societal well-being [\\\\\\\\[74\\\\\\\\]](#page-21-0); risks to consumer privacy [\\\\\\\\[63\\\\\\\\]](#page-20-0); and market inequalities that are observed in the aggregation of unprecedented levels of power of big companies that develop AI systems (Big Tech) while small and new companies are struggling to enter the market [\\\\\\\\[100\\\\\\\\]](#page-23-1). In many fields of AI application, such as policing, justice, and recruitment, bias and unfairness as described above should not only be mitigated to increase fairness but in fact, to avert violating protected human rights.\\\\n\\\\nThe above mentioned undesired effects and consequences of AI application and development propelled the European Union for new regulations, ex-ante reviews, and ex-post monitoring on AI systems. The European Union intends to assert the AI Regulation through the protection of human dignity and fundamental rights with the Proposal of the Artificial Intelligence Act [\\\\\\\\[85\\\\\\\\]](#page-22-0), convinced that human beings should remain at the center of technological development. However, to make this endeavor of the AI Act a success, to some extent divergent interdisciplinary views and perspectives on bias, fairness, and regulation, have to be taken into consideration.\\\\n\\\\nWe elaborate on legal, industrial, sociotechnical, and philosophical perspectives in light of identified axes of tension in the debate on AI fairness and regulation: Standardization vs. Localization, Utilitarianism vs. Egalitarianism, and Consequential vs. Deontological. Further, we discuss discrepancies between how these perspectives are addressed in the current Proposal of the Artificial Intelligence Act and make recommendations how they could be addressed for better reconciliation with all three perspectives and the legal requirements. In sum, we make the following contributions to the ongoing discourse on AI fairness and regulation: i. Interdisciplinary perspectives: Comprehensive interdisciplinary (technical, legal, industrial, sociotechnical, philosophical) discussion of bias, fairness, and regulation (Sections [2](#page-1-0) to [6\\\\\\\\)](#page-9-0), ii. Mapping tensions of debate: mapping the different perspectives on fairness in AI applications and regulation on to three axes that reveal tensions in the debate: Standardization vs. Localization, Utilitarianism vs. Egalitarianism, and Consequential vs. Deontological ethics (Section [7\\\\\\\\)](#page-10-0), iii. Path forward: Recommendations towards consensus for a successful AI Act that reconciles divergent perspectives (Section [8\\\\\\\\)](#page-14-0).\\\\n\\\\n# <span id=\\\\\\\"page-1-0\\\\\\\"></span>2 Technical Frameworks for Bias and Fairness in AI\\\\n\\\\nIn this section we present examples of fairness controversies for selected AI application domains with high-stake consequences. Subsequently, we discuss several AI fairness notions and present research on guidance to choose between these notions and between measures to mitigate bias in AI systems.\\\\n\\\\n### <span id=\\\\\\\"page-1-1\\\\\\\"></span>2.1 Examples of Bias and Unfairness in AI Applications\\\\n\\\\nAutomated decision-making systems were suggested to be capable of increased fairness due to avoidance of human bias interference [\\\\\\\\[52\\\\\\\\]](#page-19-0). However, many cases have come to light in which automatic decision-making was found to raise critical issues regarding fairness, and reproduces systemic, institutional, and societal biases. Such biases can result in discrimination, unfairness, and issues of privacy, thus, violating protected human rights (see Section [3\\\\\\\\)](#page-3-0). This is especially harmful when automated decision making has high-stake implications for individuals and society. In the following, we present salient examples.\\\\n\\\\nIn Policing and Justice, AI systems are applied across Europe to inform and assist dayto-day police work by profiling people, attempting to predict likely future behavior or locations of future crimes, and assessing the alleged risk of criminal involvement of individuals (e.g., Top 600 criminals list and CAS (Netherlands), Delia (Italy), SKALA (Germany). Outcomes of these predictions and assessments are used to justify surveillance, searches, or questioning of alleged high risk individuals. However they have been suspected to reinforce existing patterns of offending and enforcement [\\\\\\\\[1,](#page-16-1) [99\\\\\\\\]](#page-23-2). In the judicial arena, automated decision-making is currently being applied in various courts around the world to support certain tasks, such as risk assessment of recidivism, as well as decisions concerning bail amounts, probation periods, and sentencing [\\\\\\\\[94,](#page-22-1) [116\\\\\\\\]](#page-24-0). Across Europe, such systems are not yet used widely, however, they have been introduced or tested in some countries, e.g., in Spain (RisCanvi) or the UK (HART). Završnik [\\\\\\\\[116\\\\\\\\]](#page-24-0) highlights potentially violated rights due to opaque, automated decision-making in the justice system, e.g., the right to a fair trial, the principle of non-discrimination and equality, and the right for explanation.\\\\n\\\\nAI systems are further being applied in the domain of Education and Employment, to support candidate selection for higher education admissions and recruitment, e.g., with CV screening, targeted job advertisement, candidate sourcing, and video screening [\\\\\\\\[2\\\\\\\\]](#page-16-2). The risk of bias has been demonstrated at each of these stages in the recruitment process [\\\\\\\\[11,](#page-16-3) [56\\\\\\\\]](#page-20-1).\\\\n\\\\nIn Finance and Banking, AI algorithms constitute the basis of numerous different applications, such as market forecasting for trading, or risk management for credit scoring, loan allocations, and mortgage rates [\\\\\\\\[15\\\\\\\\]](#page-17-1). Various cases have come to light in which decisions of such applications were found to be unfair and biased towards minority borrowers, i.e., with higher mortgage and loan rejection rates for Hispanic and Black borrowers in the US [\\\\\\\\[8,](#page-16-4) [29\\\\\\\\]](#page-18-0), or lower credit limits for women than for men with equal credit relevant characteristics [\\\\\\\\[36,](#page-18-1) [106\\\\\\\\]](#page-23-3).\\\\n\\\\nFor Online Platforms, AI based recommender systems are applied to support users to navigate the web by filtering information and suggest items (videos, social media content, products, music,..) predicted to be relevant for the user. Recommender systems were found to amplify different kinds of bias, such as representation bias with an over-representation of male, white, and young users [\\\\\\\\[96\\\\\\\\]](#page-22-2), and exposure bias where the top 20% of businesses get 80% of the exposure [\\\\\\\\[87\\\\\\\\]](#page-22-3), and marketplaces preferentially recommend their own products [\\\\\\\\[21\\\\\\\\]](#page-17-2). This amplifies substantial power imbalances between market-dominating platform incumbents (Big Tech) and smaller platforms who do not have access to equal vast amounts of high-quality consumer data that is vital to enter the market [\\\\\\\\[100\\\\\\\\]](#page-23-1). The resulting immense power concentration in the private hands of very few companies that develop most AI applications and prioritize profit over benevolence for society poses an additional threat to democracy and society [\\\\\\\\[28,](#page-18-2) [105\\\\\\\\]](#page-23-4). Further, recommender systems and search result rankings that often optimize to capture attention, determine a large extent of the information to which people are exposed. This can result in distorted exposure to information and viewpoints, as well as exposure to dis- and misinformation, raising issues of fairness and posing a threat to democracies that are reliant on well-informed citizens who can engage in healthy political and social discourse [\\\\\\\\[42,](#page-19-1) [74\\\\\\\\]](#page-21-0). AI systems could threaten democracy and society further by undermining the process of elections through targeted advertisements. Such microtargeting provides tools for interference by malicious political actors [\\\\\\\\[23,](#page-17-3) [73\\\\\\\\]](#page-21-1).\\\\n\\\\n### 2.2 Mitigating Bias and Ensuring Fairness\\\\n\\\\nMost fairness definitions consider either group or individual fairness. Group fairness is focused on requiring that people who belong to protected groups receive on average the same treatment/outcome as the overall population, expressed as the equality of a selected statistical measure across groups [\\\\\\\\[111\\\\\\\\]](#page-24-1), such as statistical parity, demographic parity, equal opportunity and equality of odds. Individual fairness focuses on ensuring that any two individuals who are similar except for the protected features receive equal or similar treatment/outcomes [\\\\\\\\[26\\\\\\\\]](#page-17-4). While ideally, multiple fairness notions would be met to reach a complete fairness status, this is impossible due to mathematical incompatibilities between them [\\\\\\\\[68\\\\\\\\]](#page-20-2). Criteria to systematize the procedure of selecting between fairness notions when making a specific decision have been proposed: Amongst others, the existence of a groundtruth, base-rates between sub-groups, the cost of misclassification, or the existence of government regulations to meet may be considered [\\\\\\\\[62\\\\\\\\]](#page-20-3).\\\\n\\\\nFormalization of fairness definitions in a specific context is nuanced and it is important that AI practitioners receive some guidance when designing a fair AI system. Some recent research proposes the Fairness Compass, a schema in form of a decision tree which simplifies the selection process by settling for the desired ethical principles in a formalised way [\\\\\\\\[98\\\\\\\\]](#page-23-5). A standardized roadmap could potentially make the identification of an appropriate fairness definition a more straightforward procedure, and help document the decision process toward fairness. Audit, monitoring and explanation might then be more accessible and less expensive. Nevertheless, there should also be space for stakeholders with deeper understanding of the specific context to contribute refinement and interpretations of any such roadmap.\\\\n\\\\nThe fairness notions mentioned above deal with the outcome of automated decision-making. Counterfactual fairness [\\\\\\\\[55\\\\\\\\]](#page-19-2) and causal fairness [\\\\\\\\[112\\\\\\\\]](#page-24-2), however, have a procedural implication which might be more suitable for the cases where a counterfactual or causal connection needs to be established between features. Most of the existing fairness notions are formalized in a static scenario. If we want to better understand how bias is encoded in historical data or evaluate the consequences of certain fairness intervention, dynamic fairness notions [\\\\\\\\[20\\\\\\\\]](#page-17-5) might offer a better solution.\\\\n\\\\nTechnical methods to mitigate bias in algorithms fall under three categories: (1) Pre-processing. Pre-processing techniques try to transform/re-balance the data so that the underlying discrimination is mitigated; (2) In-processing. The construction of objective function usually has Utilitarian motivation behind, e.g. trying to maximize the utility of whole population. In-processing methods for bias mitigation can be used either by incorporating changes into the objective function or imposing a fairness constraint; (3) Post-processing. Post-processing methods reassign the labels initially predicted by the black-box model to a fairer state. [\\\\\\\\[66\\\\\\\\]](#page-20-4).\\\\n\\\\nThe existing technical solutions toward fairness focus on more consequential approaches: the outcome/decision is evaluated by a specific fairness notion and then measures are taken to correct the unfair outcome/decision. Concerns have been voiced that fairness cannot be simply achieved through mathematical formulation approaches as the formalism trap [\\\\\\\\[103\\\\\\\\]](#page-23-6) and the seeming success of these technical solutions in the end will hinder pursuits of actual fairness with the cooperation of social practices [\\\\\\\\[39\\\\\\\\]](#page-18-3).\\\\n\\\\n# <span id=\\\\\\\"page-3-0\\\\\\\"></span>3 A Legal Perspective on Bias and Fairness in AI\\\\n\\\\nTo follow one central goal of the EU—the promotion of peace and well-being for its members— EU law aims at ensuring that EU member-states and individuals are treated and treat each other equally and fairly. The blindfolded Justicia further emphasizes the importance of laws that promote fairness, but also fairness within the enforcement of all laws. Decision-making based on machinelearning could be a promising support for that, to mitigate the unconscious or deliberate biases that we as humans have. However, being trained on (biased) data from previous decisions, the promise of unbiased assessments could not be fulfilled so far [\\\\\\\\[5,](#page-16-5) [46\\\\\\\\]](#page-19-3).\\\\n\\\\nIn this section, we will take a structured look at the legal perspective on bias and fairness in AI. We will start with an overview of EU legislative framework on non-discrimination and the approach to fairness followed by the EU Data Protection Law. Then we will conclude by addressing the technical requirements to deal with bias that would be introduced with the AI Regulation Proposal.\\\\n\\\\n### 3.1 Non-Discrimination Law\\\\n\\\\nThe general principle of non-discrimination in EU law protects people from discrimination and unfair treatment. European anti-discrimination law is designed to prevent discrimination against particular groups of people that share one or more characteristics—called protected attributes—and from which the group acquires the category of a protected group. Concretely, protected attributes under the Charter of Fundamental Rights of the European Union include sex, race or ethnic origin, colour, ethnic or social origin, genetic features, religion or other belief, disability, age, sexual orientation, political or any other opinion, language, membership to a national minority, property, social origin, and birth (Art. 21.(1)) [\\\\\\\\[82\\\\\\\\]](#page-21-2). Additionally, the Charter prohibits discrimination on the grounds of nationality, compels the European Union to ensure the equality of everyone under the European law, demands the respect of cultural, religious, and linguistic diversity, and seeks equality of men and women in all areas. Several other European anti-discrimination directives have further covered the legal protection offered to these protected attributes. Specifically, under the European Legislation men and women must receive equal treatment in the labour market and regarding the access and supply of good as services[\\\\\\\\[79,](#page-21-3) [83\\\\\\\\]](#page-21-4). Likewise, equal treatment must be guaranteed between persons irrespective of their racial or ethnic origin [\\\\\\\\[78\\\\\\\\]](#page-21-5), as well as equity shall be respected in employment and occupation in regards to the grounds of disability, religion or belief, age and sexual orientation [\\\\\\\\[77\\\\\\\\]](#page-21-6). Member States expanded the protection towards discrimination through specific national laws and provisions.\\\\n\\\\nFurthermore, the European legislation presents two tools to address discrimination, direct and indirect discrimination. Direct discrimination is defined as a situation in which one person is treated less favourable on the grounds of a prohibited criterion than another is, has been or would be treated in a comparable situation [\\\\\\\\[78\\\\\\\\]](#page-21-5). Thus, it is straightforwardly related to the possession of a protected attribute that distinguishes the person from other individuals, regardless of the intention behind the disparate treatment or the mere existence of less favourable treatment. In the context of datadriven systems, direct discrimination will cover those cases where the model is not neutral towards a protected attribute and offers a less favourable output to individuals on the basis of protected groups, whether they truly fit into that group or are associated with the protected attribute. Since consciously inputting discrimination into the model will affect its accuracy, these cases are not of great concern [\\\\\\\\[113\\\\\\\\]](#page-24-3).\\\\n\\\\nBy contrast, indirect discrimination will more likely capture many situations of algorithmic discrimination because it affects situations where an apparently neutral provision, criterion or practice would put members of a protected category at a particular disadvantage compared with other persons unless that provision, criterion or practice is objectively justified by a legitimate aim and the means of achieving that aim are appropriate and necessary [\\\\\\\\[78\\\\\\\\]](#page-21-5). Nevertheless, the prohibition of indirect discrimination does not encompass a set of clear and easily applicable rules, it can rather be considered closer to a standard than to a rule [\\\\\\\\[118\\\\\\\\]](#page-24-4). The concept of indirect discrimination results in rather open-ended standards, which are often difficult to apply in practice. It needs to be proven that a seemingly neutral rule, practice or decision disproportionately affects a protected group [\\\\\\\\[118\\\\\\\\]](#page-24-4). Due to this, indirect discrimination concerns neutral models, which in principle are blinded to sensitive attributes or do not operate on the basis of those protective attributes. Thus, direct discrimination focuses on individual cases of discrimination, while indirect discrimination deals with rules and patterns of discrimination and can reveal underlying social inequalities.\\\\n\\\\n### 3.2 Data Protection Law\\\\n\\\\nThe European Union General Data Protection Regulation (GDPR) [\\\\\\\\[84\\\\\\\\]](#page-22-4) refers to automated individual decision-making and seeks, amongst other objectives, to prevent algorithmic discrimination. Generally, the GDPR states the objective to protect all the fundamental rights recognised under EU law, which the processing of personal data may challenge. According to the GDPR, the core principles that shall lead the processing of personal data are lawfulness, fairness, and transparency. Concretely, the principle of fairness entails the processing of personal information that is not in any way unduly detrimental, unexpected, or misleading to the individuals concerned ([\\\\\\\\[48\\\\\\\\]](#page-19-4)). Indeed, the principle of fairness seeks to protect the individual's fundamental rights and freedoms, and so, their non-infringement by such processing. Likewise, the principle of data accuracy requires the control of the quality of data for its processing, although it does not address the possible wrongful or disproportionate selection of data and therefore the effect and consequences resulted from such selection [\\\\\\\\[76\\\\\\\\]](#page-21-7). To ensure fair processing, the GDPR requests the use of appropriate mathematical and statistical procedures for profiling that take into account the risks involved for the interest and rights of data subjects and prevent discriminatory effects on natural persons (Recital 71 [\\\\\\\\[84\\\\\\\\]](#page-22-4)). Furthermore, the GDPR highlights the potential risks to the rights and freedom of natural persons, which could lead to physical, material or non-material damage, in particular when processing results in discrimination (Recital 75 [\\\\\\\\[84\\\\\\\\]](#page-22-4)). Despite these provisions, ensuring fairness is still quite a subjective matter as it requires that the data processing shall not exceed reasonable expectations nor provoke unjustified adverse effects on the individuals. However, what can be considered reasonable expectations and justifiable effects is an open question, leaving the notion of fair processing undefined.\\\\n\\\\nHowever, the European anti-discrimination law evidently embedded notions of substantive discrimination and therefore, unjustified algorithmic discrimination, as referred to in Article 5 and Recital 71, implies unfair processing [\\\\\\\\[38\\\\\\\\]](#page-18-4). From the legal perspective, discrimination collides with equality, infringing the principle of fairness; whereas from a technical perspective, algorithmic discrimination straightforwardly entails unfair processing (see Section [2\\\\\\\\)](#page-1-0).\\\\n\\\\n### 3.3 EU Artificial Intelligence Regulation Proposal\\\\n\\\\nWith the EU Artificial Intelligence Act the European Union aims at laying down harmonized rules on artificial intelligence with four specific objectives [\\\\\\\\[85\\\\\\\\]](#page-22-0): 1) ensure that AI systems placed on the Union market are safe and respect existing law on fundamental rights and Union values; 2) ensure legal certainty to facilitate investment and innovation in AI; 3) enhance governance and effective enforcement of existing law and safety requirements applicable to AI systems; 4) facilitate the development of a single market for lawful, safe and trustworthy AI applications preventing market fragmentation.\\\\n\\\\nIn essence, the Proposal seeks to balance legal certainty and the development of AI systems while ensuring an approach that respects European values, principles and laws. The specific purpose of the Proposal is to establish a classification for trustworthy AI systems based on a risk-based approach, to introduce new legal obligations and requirements on public authorities and businesses for the development and application of AI systems, to prohibit harmful AI-enabled practices, and to set new monitoring and enforcement regimes. Essentially, the Proposal will set a legal framework applicable for developers and end-users of AI systems which specific characteristics—opacity, complexity, dependency on data, autonomous behaviours—can adversely affect a number of fundamental rights enshrined in the EU Charter of Fundamental Rights [\\\\\\\\[85\\\\\\\\]](#page-22-0).\\\\n\\\\nThe Proposal delimits a set of prohibited AI practices considered harmful because they contravene EU values and violate fundamental rights. Second, the Proposal outlines specific obligations to avoid the appearance of bias in two types of high-risk AI systems; (1) those which are intended to be used as a safety component of a product or is itself a product, and this product is subject to an existing third-party conformity assessment, and (2) those which are involved in decision-making processes in the following areas; (i) biometric identification and categorization of natural persons, (ii) management and operation of critical infrastructure, (iii) education and vocational training, (iv) employment and workers management as well as access to self-employment, (v) law enforcement, (vi) migration, asylum, and border control management, and (vii) administration of justice and democratic processes (see Section [2.1\\\\\\\\)](#page-1-1).\\\\n\\\\nAccording to the Proposal, AI systems can only be placed into the EU market if they comply with the certain minimum requirements specified in the legislation, requirements that become stricter as the risk associated with the system increases (i.e., minimal risk, low risk, high risk, and unacceptable risk). Consequently, providers will need to carry out ex-ante conformity assessments and implement quality and risk management systems and post-market monitoring to ensure compliance with the new regulation and minimise the risk for users and affected persons. However, the Proposal pays little attention to identifying the causes and proposing recommendations to tackle the potential discriminatory harms of AI systems. Specifically, the Proposal mainly focuses on biases in data sets, forgetting other types such as those that may arise from the choice of algorithms, and the optimization or evaluation of metrics. Additionally, the Proposal may pose unreasonable trust in human operators—i.e., human in the loop—to identify and recognise cases of bias and discrimination in AI systems.\\\\n\\\\nThe Proposal does not provide detailed guidance on dealing with unavoidable trade-offs for the different stakeholders when debiasing and monitoring bias in the data set. Nevertheless, some insights can be found in the Proposal regarding the expected requirements to debias high-risk AI systems. Firstly, there will be an obligation to establish appropriate data governance and management practices concerning the training, validation, and testing of data sets, in particular, to examine possible biases, ensure the relevance, representativeness, absence of errors and completeness of the data sets, and their consideration with the characteristics or elements that are particular to the specific geographical, behavioural or functional setting within which the high-risk AI system is intended to be used [\\\\\\\\[85\\\\\\\\]](#page-22-0). Secondly, a novel exception to the Data Protection Regulation will allow to the extent that it is strictly necessary for the purposes of ensuring bias monitoring, detection and correction in relation to the high-risk AI systems [\\\\\\\\[85\\\\\\\\]](#page-22-0) the processing of special categories of data. Finally, the Proposal asks for developing methods that will ensure the detection of biased outputs and the consequent introduction of appropriate mitigation measures as it recognises the potential of AI systems to develop biased outputs due to outputs used as an input for future operations, i.e., feedback loops.\\\\n\\\\nInterestingly, the Proposal also details the role of standards and specifications in the AI landscape [\\\\\\\\[85\\\\\\\\]](#page-22-0). On the one hand, the Proposal addresses the use of harmonised standards to presume the conformity of AI systems with the regulation's requirements. On the other hand, the Proposal entitles the Commission with the duty to adopt common specifications and technical solutions when the harmonised standards are insufficient or there is a need to address specific or fundamental rights concerns. In other words, conformance with technical standards and common specifications should give providers of high-risk AI a level of confidence that they are compliant with the mandatory requirements of the proposed EU AI Regulation as well as significantly cutting the cost of compliance for business [\\\\\\\\[65\\\\\\\\]](#page-20-5). Whereas neither the standards nor the specifications will be compulsory for providers of high-risk AI systems, their non-adoption shall entail a justification as to which and why other technical solutions were adopted.\\\\n\\\\n# <span id=\\\\\\\"page-6-0\\\\\\\"></span>4 An Industry Perspective on Bias and Fairness in AI\\\\n\\\\nSubstantial research on ML fairness, even for industry applications, has originated out of academic contexts. Academic research has first proposed most fairness principles and quantitative methods to mitigate biases and unbalanced data with general application domains [\\\\\\\\[6,](#page-16-6) [59,](#page-20-6) [66\\\\\\\\]](#page-20-4). Toolkits appeared ready to be integrated for the industry, even if often developed following non-contextual design rationales based upon the issues of algorithmic methods [\\\\\\\\[43\\\\\\\\]](#page-19-5). Until recently, the technical nature of academic contributions have often not addressed the practical issues that industry practitioners face when adopting and engaging with fairness tools. Practitioners have pointed out the lack of ethical tools' usability in real-world applications due to a series of critical factors preventing the straightforward adoption of fairness principles and methods [\\\\\\\\[69\\\\\\\\]](#page-20-7). Following Morley et al. [\\\\\\\\[71\\\\\\\\]](#page-21-8), such non-effectiveness in real-world cases stems from how fairness compliance is operationalized inside companies. If not developed with the sociotechnical features and constraints of AI product deployment in mind, these methods could easily lead to failures [\\\\\\\\[43\\\\\\\\]](#page-19-5) including for example fairness definitions misinterpretation [\\\\\\\\[54\\\\\\\\]](#page-19-6), obfuscation of practitioners' accountability [\\\\\\\\[81\\\\\\\\]](#page-21-9), and gaming fairness measures as a method of ethics-washing [\\\\\\\\[71\\\\\\\\]](#page-21-8). To avoid shortcomings, researchers are now focusing on how to operationalize fairness frameworks based on the needs of industry practitioners. Veale et al. [\\\\\\\\[110\\\\\\\\]](#page-24-5) conducted interviews with decision makers in high-stakes public-sector contexts. Practitioners were found to be lacking incentives and practices for algorithmic accountability due to resource constraints and dependency on prior infrastructure. Holstein et al. [\\\\\\\\[44\\\\\\\\]](#page-19-7) enlarged the pool of industry practitioners with a systematic investigation of ML product development. Amid the area of intervention were identified issues of data quality provenance and reporting, as well as the need for domain-specific educational resources and compliance protocols, intended specifically as internal auditing processes and tools for fairness-focused debugging. Rakova et al. [\\\\\\\\[92\\\\\\\\]](#page-22-5) reported that practitioners often felt a hostile organizational environment where they were hindered or uncompensated when trying to implement fairness practices independently. Disincentive stems from the lack of educational programs, rewards, accountability allocation, and communicative protocols over fairness issues, especially when different parts of an AI development are distributed across different teams. This resulted in practitioners often feeling disoriented, unprepared, or even overwhelmed by fairness tools and checklists [\\\\\\\\[19,](#page-17-6) [44\\\\\\\\]](#page-19-7). It was also observed that practitioners recommend establishing internal and external investigation committees to create an inclusive and preventive environment and to provide resources such as protocols or educational teams [\\\\\\\\[61,](#page-20-8) [92\\\\\\\\]](#page-22-5). Other research examples, once informed on practitioners' needs, focused on designing different AI fairness solutions: checklists to be aligned with teams' workflows and organizational ad-hoc processes, fairness frameworks or internal algorithmic auditing protocols designed for industrial applications [\\\\\\\\[61,](#page-20-8) [91\\\\\\\\]](#page-22-6). Recently, Richardson and Gilbert [\\\\\\\\[97\\\\\\\\]](#page-23-7) proposed a complete industry framework of stakeholders and fairness recommendations while specifying operationalization pitfalls. Ibáñez and Olmeda [\\\\\\\\[47\\\\\\\\]](#page-19-8) distinguished two main perspectives on operationalizing fairness practices in organizations: a bottom-up, reactive approach, where prior organizational processes restrain best practices, or top-down, where a proactive approach is set in place according to the translation of principles and methods as actionable, iterative steps designed with stakeholders' needs and concerns in mind. Interestingly, the literature agrees that fairness interventions should not be standardized and reactive to prior single instances of organizational infrastructure issues, but proactive, based on a thorough understanding of different stakeholders' needs, and accounting for domain-specific and contextual factors.\\\\n\\\\nIn regards to the Proposal, it is not yet clear how fairness practices will be effectively operationalized given the mechanisms envisioned in Articles 43 and 61 from the Proposal, respectively for conformance checking and post-market monitoring of high-risk systems. For those systems, providers will be demanded to draft and verify their conformance through a quality management system, technical documentation, and post-market monitoring under the lens of a national body. This body will be guided by a national supervisory authority in coordination with the EDPB (European AI Board from the EU commission). Yet, some detractors, in line with some concerns over organizations' ethics washing, advanced skeptical doubts on the procedural efficacy of these auditing mechanisms [\\\\\\\\[60,](#page-20-9) [64\\\\\\\\]](#page-20-10). Doubts were related to the undisclosed nature of conformity declarations as well as the nature of contributions of data criteria input to the EU database for stand-alone high-risk AI systems in Article 60, withheld from the scrutiny of those affected by such systems and available only upon regulatory bodies' request. This loose gravity towards the public interest might not permit to enforce EU citizen fundamental rights to decide whether a system should be listed as high-risk. In light of the concerns for more structural fairness practices, the evolution of an overly rigid and costly compliance environment could critically undermine these needs. An official impact assessment has been proposed [\\\\\\\\[95\\\\\\\\]](#page-22-7) to quantify these costs. Mueller [\\\\\\\\[72\\\\\\\\]](#page-21-10) advanced an analysis of the economic costs that could arise for EU small and medium enterprises and corporations. In the forecast, effects will push away venture capital investors, drain European talents and tighten stronger external dependencies leading to a highly unfavorable European environment, with the risk of being excluded from the global AI market. Academics and policy analysts have advanced a debate on the validity of those claims, picturing less-burdening assessments over quality management systems, thus calling the report factitious [\\\\\\\\[37,](#page-18-5) [57\\\\\\\\]](#page-20-11). Future predictions will need to account both for amendments to the terminology and procedures. Foremost, central analysis focus should be given to the ecosystem of digital technology regulations that the EU has on its agenda [\\\\\\\\[80\\\\\\\\]](#page-21-11). These digital Proposals constitute the European intention of enforcing its legislative sovereignty and set standards for the international market. Leveraging the Brussels Effect [\\\\\\\\[12,](#page-16-7) [31\\\\\\\\]](#page-18-6) and the current rise of AI ethics attention across a wide range of institutional and academic stakeholders [\\\\\\\\[35,](#page-18-7) [102\\\\\\\\]](#page-23-8), it is reasonable to predict that in the near future current investments in integrating fairness governance practices could be streamlined into more mature and efficient regulatory frameworks with lower procedural costs while mitigating reputational risks [\\\\\\\\[92\\\\\\\\]](#page-22-5).\\\\n\\\\n# <span id=\\\\\\\"page-8-0\\\\\\\"></span>5 A Sociotechnical Perspective on Bias and Fairness in AI\\\\n\\\\nRegarding AI fairness and discrimination, many have pointed out that AI is not merely a tool, it is a sociotechnical endeavour, meaning that the development, use of (and harm from) AI technologies can not be separated from their specific social contexts [\\\\\\\\[27,](#page-17-7) [90\\\\\\\\]](#page-22-8). When attempting to prevent harm from technologies we must look closely at a new technology's actual capacities and functions within these contexts. An over-emphasis of the role of specific technological features of AI in either causing, or preventing, discrimination, for example, can obscure other forms of discrimination that are occurring, as well as lead to an unproductive and ultimately distracting focus on fixing or regulating those specific features [\\\\\\\\[33,](#page-18-8) [90\\\\\\\\]](#page-22-8).\\\\n\\\\nVeale and Borgesius [\\\\\\\\[109\\\\\\\\]](#page-24-6) make a similar argument in regards to the Proposal. They cite the examples of the prohibition against releasing AI systems that use subliminal or subconscious techniques to distort a person's behaviour and argue that this focus on evocative, ripped from the headlines potential harms does little to mitigate actual harms and adds little to existing legislation [\\\\\\\\[109\\\\\\\\]](#page-24-6). Issues include, for instance, that prohibition only covers manipulative systems that cause individual harm but not a collective harm or a harm that arises from dynamics of the user-base entwined with an AI system [\\\\\\\\[109\\\\\\\\]](#page-24-6) and that there must be intent to distort behaviour. Dourish and Bell [\\\\\\\\[25\\\\\\\\]](#page-17-8) identified a similar phenomenon surrounding the discussion and implementation of ubiquitous computing technologies and contrast the myth used to build visions of technologies and the messiness of the practical implementation of technologies in reality. They further describe ubiquitous computing researchers as explaining away limitations and unexpected consequences of specific systems by referring to a proximate future where the given technology will be fully realized and highly useful, as soon as a few remaining kinks (such as unevenly distributed infrastructure, for example) are ironed out [\\\\\\\\[25\\\\\\\\]](#page-17-8).\\\\n\\\\nIn the case of the messy realities of AI, it is widely acknowledged that it is non-trivial to build error-free models and good quality data within the context of societal factors and power structures at play [\\\\\\\\[18,](#page-17-9) [27,](#page-17-7) [67\\\\\\\\]](#page-20-12). To give a specific example, data workers who are frequently manually labeling, cleaning, and enriching the data used for training AI models, have a crucial role in the development of AI systems and their practices are subject to a myriad of non-objective influences [\\\\\\\\[67\\\\\\\\]](#page-20-12). Similarly, the harms often identified with AI use online, such as hyper-personalization, invasion of privacy, and spread of hate speech can stem from issues beyond the technology, such as monopolies, data power imbalances, and un-checked corporate crime [\\\\\\\\[24\\\\\\\\]](#page-17-10). Some have argued that those aspects of online life are a requisite feature of an emerging economic system that has grown out from the existing capitalist economic system [\\\\\\\\[117\\\\\\\\]](#page-24-7).\\\\n\\\\nTherefore, we must acknowledge the systemic sources of the discrimination when mitigating discriminatory harm of AI technologies and the discussion of the impact of such technologies should start at an earlier point. In particular, we must look at the specific setting of a given case. This includes considering what specific sociopolitical goals a given AI system is enforcing. For example, in Austria, a risk assessment algorithm created for use in the public employment system has been described as guided by a philosophy of neo-liberal austerity in the social sector which has been replacing the concept of the European welfare state [\\\\\\\\[3\\\\\\\\]](#page-16-8). We must also consider where the discussions are happening, who is involved in the discussions, and how the population is able to discuss and enforce whether an AI in a domain should be used at all. In regards to the Proposal, according to [\\\\\\\\[109\\\\\\\\]](#page-24-6), there is evidence of industry influence in high level policy decision-making surrounding the current Proposal.\\\\n\\\\nAnother complication in regulating and mitigating harm from AI is the complexity of determining how, or if, it is possible to distinguish between AI decisions and human decisions. If we do not acknowledge these entanglements, there is a risk of bias being addressed with overly mechanistic approaches. In reference to the example of privacy ethics, Nissenbaum [\\\\\\\\[75\\\\\\\\]](#page-21-12) has described how a focus on the very attempt to mitigate privacy concerns by ever more sophisticated anonymization methods can lead to overlooking other issues, such as algorithms that do not infringe on privacy, yet are still harmful. Similarly, a focus on attempting to operationalize a very specific concept of fairness, and to regulate specific methods for monitoring it, risks pulling awareness from other algorithmic harms, or even obfuscating underlying causes of harm [\\\\\\\\[7,](#page-16-9) [90\\\\\\\\]](#page-22-8). In the case of the Austrian AMS, described above, the controversy of a proposed algorithm opened up a whole discussion about how a Public Employment System should be run overall. From the perspective of power aware analysis [\\\\\\\\[67\\\\\\\\]](#page-20-12) everyone affected needs to be involved in those decisions.\\\\n\\\\n# <span id=\\\\\\\"page-9-0\\\\\\\"></span>6 A Philosophical Perspective on Bias and Fairness in AI\\\\n\\\\nWe also look at developments in AI and algorithmic fairness through the lens of moral philosophy, specifically normative ethics [\\\\\\\\[49\\\\\\\\]](#page-19-9), which essentially investigates the question of whether something is morally right or wrong. There are two major schools of thought in normative ethics; (i) Deontological ethics argues the existence and significance of inherent rightness of an action (examples include Kant's categorical imperative [\\\\\\\\[86\\\\\\\\]](#page-22-9), and Rawls' veil of ignorance [\\\\\\\\[93\\\\\\\\]](#page-22-10)); (ii) Consequentialism judges the morality of an action based on the value it brings (examples include welfarism [\\\\\\\\[51\\\\\\\\]](#page-19-10), hedonism [\\\\\\\\[70\\\\\\\\]](#page-21-13)). While our deontological views inform the building blocks of morality in today's society (e.g., EU fundamental rights), consequential approaches enjoy scalability through the use of representative or proxy metrics in real-world usages (e.g., cost-benefit analysis [\\\\\\\\[58\\\\\\\\]](#page-20-13) or per-capita income in economics, and overall accuracy in machine learning as discussed in Section [2\\\\\\\\)](#page-1-0). Traditional AI research often follows a declarative approach where a mathematical objective is designed and optimized while caring less about the decision-making process and its correctness or representativeness [\\\\\\\\[13,](#page-16-10) [16,](#page-17-11) [29\\\\\\\\]](#page-18-0). Such an approach can be argued to be a consequentialist's approach to AI whereby only the optimization of final objective matters and the end justifies the procedure. However, this approach has received a lot of critique within the AI domain, and a range of issues have been pointed out; for example concerning causality [\\\\\\\\[17,](#page-17-12) [34\\\\\\\\]](#page-18-9), fairness [\\\\\\\\[29,](#page-18-0) [66\\\\\\\\]](#page-20-4), explainability [\\\\\\\\[13\\\\\\\\]](#page-16-10), including the comparability and robustness of explanations [\\\\\\\\[88,](#page-22-11) [89\\\\\\\\]](#page-22-12), and trustworthiness [\\\\\\\\[107\\\\\\\\]](#page-23-9).\\\\n\\\\nAnother angle from which AI developments can be looked at, is Welfarism [\\\\\\\\[51\\\\\\\\]](#page-19-10) (a type of\\\\n\\\\nconsequentialism), which suggests choosing the action that maximizes the welfare or well-being of the population. In fact, it is widely used in some areas of economics, game theory, social-choice theory, and applications. Welfarism is often studied in two major forms; (i) Utilitarianism [\\\\\\\\[104\\\\\\\\]](#page-23-10) emphasizes maximizing the welfare of the population; (ii) Egalitarianism argues for equality often leading to a form of Rawlsian justice [\\\\\\\\[93\\\\\\\\]](#page-22-10) which comes under deontological ethics, but its objective form in welfarism tries to maximize the welfare of the worst-off. Utilitarianism is found to be heavily embedded in today's society. For example, the optimization objectives (loss functions) in machine learning are often the aggregate errors over the set of data points or the individuals, i.e., utilitarian in nature. Utilitarian social welfare is quite prevalent in economics, computational social choice (allocation, voting, etc.)[1](#page-10-1) . Such utilitarian objectives tend to optimize for the overall utility while may be best-serving the majority and poorly serving the minority populations. This is one of the reasons due to which the usual loss-minimizing objectives have been found to be unfair in many applications including criminal justice, banking, and gig-economy. On the other hand, egalitarian welfarism in machine learning would likely try to equalize the errors of all or groups of individuals instead of minimizing the aggregate errors. In fact algorithmic fairness notions like individual fairness [\\\\\\\\[26\\\\\\\\]](#page-17-4), equal opportunity and equality of odds [\\\\\\\\[40\\\\\\\\]](#page-18-10), equal mistreatment [\\\\\\\\[114\\\\\\\\]](#page-24-8) are either inspired by or promote egalitarian views in consequential modeling (error represents a consequence). These notions have been found to reduce the effects of pre-existing biases in data and to improve the utilities of marginalized groups under algorithmic decision-making systems.\\\\n\\\\nA few recent works have also explored non-consequential or deontological approaches to algorithmic fairness. These works can be grouped into two categories. (1) Works on procedural fairness [\\\\\\\\[30,](#page-18-11) [32\\\\\\\\]](#page-18-12) argue that it is essential for the chosen design and principles to be socially acceptable. Thus, these works focus on understanding how people assess fairness and ways to infer societal expectations about fairness principles thereby accounting for all voices in designing fair decisionmaking systems. For example, Grgić-Hlača et al. [\\\\\\\\[32\\\\\\\\]](#page-18-12) propose a framework for procedural fairness by evaluating the moral judgments of humans regarding the use of certain features and accordingly designing decision-making systems. (2) Another set of works argue for causal and counterfactual fairness, i.e., addressing unfair causal effects of sensitive attributes in the decision-making process [\\\\\\\\[17,](#page-17-12) [55\\\\\\\\]](#page-19-2). Instead of focusing on the outcome alone, these works have explored deontological aspects and propose to ensure fairness in the decision-making process.\\\\n\\\\n# <span id=\\\\\\\"page-10-0\\\\\\\"></span>7 Mapping Perspectives\\\\n\\\\nWe have identified three axes along which different perspectives in the debate about AI Regulation for preventing unfairness and discrimination fall. These axes may or may not be orthogonal, i.e., they may have relationships with each other. In the following sections, we define the axes and describe the debate surrounding regulating fairness in AI represented by each axis. These are not all of the axes of debate, rather these are salient tensions that we have identified. We find them helpful in conceptualizing and mapping the values and desiderata of the perspectives we are focusing on.\\\\n\\\\n### 7.1 Axis-1: Standardization vs. Localization\\\\n\\\\n#### 7.1.1 The axis\\\\n\\\\nThis first axis of interest addresses the differences between standardization and localization. Standardization entails the process of making things of the same type all have the same basic features\\\\n\\\\n<span id=\\\\\\\"page-10-1\\\\\\\"></span><sup>1</sup>Nash social welfare [\\\\\\\\[50\\\\\\\\]](#page-19-11) is an exception.\\\\n\\\\n<span id=\\\\\\\"page-11-0\\\\\\\"></span>![](_page_11_Picture_0.jpeg)\\\\n\\\\nFigure 1: Three identified axes along which the debate about regulation of fairness in AI falls; Here they are aligned along high-level characterizations and common arguments made for, and against, each of the ends of the identified axes.\\\\n\\\\n(from Cambridge dictionary), specifically, through the creation of protocols to guide the design, development, and creation of such goods or services based on the consensus of all the relevant parties in the industry. Standardization is intended to ensure that all the goods and services produced respecting those protocols come with the same or equivalent quality, safety, interoperability and compatibility. For this reason, multiple parties need to be involved in developing such protocols and standards, namely, manufacturers, sellers, buyers, customers, trade associations, users or regulators (<https://www.iso.org/standards.html>). By contrast, localization describes the process of making a product or a service more suitable for a particular country, area, etc. (from Cambridge dictionary). In essence, localization entails adapting the product or service to the characteristics of a given culture, region, or society.\\\\n\\\\n### 7.1.2 Pros and cons\\\\n\\\\nIn the context of AI, advocates for and members of industry frequently cite standardization as a method for preventing or mitigating discrimination [\\\\\\\\[41,](#page-18-13) [53,](#page-19-12) [108\\\\\\\\]](#page-23-11). In this respect, high-risk AI systems will be presumed to comply with the requirements established in the AI Proposal if they are, as well, in conformity with the harmonised standards published by the Official Journal of the European Union as referred to in article 40 [\\\\\\\\[85\\\\\\\\]](#page-22-0). Likewise, high-risk AI systems in conformity with the specifications referred to in Article 41 of the AI Proposal will be presumed in conformity with the regulation [\\\\\\\\[85\\\\\\\\]](#page-22-0). In this sense, conformity with standards and specifications as proposed in the AI Regulation will allow the entry of high-risk AI systems in the European market while guaranteeing agreed levels of quality and safety that ensure the adherence to European principles and values (i.e., non-discrimination, fairness, and human dignity).\\\\n\\\\nA dilemma regarding standardization, however, appears when there is a disagreement regarding the standard of fairness that should be used to assess AI systems. As presented in Section [2.1](#page-1-1) the straightforward example of incompatible fairness standards referred to the case of COMPAS and the different standards followed by ProPublica [\\\\\\\\[5\\\\\\\\]](#page-16-5) and Northpoint [\\\\\\\\[22\\\\\\\\]](#page-17-13) for their fairness assessments, i.e., disparate mistreatment and calibration respectively [\\\\\\\\[118\\\\\\\\]](#page-24-4). Moreover, overly specific and strict standards and frameworks risk encoding a biased, restrictive, non-relevant to everyone, singular worldview, and may ultimately lead to uniformization from a top-down approach Section [4.](#page-6-0) In truth, standardarization as a method to enforce fairness can in some cases overlook the root-causes of bias, setting standards and notions of fairness that do not offer a real solution to the intrinsic discrimination or biases in certain situations or contexts Section [5.](#page-8-0) A—purely hypothetical—example of this problem would be the hard-coded requirements for gender parity in school admissions or hiring where there was a low representation of one of the genders, e.g., due to relocation for work reasons or armed conflicts. The solution would be to establish an acceptable ratio of males to females set at a level appropriate to the local context, rather than a strict gender parity requirement.\\\\n\\\\nIn this regard, localizing AI systems entails the process of making them local in character by limiting the ethics regulation and specifics of enforcement to the desired area. Whereas the complete localization of AI systems will be in conflict with the embedded values of the AI Regulation (e.g., European Common Market and European Fundamental Rights), the localization of some of the decisions regarding their design, development, or deployment may allow a more tailored approach to address AI discrimination and biases in specific geographical, cultural, or sociotechnical contexts. The localization of some requirements and technical solutions may, as well, allow for the definition of ethical and legal guidelines that address the specific circumstances of a community, local area, or sector beyond the general standards and specifications.\\\\n\\\\n### 7.2 Axis-2: Utilitarian vs. Egalitarian\\\\n\\\\n#### 7.2.1 The axis\\\\n\\\\nThe second axis of interest addresses differences between utilitarian and egalitarian views. While a utilitarian philosophy is one of maximizing the overall welfare of the population, egalitarianism aims for equality amongst all those people.\\\\n\\\\n#### 7.2.2 Pros and cons\\\\n\\\\nUtilitarianism has long been argued to be in conflict with the certain conceptualizations of fairness (see Chapter 14 of Hooker [\\\\\\\\[45\\\\\\\\]](#page-19-13)). In the context of AI, algorithms are often designed to optimize for certain mathematical objectives (which can be categorized as a declarative approach). The objective functions in machine learning tasks usually measure a form of aggregate accuracy over a population, which fits the definition of a utilitarian measure. Optimizing solely for such a measure in AI applications risks optimizing the utility of the whole population while hurting minority groups in many [\\\\\\\\[40,](#page-18-10) [114\\\\\\\\]](#page-24-8). Utilitarian approaches are so ingrained in the computing research and development mindset that the early group fairness notions—which are supposed to mitigate the discriminatory effects of utilitarian objectives—such as demographic parity, had been reduced to utilitarian forms by constraining over the aggregate benefits or outcomes of groups of individuals [\\\\\\\\[115\\\\\\\\]](#page-24-9). The literature has now moved on to notions such as individual fairness, equal opportunity, and treatment parity which, even though outcome-based, are more egalitarian in nature.\\\\n\\\\nDespite its obvious conflicts with fairness, and egalitarianism's close connection with fairness, utilitarian welfare is often cited a necessary factor in system and policy design. In fact, protecting the EU's economic interests is stated as a goal of the AI Act [\\\\\\\\[85\\\\\\\\]](#page-22-0). Since utilitarianism captures a certain overall efficiency of a system (accuracy in machine learning, utilitarian welfare in economics), its goals often reflect business-oriented metrics of AI applications (i.e., click-through rate for recommendations in online marketplaces, or success-rate of ranked workers on gig-economy platforms). However, there might be a trade-off between maximizing efficiency and achieving other social objectives like equity or fairness in cases of inherent imbalance in the data or population [\\\\\\\\[9,](#page-16-11) [10\\\\\\\\]](#page-16-12).\\\\n\\\\n### 7.3 Axis-3: Consequential vs. Deontological\\\\n\\\\n#### 7.3.1 The axis\\\\n\\\\nThis third axis of interest from the discussions in Sections [3](#page-3-0) to [6](#page-9-0) represents the differences between consequential and deontological ethics. Deontological ethics argue for the existence of the inherent rightness of an action, while consequential ethics evaluate morality based on the consequences of an action.\\\\n\\\\n#### 7.3.2 Pros and cons\\\\n\\\\nTechnical measures for mitigating AI based discrimination tend to focus on fairness notions, whereby a fairness constraint is often added to the original objective. Fairness in this case is defined by statistical properties of the outcome/decision of the system (e.g., demographic parity). Fairness notions thus seek to reduce harm by adjusting or influencing the outcome to fit some statistical definition of fairness. While the motivation for doing this may be based on deontological principles of equality, this approach belies a consequentialist definition of fairness, wherein one declares that fairness has been achieved through an equality in outcome, such as equal amount of good (accurate) and bad (inaccurate) outcomes for each group.\\\\n\\\\nDeontological ethics is often given as an opposite to consequentialism. A deontological approach argues for the existence and significance of the inherent rightness of an action; in the context of AI based discrimination, this would suggest that the approach described above does not meet the criteria of acting morally, as the focus is on shifting the outcome. From a deontological perspective, an AI system is unlikely to be fair if the development of AI itself is not driven by essential guiding principles, such as fairness.\\\\n\\\\nThe Proposal's prohibition of certain uses is based on deontological principles of protecting fundamental individual rights. However, the risk based approach could be viewed as consequential, in that it only targets systems used in contexts perceived as being highly consequential. This means that many AI systems which might exhibit harmful representational or discriminatory biases, such as social media and online platforms are relieved of any requirements.\\\\n\\\\nSummary: Based on the pattern of high-level characterizations and common arguments made for, and against, each end of the identified axes, we place them along a single axis, with one end containing localized, deontological, egalitarian approaches (LED) and the other end containing standardized, utilitarian, consequential approaches (SUC); we illustrate this mapping in Figure [1.](#page-11-0) The LED end contains approaches that purport to acknowledge systemic and complex causes of discrimination and are often criticized as being overly subjective and hard to deploy. The approaches on the SUC end purport to be objective and easy to implement while often being critiqued as failing to recognize systemic causes or ensure inclusion of minority voices. This mapping of the perceived benefits and shortcomings of each approach allows us to identify a key tension in the debate on regulating fairness in AI. It is one that is based on differing understandings of the nature of bias and discrimination, along with differing priorities as to what constitutes practicality and implementability in efforts to increase fairness. Following this, we suggest how the Proposal could better balance these values, as well as the differing perspectives of stakeholders, to achieve the stated goal of guaranteeing agreed levels of quality and safety in accordance with European principles and values (i.e., non-discrimination, fairness, and human dignity) without creating major hurdles for the European AI Industry.\\\\n\\\\n# <span id=\\\\\\\"page-14-0\\\\\\\"></span>8 Key Agreement and A Path Forward\\\\n\\\\n### 8.1 Key Agreement\\\\n\\\\nWe see a specific agreement amongst the presented perspectives, regarding limitations of the current regulation. Ultimately each of the perspectives agree that regulation needs to be grounded in the reality of the context of the use of AI, and that this is not sufficiently achieved in the Proposal. A brief summary of these previously discussed realities that the Proposal as not sufficiently accounting for is as follows: 1. lack of agreement on what technology like AI really is and what are its capabilities, 2. cost and complexity for a business to follow the required regulations, 3. the known limitations of debiasing techniques and explanations of black boxes, 4. lack of specifications on how to best implement human oversight in the context of AI systems, 5. varied and shifting notions of fairness within society, 6. impact of power imbalances (eg. technological divide, data power, company size, and market share) on the creation and enforcement of and ability to comply with the Proposal.\\\\n\\\\n### 8.2 A Path Forward: Balancing Perspectives\\\\n\\\\n#### <span id=\\\\\\\"page-14-1\\\\\\\"></span>8.2.1 Standardization and Localization\\\\n\\\\nStandardization may facilitate the translation of fundamental rights, i.e., right to fairness, into standards and specifications to be followed and complied with by all AI actors with the aim of ensuring that AI systems do not discriminate nor mistreat individuals.\\\\n\\\\nLikewise, localization may allow the clarification of deontological values in more specific and concrete requirements, metrics, or assessments, particular to each enforcement context. This is to prevent a top-down enforcement of operationalizations of fairness that are untenable, or even unfair, in some contexts. For example, in Section [4](#page-6-0) we have summarized the literature demonstrating that ensuring fairness compliance from AI industry could as well be served from a more localized approach to operationalizing fairness. This does not imply the relativization of the legal and ethical principle of fairness but, on the contrary, take into account the wider scenario beyond the purely technical nature of AI and strengthen the enforcement of fairness during the whole life cycle of AI.\\\\n\\\\nProposed role of AI Regulation Standardization should be used to the extent that the measure has a direct link to upholding the deontological value of fairness. In order to ensure the principle of universalization, though, special care must be taken to build in flexible localization allowances.\\\\n\\\\n#### 8.2.2 Utilitarian and Egalitarian\\\\n\\\\nIt may be possible to maintain an egalitarian approach to AI Regulations, while also taking advantage of the potential benefits of utilitarian measures. For example, to promote equality (i.e., bring in egalitarianism) all stakeholders could be given sufficient power to provide inputs on how to maximize and measure their welfare. Any decisions about utilitarian measures would then be based on this input. Note that increased awareness of the use of AI systems and their implications toward fairness among the responding individuals (stakeholders) is essential for a successful process. This approach would, again, bring up the question of standardization versus localization. Specifically, how highly localized measures would be required to adequately account for the policy expectations of all individuals in an egalitarian fashion. To address this, we would defer to the principles suggested in Section [8.2.1.](#page-14-1) Extensive work is needed to determine how best to implement such a process, but some of the open questions may be best left answered by the inclusive input process itself.\\\\n\\\\nProposed role of AI Regulation The specific framework for how to obtain and incorporate stakeholder inputs should be laid out. A way needs to be found to enforce that all stakeholders have sufficient power and influence in AI Regulation decision making processes and that they are themselves sufficiently aware of the potential adverse implications of AI technology.\\\\n\\\\n#### 8.2.3 Deontological and Consequential\\\\n\\\\nThe EU's stance on fairness is deontological, in that fairness is justified by itself, with no direct subordination to its eventual outcomes. What matters is whether the action is motivated by duty (respect of the moral law: dignity and universalization). However, expectations of individuals on the specifics of what constitutes freedom, equality, and dignity, may vary across cultures, geographies, and contexts. This has led digital and human rights groups to highlight that AI policies should empower individuals, communities, and organisations to contest AI-based systems and to demand redress when they themselves determine that their fundamental rights have been violated [\\\\\\\\[7\\\\\\\\]](#page-16-9).\\\\n\\\\nThe Proposal itself is not intended to legislate individual rights; that is intended to be covered in other laws of the European legal framework. With that in mind, the Proposal could still enforce an individual's need to be informed and to understand the impacts. Therefore transparency, explainability of the design, development and implementaion of AI systems, as well as their output, remains paramount. There must also be understandable and effective methods for stakeholders to adjust the specific standards, such as what uses are forbidden, in the case of unforeseen use cases and impacts or of the recognition of previously ignored violations of the European principles.\\\\n\\\\nProposed role of AI Regulation Requirements such as documentation and transparency should specifically serve stakeholders' needs to understand the implications of AI systems for their specific situation, life, and work.\\\\n\\\\n# 9 Conclusion\\\\n\\\\nIn this position paper, we presented technical, legal, industrial, sociotechnical, and (moral) philosophical perspectives on the debate on fairness in AI systems with a particular focus on the Proposal of the EU AI Act. We identified a pattern of common arguments representing a key tension in the debate with one side containing deontological, egalitarian, localized approaches and the other side containing standardized, utilitarian, consequential approaches. We discussed how different (symbolic) ends of the axes could be reconciled and proposed the following roles that the AI Regulation could take to successfully address these tensions: (1) apply standardization to uphold deontological values, but ensure universalization by including flexible localization allowances; (2) lay out a framework to incorporate stakeholder inputs and ensure that they are sufficiently aware of potential adverse implications of AI technology; and (3) design requirements of documentation and transparency so that they serve the needs of stakeholders.\\\\n\\\\nAcknowledgements: This work has received funding from the European Union's Horizon 2020 research and innovation programme under Marie Sklodowska-Curie Actions (grant agreement number 860630) for the project \\\\\\\"NoBIAS - Artificial Intelligence without Bias\\\\\\\" and (grant agreement number 860621) for the project \\\\\\\"NL4XAI - Natural Language for Explainable AI\\\\\\\". The authors would like to thank all the panelists of European AI Regulation Week 2021 ([https:](https://aia-week.pages.citius.usc.es/) [//aia-week.pages.citius.usc.es/](https://aia-week.pages.citius.usc.es/)) for their helpful comments on AI regulation. This work reflects only the authors' views and the European Research Executive Agency (REA) is not responsible for any use that may be made of the information it contains.\\\\n\\\\n# References\\\\n\\\\n- <span id=\\\\\\\"page-16-1\\\\\\\"></span>[1] Angelika Adensamer and Lukas Daniel Klausner. 2021. \\\\\\\"Part Man, Part Machine, All Cop\\\\\\\": Automation in Policing. Frontiers in Artificial Intelligence 4 (2021), 29. [https://doi.org/](https://doi.org/10.3389/frai.2021.655486) [10.3389/frai.2021.655486](https://doi.org/10.3389/frai.2021.655486)\\\\n- <span id=\\\\\\\"page-16-2\\\\\\\"></span>[2] Edward Tristram Albert. 2019. AI in talent acquisition: A review of AI-applications used in recruitment and selection. Strategic HR Review 18, 5 (2019), 215–221. [https://doi.org/](https://doi.org/10.1108/shr-04-2019-0024) [10.1108/shr-04-2019-0024](https://doi.org/10.1108/shr-04-2019-0024)\\\\n- <span id=\\\\\\\"page-16-8\\\\\\\"></span>[3] Doris Allhutter, Florian Cech, Fabian Fischer, Gabriel Grill, and Astrid Mager. 2020. Algorithmic profiling of Job Seekers in austria: How austerity politics are made effective. Frontiers in Big Data 3 (2020). <https://doi.org/10.3389/fdata.2020.00005>\\\\n- <span id=\\\\\\\"page-16-0\\\\\\\"></span>[4] Mike Ananny and Kate Crawford. 2018. Seeing without knowing: Limitations of the transparency ideal and its application to algorithmic accountability. New Media & Society 20, 3 (2018), 973–989. <https://doi.org/10.1177/1461444816676645>\\\\n- <span id=\\\\\\\"page-16-5\\\\\\\"></span>[5] Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. 2022. Machine Bias\\\\\\\\*. Ethics of Data and Analytics (2022), 254–264. <https://doi.org/10.1201/9781003278290-37>\\\\n- <span id=\\\\\\\"page-16-6\\\\\\\"></span>[6] Jacqui Ayling and Adriane Chapman. 2021. Putting AI ethics to work: are the tools fit for purpose? AI and Ethics (2021), 1–25. <https://doi.org/10.1007/s43681-021-00084-x>\\\\n- <span id=\\\\\\\"page-16-9\\\\\\\"></span>[7] Agathe Balayan and Seda Gürses. 2021. Beyond Debiasing: Regulating AI and Its Inequalities. Technical Report. Delft University of Technology.\\\\n- <span id=\\\\\\\"page-16-4\\\\\\\"></span>[8] Robert Bartlett, Adair Morse, Richard Stanton, and Nancy Wallace. 2019. Consumer-lending discrimination in the FinTech era. Technical Report. National Bureau of Economic Research.\\\\n- <span id=\\\\\\\"page-16-11\\\\\\\"></span>[9] Richard Berk et al. 2017. A convex framework for fair regression. arXiv preprint arXiv:1706.02409 (2017).\\\\n- <span id=\\\\\\\"page-16-12\\\\\\\"></span>[10] Dimitris Bertsimas, Vivek F. Farias, and Nikolaos Trichakis. 2012. On the efficiency-fairness trade-off. Management Science 58, 12 (2012), 2234–2250. [https://doi.org/10.1287/mnsc.](https://doi.org/10.1287/mnsc.1120.1549) [1120.1549](https://doi.org/10.1287/mnsc.1120.1549)\\\\n- <span id=\\\\\\\"page-16-3\\\\\\\"></span>[11] Miranda Bogen and Aaron Rieke. 2018. Help Wanted: An Examination of Hiring Algorithms, Equity, and Bias. Report. Upturn.\\\\n- <span id=\\\\\\\"page-16-7\\\\\\\"></span>[12] Anu Bradford. 2020. The Brussels effect: How the European Union rules the world. Oxford University Press, USA.\\\\n- <span id=\\\\\\\"page-16-10\\\\\\\"></span>[13] Nadia Burkart and Marco F. Huber. 2021. A survey on the explainability of supervised machine learning. Journal of Artificial Intelligence Research 70 (2021), 245–317. [https:](https://doi.org/10.1613/jair.1.12228) [//doi.org/10.1613/jair.1.12228](https://doi.org/10.1613/jair.1.12228)\\\\n\\\\n- <span id=\\\\\\\"page-17-0\\\\\\\"></span>[14] Aylin Caliskan, Joanna J Bryson, and Arvind Narayanan. 2017. Semantics derived automatically from language corpora contain human-like biases. Science 356, 6334 (2017), 183–186. <https://doi.org/10.1126/science.aal4230>\\\\n- <span id=\\\\\\\"page-17-1\\\\\\\"></span>[15] Longbing Cao. 2022. AI in finance: Challenges, techniques, and opportunities. Comput. Surveys 55, 3 (2022), 1–38. <https://doi.org/10.1145/3502289>\\\\n- <span id=\\\\\\\"page-17-11\\\\\\\"></span>[16] Manuel Carabantes. 2020. Black-box artificial intelligence: an epistemological and critical analysis. AI & SOCIETY 35, 2 (2020), 309–317. [https://doi.org/10.1007/](https://doi.org/10.1007/s00146-019-00888-w) [s00146-019-00888-w](https://doi.org/10.1007/s00146-019-00888-w)\\\\n- <span id=\\\\\\\"page-17-12\\\\\\\"></span>[17] Daniel C Castro, Ian Walker, and Ben Glocker. 2020. Causality matters in medical imaging. Nature Communications 11, 1 (2020), 1–10. [https://doi.org/10.1038/](https://doi.org/10.1038/s41467-020-17478-w) [s41467-020-17478-w](https://doi.org/10.1038/s41467-020-17478-w)\\\\n- <span id=\\\\\\\"page-17-9\\\\\\\"></span>[18] Kyla Chasalow and Karen Levy. 2021. Representativeness in Statistics, Politics, and Machine Learning. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency. Association for Computing Machinery, New York, NY, USA, 77–89. <https://doi.org/10.1145/3442188.3445872>\\\\n- <span id=\\\\\\\"page-17-6\\\\\\\"></span>[19] Henriette Cramer, Jean Garcia-Gathright, Sravana Reddy, Aaron Springer, and Romain Takeo Bouyer. 2019. Translation, tracks & data: an algorithmic bias effort in practice. In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems. 1–8. <https://doi.org/10.1145/3290607.3299057>\\\\n- <span id=\\\\\\\"page-17-5\\\\\\\"></span>[20] Alexander D'Amour, Hansa Srinivasan, James Atwood, Pallavi Baljekar, David Sculley, and Yoni Halpern. 2020. Fairness is not static: deeper understanding of long term fairness via simulation studies. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency. 525–534. <https://doi.org/10.1145/3351095.3372878>\\\\n- <span id=\\\\\\\"page-17-2\\\\\\\"></span>[21] Abhisek Dash, Abhijnan Chakraborty, Saptarshi Ghosh, Animesh Mukherjee, and Krishna P Gummadi. 2021. When the umpire is also a player: Bias in private label product recommendations on e-commerce marketplaces. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency. 873–884. <https://doi.org/10.1145/3442188.3445944>\\\\n- <span id=\\\\\\\"page-17-13\\\\\\\"></span>[22] William Dieterich, Christina Mendoza, and MS Tim Brennan. 2016. COMPAS Risk Scales: Demonstrating Accuracy Equity and Predictive Parity.\\\\n- <span id=\\\\\\\"page-17-3\\\\\\\"></span>[23] Tom Dobber, Ronan Ó Fathaigh, and Frederik Zuiderveen Borgesius. 2019. The regulation of online political micro-targeting in Europe. Internet Policy Review 8, 4 (2019).\\\\n- <span id=\\\\\\\"page-17-10\\\\\\\"></span>[24] Cory Doctorow. 2021. How to Destroy 'Surveillance Capitalism'. Medium Editions.\\\\n- <span id=\\\\\\\"page-17-8\\\\\\\"></span>[25] Paul Dourish and Genevieve Bell. 2011. Divining a Digital Future: Mess and Mythology in Ubiquitous Computing. MIT Press, Cambridge, Mass.\\\\n- <span id=\\\\\\\"page-17-4\\\\\\\"></span>[26] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. 2012. Fairness through awareness. Proceedings of the 3rd Innovations in Theoretical Computer Science Conference on - ITCS '12. <https://doi.org/10.1145/2090236.2090255>\\\\n- <span id=\\\\\\\"page-17-7\\\\\\\"></span>[27] M. C. Elish and danah boyd. 2017. Situating methods in the magic of Big Data and ai. Communication Monographs 85, 1 (2017), 57–80. [https://doi.org/10.1080/03637751.](https://doi.org/10.1080/03637751.2017.1375130) [2017.1375130](https://doi.org/10.1080/03637751.2017.1375130)\\\\n\\\\n- <span id=\\\\\\\"page-18-2\\\\\\\"></span>[28] Robert Epstein. 2019. Why Google Poses a Serious Threat to Democracy, and How to End That Threat. America Institute for Behavioral Research and Technology (2019).\\\\n- <span id=\\\\\\\"page-18-0\\\\\\\"></span>[29] Jessie Finocchiaro, Roland Maio, Faidra Monachou, Gourab K Patro, Manish Raghavan, Ana-Andreea Stoica, and Stratis Tsirtsis. 2021. Bridging Machine Learning and mechanism design towards Algorithmic Fairness. Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency. <https://doi.org/10.1145/3442188.3445912>\\\\n- <span id=\\\\\\\"page-18-11\\\\\\\"></span>[30] Ben Green and Yiling Chen. 2019. Disparate interactions: An algorithm-in-the-loop analysis of fairness in risk assessments. In Proceedings of the 2019 Conference on Fairness, Accountability, and Transparency. 90–99. <https://doi.org/10.1145/3287560.3287563>\\\\n- <span id=\\\\\\\"page-18-6\\\\\\\"></span>[31] Graham Greenleaf. 2021. The 'Brussels Effect' of the EU's 'AI Act' on Data Privacy Outside Europe. , 3-7 pages. <https://papers.ssrn.com/abstract=3898904>\\\\n- <span id=\\\\\\\"page-18-12\\\\\\\"></span>[32] Nina Grgić-Hlača, Elissa M Redmiles, Krishna P Gummadi, and Adrian Weller. 2018. Human perceptions of fairness in algorithmic decision making: A case study of criminal risk prediction. In Proceedings of the 2018 World Wide Web Conference - WWW '18. 903–912. [https:](https://doi.org/10.1145/3178876.3186138) [//doi.org/10.1145/3178876.3186138](https://doi.org/10.1145/3178876.3186138)\\\\n- <span id=\\\\\\\"page-18-8\\\\\\\"></span>[33] Nina Grgić-Hlača, Muhammad Bilal Zafar, Krishna P Gummadi, and Adrian Weller. 2018. Beyond distributive fairness in algorithmic decision making: Feature selection for procedurally fair learning. In Thirty-Second AAAI Conference on Artificial Intelligence. [https://ojs.](https://ojs.aaai.org/index.php/AAAI/article/view/11296) [aaai.org/index.php/AAAI/article/view/11296](https://ojs.aaai.org/index.php/AAAI/article/view/11296)\\\\n- <span id=\\\\\\\"page-18-9\\\\\\\"></span>[34] Ruocheng Guo, Lu Cheng, Jundong Li, P Richard Hahn, and Huan Liu. 2020. A survey of learning causality with data: Problems and methods. ACM Computing Surveys (CSUR) 53, 4 (2020), 1–37. <https://doi.org/10.1145/3397269>\\\\n- <span id=\\\\\\\"page-18-7\\\\\\\"></span>[35] Abhishek Gupta, Connor Wright, Marianna Bergamaschi Ganapini, Masa Sweidan, and Renjie Butalid. 2022. State of AI Ethics Report (Volume 6, February 2022). arXiv preprint arXiv:2202.07435 (2022).\\\\n- <span id=\\\\\\\"page-18-1\\\\\\\"></span>[36] Alisha Haridasani Gupta. 2019. Are Algorithms Sexist? The New York Times (2019).\\\\n- <span id=\\\\\\\"page-18-5\\\\\\\"></span>[37] Meeri Haataja and Joanna J. Bryson. 2021. What costs should we expect from the EU's AI Act? SocArXiv. Center for Open Science.\\\\n- <span id=\\\\\\\"page-18-4\\\\\\\"></span>[38] Philipp Hacker. 2018. Teaching fairness to artificial intelligence: Existing and novel strategies against algorithmic discrimination under EU law. Common Market Law Review 55, 4 (2018), 1143–1185. <https://doi.org/10.54648/cola2018095>\\\\n- <span id=\\\\\\\"page-18-3\\\\\\\"></span>[39] Bernard E. Harcourt. 2007. Against Prediction: Profiling, Policing, and Punishing in an Actuarial Age. University of Chicago Press. viii, 336 pages.\\\\n- <span id=\\\\\\\"page-18-10\\\\\\\"></span>[40] Moritz Hardt, Eric Price, and Nati Srebro. 2016. Equality of opportunity in supervised learning. In Advances in Neural Information Processing Systems, Vol. 29. 3315–3323. [https://](https://proceedings.neurips.cc/paper/2016/file/9d2682367c3935defcb1f9e247a97c0d-Paper.pdf) [proceedings.neurips.cc/paper/2016/file/9d2682367c3935defcb1f9e247a97c0d-Paper.](https://proceedings.neurips.cc/paper/2016/file/9d2682367c3935defcb1f9e247a97c0d-Paper.pdf) [pdf](https://proceedings.neurips.cc/paper/2016/file/9d2682367c3935defcb1f9e247a97c0d-Paper.pdf)\\\\n- <span id=\\\\\\\"page-18-13\\\\\\\"></span>[41] John C. Havens. 2018. Creating the human standard for ethical autonomous and intelligent systems (A/IS). AI Matters 4 (4 2018), 28–31. Issue 1. [https://doi.org/10.1145/3203247.](https://doi.org/10.1145/3203247.3203255) [3203255](https://doi.org/10.1145/3203247.3203255)\\\\n\\\\n- <span id=\\\\\\\"page-19-1\\\\\\\"></span>[42] Thomas T Hills. 2019. The Dark Side of Information Proliferation. Perspectives on Psychological Science 14 (2019), 323–330. <https://doi.org/10.1177/1745691618803647>\\\\n- <span id=\\\\\\\"page-19-5\\\\\\\"></span>[43] Anna Lauren Hoffmann. 2019. Where fairness fails: data, algorithms, and the limits of antidiscrimination discourse. 22, 7 (06 2019), 900–915. [https://doi.org/10.1080/1369118x.](https://doi.org/10.1080/1369118x.2019.1573912) [2019.1573912](https://doi.org/10.1080/1369118x.2019.1573912)\\\\n- <span id=\\\\\\\"page-19-7\\\\\\\"></span>[44] Kenneth Holstein, Jennifer Wortman Vaughan, Hal Daumé III, Miro Dudik, and Hanna Wallach. 2019. Improving fairness in machine learning systems: What do industry practitioners need?. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. 1–16. <https://doi.org/10.1145/3290605.3300830>\\\\n- <span id=\\\\\\\"page-19-13\\\\\\\"></span>[45] Brad Hooker. 2014. Utilitarianism and fairness. Cambridge University Press, 280–302.\\\\n- <span id=\\\\\\\"page-19-3\\\\\\\"></span>[46] Dietmar Hübner. 2021. Two kinds of discrimination in AI-based penal decision-making. ACM SIGKDD Explorations Newsletter 23, 1 (2021), 4–13. [https://doi.org/10.1145/3468507.](https://doi.org/10.1145/3468507.3468510) [3468510](https://doi.org/10.1145/3468507.3468510)\\\\n- <span id=\\\\\\\"page-19-8\\\\\\\"></span>[47] Javier Camacho Ibáñez and Mónica Villas Olmeda. 2021. Operationalising AI ethics: How are companies bridging the gap between practice and principles? An exploratory study. (08 2021). <https://doi.org/10.1007/s00146-021-01267-0>\\\\n- <span id=\\\\\\\"page-19-4\\\\\\\"></span>[48] Information Commissioner's Office (ICO). 2021. Guide to the General Data Protection Regulation (GDPR). [https://ico.org.uk/for-organisations/guide-to-data-protection/](https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/) [guide-to-the-general-data-protection-regulation-gdpr/](https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/)\\\\n- <span id=\\\\\\\"page-19-9\\\\\\\"></span>[49] Shelly Kagan. 2018. Normative ethics. Routledge.\\\\n- <span id=\\\\\\\"page-19-11\\\\\\\"></span>[50] Mamoru Kaneko and Kenjiro Nakamura. 1979. The Nash Social Welfare function. Econometrica: Journal of the Econometric Society 47, 2 (1979), 423–435. [https://doi.org/10.2307/](https://doi.org/10.2307/1914191) [1914191](https://doi.org/10.2307/1914191)\\\\n- <span id=\\\\\\\"page-19-10\\\\\\\"></span>[51] Simon Keller. 2009. Welfarism. Philosophy Compass 4, 1 (2009), 82–95. [https://doi.org/](https://doi.org/10.1111/j.1747-9991.2008.00196.x) [10.1111/j.1747-9991.2008.00196.x](https://doi.org/10.1111/j.1747-9991.2008.00196.x)\\\\n- <span id=\\\\\\\"page-19-0\\\\\\\"></span>[52] Jon Kleinberg, Sendhil Mullainathan, and Manish Raghavan. 2017. Inherent Trade-Offs in the Fair Determination of Risk Scores. In 8th Innovations in Theoretical Computer Science Conference (ITCS 2017). Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik, 1–23. [https:](https://doi.org/10.4230/LIPIcs.ITCS.2017.43) [//doi.org/10.4230/LIPIcs.ITCS.2017.43](https://doi.org/10.4230/LIPIcs.ITCS.2017.43)\\\\n- <span id=\\\\\\\"page-19-12\\\\\\\"></span>[53] Ansgar Koene, Adam Leon Smith, Takashi Egawa, Sukanya Mandalh, and Yohko Hatada. 2018. IEEE P70xx, Establishing Standards for Ethical Technology. Proceedings of KDD, ExCeL London UK (8 2018), 1–2.\\\\n- <span id=\\\\\\\"page-19-6\\\\\\\"></span>[54] P. M. Krafft, Meg Young, Michael Katell, Karen Huang, and Ghislain Bugingo. 2019. Defining AI in Policy versus Practice. <https://papers.ssrn.com/abstract=3431304>\\\\n- <span id=\\\\\\\"page-19-2\\\\\\\"></span>[55] Matt J Kusner, Joshua Loftus, Chris Russell, and Ricardo Silva. 2017. Counterfactual fairness. In Advances in Neural Information Processing Systems, Vol. 30. 4066–4076. [https://](https://proceedings.neurips.cc/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf) [proceedings.neurips.cc/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.](https://proceedings.neurips.cc/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf) [pdf](https://proceedings.neurips.cc/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf)\\\\n\\\\n- <span id=\\\\\\\"page-20-1\\\\\\\"></span>[56] Anja Lambrecht and Catherine Tucker. 2019. Algorithmic bias? an empirical study of apparent gender-based discrimination in the display of STEM career ads. Management Science 65, 7 (2019), 2966–2981. <https://doi.org/10.1287/mnsc.2018.3093>\\\\n- <span id=\\\\\\\"page-20-11\\\\\\\"></span>[57] Moritz Laurer, Andrea Renda, and Timothy Yeung. 2021. Clarifying the costs for the EU's AI Act. Technical Report.\\\\n- <span id=\\\\\\\"page-20-13\\\\\\\"></span>[58] Richard Layard and Stephen Gllaister. 1994. Cost-benefit analysis. Cambridge University Press, Cambridge, UK.\\\\n- <span id=\\\\\\\"page-20-6\\\\\\\"></span>[59] Michelle Seng Ah Lee and Jatinder Singh. 2021. The landscape and gaps in open source fairness toolkits. Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. <https://doi.org/10.1145/3411764.3445261>\\\\n- <span id=\\\\\\\"page-20-9\\\\\\\"></span>[60] Mark MacCarthy and Kenneth Propp. 2021. Machines learn that Brussels writes the rules: The EU's new AI regulation. Brookings, May 4 (2021), 2021.\\\\n- <span id=\\\\\\\"page-20-8\\\\\\\"></span>[61] Michael A. Madaio, Luke Stark, Jennifer Wortman Vaughan, and Hanna Wallach. 2020. Co-Designing Checklists to Understand Organizational Challenges and Opportunities around Fairness in AI. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1–14. <https://doi.org/10.1145/3313831.3376445>\\\\n- <span id=\\\\\\\"page-20-3\\\\\\\"></span>[62] Karima Makhlouf, Sami Zhioua, and Catuscia Palamidessi. 2021. On the applicability of machine learning fairness notions. ACM SIGKDD Explorations Newsletter 23, 1 (2021), 14– 23. <https://doi.org/10.1145/3468507.3468511>\\\\n- <span id=\\\\\\\"page-20-0\\\\\\\"></span>[63] Karl Manheim and Lyric Kaplan. 2019. Artificial intelligence: Risks to privacy and democracy. Yale JL & Tech. 21 (2019), 106. <https://ssrn.com/abstract=3273016>\\\\n- <span id=\\\\\\\"page-20-10\\\\\\\"></span>[64] Ian Manners. 2002. Normative Power Europe: A Contradiction in Terms? 40, 2 (06 2002), 235–258.\\\\n- <span id=\\\\\\\"page-20-5\\\\\\\"></span>[65] Mark McFadden, Kate Jones, Emily Taylor, and Georgia Osborn. 2021. Harmonising Artificial Intelligence: The Role of Standards in the EU AI Regulation. (2021).\\\\n- <span id=\\\\\\\"page-20-4\\\\\\\"></span>[66] Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. 2021. A Survey on Bias and Fairness in Machine Learning. ACM Comput. Surv. 54, 6, Article 115 (jul 2021), 35 pages. <https://doi-org.ezbusc.usc.gal/10.1145/3457607>\\\\n- <span id=\\\\\\\"page-20-12\\\\\\\"></span>[67] Milagros Miceli, Martin Schuessler, and Tianling Yang. 2020. Between Subjectivity and Imposition: Power Dynamics in Data Annotation for Computer Vision. Proceedings of the ACM on Human-Computer Interaction 4, CSCW2 (Oct. 2020), 1–25. [https://doi.org/10.1145/](https://doi.org/10.1145/3415186) [3415186](https://doi.org/10.1145/3415186)\\\\n- <span id=\\\\\\\"page-20-2\\\\\\\"></span>[68] Shira Mitchell, Eric Potash, Solon Barocas, Alexander D'Amour, and Kristian Lum. 2021. Prediction-Based Decisions and Fairness: A Catalogue of Choices, Assumptions, and Definitions. 8, 1 (03 2021), 141–163. [https://doi.org/10.1146/](https://doi.org/10.1146/annurev-statistics-042720-125902) [annurev-statistics-042720-125902](https://doi.org/10.1146/annurev-statistics-042720-125902) arXiv:1811.07867\\\\n- <span id=\\\\\\\"page-20-7\\\\\\\"></span>[69] Brent Mittelstadt. 2019. Principles alone cannot guarantee ethical AI. Nature Machine Intelligence 1, 11 (11 2019), 501–507. <https://doi.org/10.1038/s42256-019-0114-4>\\\\n\\\\n- <span id=\\\\\\\"page-21-13\\\\\\\"></span>[70] Andrew Moore. 2013. Hedonism. Stanford University. [https://plato.stanford.edu/](https://plato.stanford.edu/entries/hedonism/) [entries/hedonism/](https://plato.stanford.edu/entries/hedonism/)\\\\n- <span id=\\\\\\\"page-21-8\\\\\\\"></span>[71] Jessica Morley, Anat Elhalal, Francesca Garcia, Libby Kinsey, Jakob Mökander, and Luciano Floridi. 2021. Ethics as a Service: A Pragmatic Operationalisation of AI Ethics. 31, 2 (2021), 239–256. <https://doi.org/10.1007/s11023-021-09563-w>\\\\n- <span id=\\\\\\\"page-21-10\\\\\\\"></span>[72] Benjamin Mueller. 2021. How Much Will the Artificial Intelligence Act Cost Europe? Technical Report. Center for Data Innovation.\\\\n- <span id=\\\\\\\"page-21-1\\\\\\\"></span>[73] Sendhil Mullainathan. 2018. Algorithmic fairness and the social welfare function. In Proceedings of the 2018 ACM Conference on Economics and Computation. 1–1. [https:](https://doi.org/10.1145/3219166.3219236) [//doi.org/10.1145/3219166.3219236](https://doi.org/10.1145/3219166.3219236)\\\\n- <span id=\\\\\\\"page-21-0\\\\\\\"></span>[74] Catelijne Muller. 2020. The Impact of Artificial Intelligence on Human Rights, Democracy and the Rule of Law. Technical Report. Council of Europe, Strasbourg.\\\\n- <span id=\\\\\\\"page-21-12\\\\\\\"></span>[75] Helen Nissenbaum. 2009. Privacy in Context: Technology, Policy, and the Integrity of Social Life. Stanford University Press. <https://doi.org/10.1515/9780804772891>\\\\n- <span id=\\\\\\\"page-21-7\\\\\\\"></span>[76] Eirini Ntoutsi et al. 2020. Bias in data-driven artificial intelligence systems—An introductory survey. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery 10 (5 2020). Issue 3. <https://doi.org/10.1002/widm.1356>\\\\n- <span id=\\\\\\\"page-21-6\\\\\\\"></span>[77] Council of the European Union. 2000. Council Directive 2000/78/EC of 27 November 2000 establishing a general framework for equal treatment in employment and occupation.\\\\n- <span id=\\\\\\\"page-21-5\\\\\\\"></span>[78] Council of the European Union. 2000. Council Directive E 2000/43/EC of 29 June 2000 implementing the principle of equal treatment between persons irrespective of racial or ethnic origin.\\\\n- <span id=\\\\\\\"page-21-3\\\\\\\"></span>[79] Council of the European Union. 2004. Council Directive 2004/113/EC of 13 December 2004 implementing the principle of equal treatment between men and women in the access to and supply of goods and services.\\\\n- <span id=\\\\\\\"page-21-11\\\\\\\"></span>[80] Commission of the European Union. 2021. Communication from the Commission to the European Parliament, the Council, the European Economic and Social Committee and the Committee of the Regions 2013 Digital Compass: the European way for the Digital Decade.\\\\n- <span id=\\\\\\\"page-21-9\\\\\\\"></span>[81] Will Orr and Jenny L Davis. 2020. Attributions of ethical responsibility by Artificial Intelligence practitioners. Information, Communication & Society 23, 5 (2020), 719–735. <https://doi.org/10.1080/1369118x.2020.1713842>\\\\n- <span id=\\\\\\\"page-21-2\\\\\\\"></span>[82] European Parliament and Council. 2007. Charter of Fundamental Rights of the European Union.\\\\n- <span id=\\\\\\\"page-21-4\\\\\\\"></span>[83] European Parliament and Council of the European Union. 2006. Directive 2006/54/EC Of the European Parliament and of the Council of 5 July 2006 on the implementation of the principle of equal opportunities and equal treatment of men and women in matters of employment and occupation.\\\\n\\\\n- <span id=\\\\\\\"page-22-4\\\\\\\"></span>[84] European Parliament and Council of the European Union. 2016. Regulation (EU) 2016/679 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation).\\\\n- <span id=\\\\\\\"page-22-0\\\\\\\"></span>[85] European Parliament and Council of the European Union. 2021. Proposal for a Regulation of the European Parliament and of the Council laying down harmonised rules on Artificial Intelligence (Artificial Intelligence Act) and amending certain Union legislative acts.\\\\n- <span id=\\\\\\\"page-22-9\\\\\\\"></span>[86] Herbert James Paton. 1971. The categorical imperative: A study in Kant's moral philosophy. Vol. 1023. University of Pennsylvania Press.\\\\n- <span id=\\\\\\\"page-22-3\\\\\\\"></span>[87] Gourab K Patro, Arpita Biswas, Niloy Ganguly, Krishna P Gummadi, and Abhijnan Chakraborty. 2020. FairRec: Two-sided fairness for personalized recommendations in twosided platforms. In Proceedings of The Web Conference 2020. 1194–1204. [https://doi.org/](https://doi.org/10.1145/3366423.3380196) [10.1145/3366423.3380196](https://doi.org/10.1145/3366423.3380196)\\\\n- <span id=\\\\\\\"page-22-11\\\\\\\"></span>[88] Martin Pawelczyk, Sascha Bielawski, Johannes van den Heuvel, Tobias Richter, and Gjergji Kasneci. 2021. CARLA: A Python Library to Benchmark Algorithmic Recourse and Counterfactual Explanation Algorithms. In Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 2021.\\\\n- <span id=\\\\\\\"page-22-12\\\\\\\"></span>[89] Martin Pawelczyk, Klaus Broelemann, and Gjergji Kasneci. 2020. On Counterfactual Explanations under Predictive Multiplicity. In Proceedings of the Thirty-Sixth Conference on Uncertainty in Artificial Intelligence, UAI 2020 (Proceedings of Machine Learning Research, Vol. 124). AUAI Press, 809–818.\\\\n- <span id=\\\\\\\"page-22-8\\\\\\\"></span>[90] Seeta Peña Gangadharan and Jędrzej Niklas. 2019. Decentering Technology in Discourse on Discrimination. Information, Communication & Society 22, 7 (June 2019), 882–899. [https:](https://doi.org/10.1080/1369118X.2019.1593484) [//doi.org/10.1080/1369118X.2019.1593484](https://doi.org/10.1080/1369118X.2019.1593484)\\\\n- <span id=\\\\\\\"page-22-6\\\\\\\"></span>[91] Inioluwa Deborah Raji et al. 2020. Closing the AI accountability gap: Defining an end-to-end framework for internal algorithmic auditing. In Proceedings of the 2020 conference on fairness, accountability, and transparency. 33–44. <https://doi.org/10.1145/3351095.3372873>\\\\n- <span id=\\\\\\\"page-22-5\\\\\\\"></span>[92] Bogdana Rakova, Jingying Yang, Henriette Cramer, and Rumman Chowdhury. 2021. Where responsible AI meets reality: Practitioner perspectives on enablers for shifting organizational practices. Proceedings of the ACM on Human-Computer Interaction 5, CSCW1 (2021), 1–23. <https://doi.org/10.1145/3449081>\\\\n- <span id=\\\\\\\"page-22-10\\\\\\\"></span>[93] John Rawls. 2009. A theory of justice. Harvard University Press, Cambridge, Mass.\\\\n- <span id=\\\\\\\"page-22-1\\\\\\\"></span>[94] Richard M. Re and Alicia Solow-Niederman. 2019. Developing artificially intelligent justice. Stan. Tech. L. Rev. 22 (2019), 242. <https://ssrn.com/abstract=3390854>\\\\n- <span id=\\\\\\\"page-22-7\\\\\\\"></span>[95] Andrea Renda et al. 2021. Study to support an impact assessment of regulatory requirements for artificial intelligence in Europe. Technical Report. European Commission - Directorate-General for Communications Networks, Content and Technology.\\\\n- <span id=\\\\\\\"page-22-2\\\\\\\"></span>[96] Filipe N. Ribeiro et al. 2018. Media Bias Monitor : Quantifying Biases of Social Media News Outlets at Large-Scale. In Twelfth International AAAI Conference on Web and Social Media. AAAI Press, Palo Alto, California, 290–299. [https://aaai.org/ocs/index.php/ICWSM/](https://aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/view/17878) [ICWSM18/paper/view/17878](https://aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/view/17878)\\\\n\\\\n- <span id=\\\\\\\"page-23-7\\\\\\\"></span>[97] Brianna Richardson and Juan E. Gilbert. 2021. A Framework for Fairness: A Systematic Review of Existing Fair AI Solutions. (12 2021). arXiv:2112.05700 [http://arxiv.org/abs/](http://arxiv.org/abs/2112.05700) [2112.05700](http://arxiv.org/abs/2112.05700)\\\\n- <span id=\\\\\\\"page-23-5\\\\\\\"></span>[98] Boris Ruf and Marcin Detyniecki. 2021. Towards the Right Kind of Fairness in AI. (09 2021). arXiv:2102.08453 [cs] <http://arxiv.org/abs/2102.08453>\\\\n- <span id=\\\\\\\"page-23-2\\\\\\\"></span>[99] Ajay Sandhu and Peter Fussey. 2021. The 'uberization of policing'? How police negotiate and operationalise predictive policing technology. Policing and Society 31, 1 (2021), 66–81. <https://doi.org/10.1080/10439463.2020.1803315>\\\\n- <span id=\\\\\\\"page-23-1\\\\\\\"></span>[100] Cristian Santesteban and Shayne Longpre. 2020. How big data confers market power to Big Tech: Leveraging the perspective of data science. The Antitrust Bulletin 65, 3 (2020), 459–485. <https://doi.org/10.1177/0003603x20934212>\\\\n- <span id=\\\\\\\"page-23-0\\\\\\\"></span>[101] Laura Sartori and Andreas Theodorou. 2022. A sociotechnical perspective for the future of AI: narratives, inequalities, and human control. Ethics and Information Technology 24, 1 (2022), 1–11. <https://doi.org/10.1007/s10676-022-09624-3>\\\\n- <span id=\\\\\\\"page-23-8\\\\\\\"></span>[102] Daniel S. Schiff, Kelly Laas, Justin B. Biddle, and Jason Borenstein. 2022. Global AI Ethics Documents: What They Reveal About Motivations, Practices, and Policies. In Codes of Ethics and Ethical Guidelines: Emerging Technologies, Changing Fields. Springer International Publishing, 121–143. [https://doi.org/10.1007/978-3-030-86201-5\\\\\\\\\\\\\\\\_7](https://doi.org/10.1007/978-3-030-86201-5_7)\\\\n- <span id=\\\\\\\"page-23-6\\\\\\\"></span>[103] Andrew D. Selbst, danah boyd, Sorelle A. Friedler, Suresh Venkatasubramanian, and Janet Vertesi. 2019. Fairness and Abstraction in Sociotechnical Systems. In Proceedings of the Conference on Fairness, Accountability, and Transparency (Atlanta, GA, USA) (FAT\\\\\\\\* '19). Association for Computing Machinery, New York, NY, USA, 59–68. [https://doi.org/10.](https://doi.org/10.1145/3287560.3287598) [1145/3287560.3287598](https://doi.org/10.1145/3287560.3287598)\\\\n- <span id=\\\\\\\"page-23-10\\\\\\\"></span>[104] Amartya Sen. 1979. Utilitarianism and welfarism. The journal of Philosophy 76, 9 (1979), 463–489. <https://doi.org/10.2307/2025934>\\\\n- <span id=\\\\\\\"page-23-4\\\\\\\"></span>[105] Josh Simons and Dipayan Ghosh. 2022. Utilities for democracy: Why and how the Algorithmic Infrastructure of Facebook and Google must be regulated. [https://www.brookings.edu/research/](https://www.brookings.edu/research/utilities-for-democracy-why-and-how-the-algorithmic-infrastructure-of-facebook-and-google-must-be-regulated/) [utilities-for-democracy-why-and-how-the-algorithmic-infrastructure-of-facebook-and-google-must-be-regulated/](https://www.brookings.edu/research/utilities-for-democracy-why-and-how-the-algorithmic-infrastructure-of-facebook-and-google-must-be-regulated/)\\\\n- <span id=\\\\\\\"page-23-3\\\\\\\"></span>[106] Taylor Telford. 2019. Apple Card algorithm sparks gender bias allegations against Goldman Sachs. [https://www.washingtonpost.com/business/2019/11/11/](https://www.washingtonpost.com/business/2019/11/11/apple-card-algorithm-sparks-gender-bias-allegations-against-goldman-sachs/) [apple-card-algorithm-sparks-gender-bias-allegations-against-goldman-sachs/](https://www.washingtonpost.com/business/2019/11/11/apple-card-algorithm-sparks-gender-bias-allegations-against-goldman-sachs/)\\\\n- <span id=\\\\\\\"page-23-9\\\\\\\"></span>[107] Ehsan Toreini et al. 2020. The relationship between trust in AI and trustworthy machine learning technologies. In Proceedings of the 2020 conference on fairness, accountability, and transparency. 272–283. <https://doi.org/10.1145/3351095.3372834>\\\\n- <span id=\\\\\\\"page-23-11\\\\\\\"></span>[108] Antje Von Ungern-Sternberg et al. 2022. Discriminatory AI and the Law– Legal standards for algorithmic profiling. In The Cambridge Handbook of Responsible Artificial Intelligence: Interdisciplinary Perspectives (Cambridge Law Handbooks). Cambridge University Press. <https://ssrn.com/abstract=3876657>\\\\n\\\\n- <span id=\\\\\\\"page-24-6\\\\\\\"></span>[109] Michael Veale and Frederik Zuiderveen Borgesius. 2021. Demystifying the Draft EU Artificial Intelligence Act — Analysing the Good, the Bad, and the Unclear Elements of the Proposed Approach. Computer Law Review International 22, 4 (Aug. 2021), 97–112. [https://doi.](https://doi.org/doi:10.9785/cri-2021-220402) [org/doi:10.9785/cri-2021-220402](https://doi.org/doi:10.9785/cri-2021-220402)\\\\n- <span id=\\\\\\\"page-24-5\\\\\\\"></span>[110] Michael Veale, Max Van Kleek, and Reuben Binns. 2018. Fairness and accountability design needs for algorithmic support in high-stakes public sector decision-making. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. 1–14. [https://doi.](https://doi.org/10.1145/3173574.3174014) [org/10.1145/3173574.3174014](https://doi.org/10.1145/3173574.3174014)\\\\n- <span id=\\\\\\\"page-24-1\\\\\\\"></span>[111] Sahil Verma and Julia Rubin. 2018. Fairness Definitions Explained. In Proceedings of the International Workshop on Software Fairness (New York, NY, USA) (FairWare '18). Association for Computing Machinery, 1–7. <https://doi.org/10.1145/3194770.3194776>\\\\n- <span id=\\\\\\\"page-24-2\\\\\\\"></span>[112] Julius von Kügelgen, Amir-Hossein Karimi, Umang Bhatt, Isabel Valera, Adrian Weller, and Bernhard Schölkopf. 2021. On the Fairness of Causal Algorithmic Recourse. arXiv:2010.06529 [cs, stat] <http://arxiv.org/abs/2010.06529>\\\\n- <span id=\\\\\\\"page-24-3\\\\\\\"></span>[113] Raphaële Xenidis and Linda Senden. 2019. EU non-discrimination law in the era of artificial intelligence: Mapping the challenges of algorithmic discrimination. In Ulf Bernitz et al (eds), General Principles of EU law and the EU Digital Order. Kluwer Law International, 2020, 151–182. <https://ssrn.com/abstract=3529524>\\\\n- <span id=\\\\\\\"page-24-8\\\\\\\"></span>[114] Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rodriguez, and Krishna P Gummadi. 2017. Fairness beyond disparate treatment & disparate impact: Learning classification without disparate mistreatment. In Proceedings of the 26th international conference on world wide web. 1171–1180. <https://doi.org/10.1145/3038912.3052660>\\\\n- <span id=\\\\\\\"page-24-9\\\\\\\"></span>[115] Muhammad Bilal Zafar, Isabel Valera, Manuel Rodriguez, Krishna Gummadi, and Adrian Weller. 2017. From parity to preference-based notions of fairness in classification. In Advances in Neural Information Processing Systems. 229–239.\\\\n- <span id=\\\\\\\"page-24-0\\\\\\\"></span>[116] Aleš Završnik. 2020. Criminal justice, artificial intelligence systems, and human rights. In ERA Forum, Vol. 20. Springer, 567–583. <https://doi.org/10.1007/s12027-020-00602-0>\\\\n- <span id=\\\\\\\"page-24-7\\\\\\\"></span>[117] Shoshana Zuboff. 2019. Surveillance Capitalism and the Challenge of Collective Action. New Labor Forum 28, 1 (Jan. 2019), 10–29. <https://doi.org/10.1177/1095796018819461>\\\\n- <span id=\\\\\\\"page-24-4\\\\\\\"></span>[118] Frederik Zuiderveen Borgesius. 2018. Discrimination, artificial intelligence, and algorithmic decision-making. Technical Report. Strasbourg Council of Europe.\\\",\\n  \\\"metadata\\\": {\\n    \\\"file_name\\\": \\\"2207.01510.pdf\\\",\\n    \\\"file_size\\\": 579519,\\n    \\\"file_type\\\": \\\".pdf\\\",\\n    \\\"absolute_path\\\": \\\"/Users/joshchou/2207.01510.pdf\\\",\\n    \\\"page_count\\\": null,\\n    \\\"extracted_images\\\": [\\n      \\\"/Users/joshchou/extracted_media/2207.01510_page__page_11_Picture_0.jpeg_img_0.png\\\"\\n    ],\\n    \\\"extracted_media\\\": [\\n      {\\n        \\\"type\\\": \\\"image\\\",\\n        \\\"path\\\": \\\"/Users/joshchou/extracted_media/2207.01510_page__page_11_Picture_0.jpeg_img_0.png\\\",\\n        \\\"page\\\": \\\"_page_11_Picture_0.jpeg\\\",\\n        \\\"filename\\\": \\\"2207.01510_page__page_11_Picture_0.jpeg_img_0.png\\\"\\n      }\\n    ],\\n    \\\"output_format\\\": \\\"markdown\\\",\\n    \\\"extracted_text_file_path\\\": null\\n  }\\n}\"]",
          "info": {},
          "timestamp": "2025-09-25T16:22:50.302209",
          "success": true,
          "result": [
            {
              "tool_name": "mcp",
              "tool_call_id": "call_Ix453cSJgio8hn7XVzPpPAGN",
              "agent_name": "gaia_tracing_agent---uuid4453c8uuid",
              "action_name": "image__mcp_extract_text_ocr",
              "params": {
                "file_path": "/Users/joshchou/extracted_media/2207.01510_page__page_11_Picture_0.jpeg_img_0.png",
                "language": "eng",
                "preprocess": true
              },
              "policy_info": ""
            }
          ],
          "trace_data": {
            "execution_tree": {
              "code": "root",
              "contains_llm_call": true,
              "is_completed": false,
              "is_function_call": false,
              "function_name": null,
              "line_number_start": null,
              "line_number_end": null,
              "children": [
                {
                  "code": "result = Runners.sync_run_task(task=task)",
                  "contains_llm_call": true,
                  "is_completed": false,
                  "is_function_call": true,
                  "function_name": "sync_run_task",
                  "line_number_start": 1,
                  "line_number_end": 1,
                  "children": [
                    {
                      "code": "sync_run_task_execution_block",
                      "contains_llm_call": true,
                      "is_completed": false,
                      "is_function_call": false,
                      "function_name": "sync_run_task",
                      "line_number_start": 59,
                      "line_number_end": 60,
                      "children": []
                    }
                  ]
                }
              ]
            },
            "llm_calls": [
              {
                "function_name": "sync_run_task",
                "code": "result = Runners.sync_run_task(task=task)",
                "line_number": 1
              }
            ],
            "execution_flow": []
          }
        },
        {
          "agent_id": "gaia_tracing_agent---uuid4453c8uuid",
          "observation": "[\"{\\n  \\\"success\\\": true,\\n  \\\"message\\\": \\\"OCR Results for 2207.01510_page__page_11_Picture_0.jpeg_img_0.png:\\\\n\\\\n**Extracted Text:**\\\\nOCR failed: 'utf-8' codec can't decode byte 0x89 in position 270: invalid start byte\\\\n\\\\n**Statistics:**\\\\n- Words: 14\\\\n- Characters: 84\\\\n- Language: eng\\\\n- Processing time: 0.19s\\\",\\n  \\\"metadata\\\": {\\n    \\\"file_name\\\": \\\"2207.01510_page__page_11_Picture_0.jpeg_img_0.png\\\",\\n    \\\"file_size\\\": 87414,\\n    \\\"file_type\\\": \\\".png\\\",\\n    \\\"absolute_path\\\": \\\"/Users/joshchou/extracted_media/2207.01510_page__page_11_Picture_0.jpeg_img_0.png\\\",\\n    \\\"width\\\": 1018,\\n    \\\"height\\\": 590,\\n    \\\"mode\\\": \\\"RGB\\\",\\n    \\\"format\\\": \\\"PNG\\\",\\n    \\\"has_transparency\\\": false,\\n    \\\"output_files\\\": [],\\n    \\\"extracted_text\\\": \\\"OCR failed: 'utf-8' codec can't decode byte 0x89 in position 270: invalid start byte\\\",\\n    \\\"analysis_result\\\": null,\\n    \\\"compression_ratio\\\": null,\\n    \\\"output_format\\\": \\\"ocr_text\\\"\\n  }\\n}\"]",
          "info": {},
          "timestamp": "2025-09-25T16:23:02.761690",
          "success": true,
          "result": [
            {
              "tool_name": "mcp",
              "tool_call_id": "call_wMV9cZWZe6yIMxzzRmAThzeH",
              "agent_name": "gaia_tracing_agent---uuid4453c8uuid",
              "action_name": "search__mcp_search_google",
              "params": {
                "query": "arxiv Physics and Society August 11 2016",
                "num_results": 3,
                "safe_search": true,
                "language": "en",
                "output_format": "json"
              },
              "policy_info": "The OCR extraction from the figure in the AI regulation paper failed due to a decoding error. However, the text of the paper itself (Section 7, \"Mapping Perspectives\") describes the three axes and their label words:\n\n- **Axis 1:** Standardization vs. Localization\n- **Axis 2:** Utilitarianism vs. Egalitarianism\n- **Axis 3:** Consequential vs. Deontological\n\nSo, the six axis-end label words are:\n- Standardization\n- Localization\n- Utilitarianism\n- Egalitarianism\n- Consequential\n- Deontological\n\n### Next Step\n\nNow, I will search for the Physics and Society article submitted to arXiv.org on August 11, 2016, and identify which of these six words is used to describe a type of society in that article."
            }
          ],
          "trace_data": {
            "execution_tree": {
              "code": "root",
              "contains_llm_call": true,
              "is_completed": false,
              "is_function_call": false,
              "function_name": null,
              "line_number_start": null,
              "line_number_end": null,
              "children": [
                {
                  "code": "result = Runners.sync_run_task(task=task)",
                  "contains_llm_call": true,
                  "is_completed": false,
                  "is_function_call": true,
                  "function_name": "sync_run_task",
                  "line_number_start": 1,
                  "line_number_end": 1,
                  "children": [
                    {
                      "code": "sync_run_task_execution_block",
                      "contains_llm_call": true,
                      "is_completed": false,
                      "is_function_call": false,
                      "function_name": "sync_run_task",
                      "line_number_start": 59,
                      "line_number_end": 60,
                      "children": []
                    }
                  ]
                }
              ]
            },
            "llm_calls": [
              {
                "function_name": "sync_run_task",
                "code": "result = Runners.sync_run_task(task=task)",
                "line_number": 1
              }
            ],
            "execution_flow": []
          }
        },
        {
          "agent_id": "gaia_tracing_agent---uuid4453c8uuid",
          "observation": "[\"{\\n  \\\"success\\\": true,\\n  \\\"message\\\": {\\n    \\\"query\\\": \\\"arxiv Physics and Society August 11 2016\\\",\\n    \\\"results\\\": [\\n      {\\n        \\\"id\\\": \\\"google-0\\\",\\n        \\\"title\\\": \\\"Phase transition from egalitarian to hierarchical societies driven by ...\\\",\\n        \\\"url\\\": \\\"https://arxiv.org/abs/1608.03637\\\",\\n        \\\"snippet\\\": \\\"Physics > Physics and Society. arXiv:1608.03637 (physics). [Submitted on 11 Aug 2016]. Title:Phase transition from egalitarian to hierarchical societies ...\\\",\\n        \\\"source\\\": \\\"google\\\",\\n        \\\"display_link\\\": \\\"arxiv.org\\\",\\n        \\\"formatted_url\\\": \\\"https://arxiv.org/abs/1608.03637\\\"\\n      },\\n      {\\n        \\\"id\\\": \\\"google-1\\\",\\n        \\\"title\\\": \\\"GAIA: A Benchmark for General AI Assistants\\\",\\n        \\\"url\\\": \\\"https://ukgovernmentbeis.github.io/inspect_evals/evals/assistants/gaia/\\\",\\n        \\\"snippet\\\": \\\"Which of these words is used to describe a type of society in a Physics and Society article submitted to arXiv.org on August 11, 2016? Scoring. A simple mean ...\\\",\\n        \\\"source\\\": \\\"google\\\",\\n        \\\"display_link\\\": \\\"ukgovernmentbeis.github.io\\\",\\n        \\\"formatted_url\\\": \\\"https://ukgovernmentbeis.github.io/inspect_evals/evals/assistants/gaia/\\\"\\n      },\\n      {\\n        \\\"id\\\": \\\"google-2\\\",\\n        \\\"title\\\": \\\"Physics and Society\\\",\\n        \\\"url\\\": \\\"https://arxiv.org/list/physics.soc-ph/recent\\\",\\n        \\\"snippet\\\": \\\"Subjects: Physics and Society (physics.soc-ph); Social and Information Networks (cs.SI). [11] arXiv:2509.16217 [pdf, other]. Title: An objective criterion for ...\\\",\\n        \\\"source\\\": \\\"google\\\",\\n        \\\"display_link\\\": \\\"arxiv.org\\\",\\n        \\\"formatted_url\\\": \\\"https://arxiv.org/list/physics.soc-ph/recent\\\"\\n      }\\n    ],\\n    \\\"count\\\": 3\\n  },\\n  \\\"metadata\\\": {\\n    \\\"query\\\": \\\"arxiv Physics and Society August 11 2016\\\",\\n    \\\"search_engine\\\": \\\"google\\\",\\n    \\\"total_results\\\": 3,\\n    \\\"search_time\\\": 0.6385409832000732,\\n    \\\"language\\\": \\\"en\\\",\\n    \\\"country\\\": \\\"us\\\",\\n    \\\"safe_search\\\": true,\\n    \\\"error_type\\\": null,\\n    \\\"api_quota_used\\\": true\\n  }\\n}\"]",
          "info": {},
          "timestamp": "2025-09-25T16:23:12.022270",
          "success": true,
          "result": [
            {
              "tool_name": "mcp",
              "tool_call_id": "call_ojuEwAdiQYE1H5JWhahBXBUW",
              "agent_name": "gaia_tracing_agent---uuid4453c8uuid",
              "action_name": "pdf__mcp_extract_document_content",
              "params": {
                "file_path": "https://arxiv.org/pdf/1608.03637",
                "output_format": "markdown"
              },
              "policy_info": ""
            }
          ],
          "trace_data": {
            "execution_tree": {
              "code": "root",
              "contains_llm_call": true,
              "is_completed": false,
              "is_function_call": false,
              "function_name": null,
              "line_number_start": null,
              "line_number_end": null,
              "children": [
                {
                  "code": "result = Runners.sync_run_task(task=task)",
                  "contains_llm_call": true,
                  "is_completed": false,
                  "is_function_call": true,
                  "function_name": "sync_run_task",
                  "line_number_start": 1,
                  "line_number_end": 1,
                  "children": [
                    {
                      "code": "sync_run_task_execution_block",
                      "contains_llm_call": true,
                      "is_completed": false,
                      "is_function_call": false,
                      "function_name": "sync_run_task",
                      "line_number_start": 59,
                      "line_number_end": 60,
                      "children": []
                    }
                  ]
                }
              ]
            },
            "llm_calls": [
              {
                "function_name": "sync_run_task",
                "code": "result = Runners.sync_run_task(task=task)",
                "line_number": 1
              }
            ],
            "execution_flow": []
          }
        },
        {
          "agent_id": "gaia_tracing_agent---uuid4453c8uuid",
          "observation": "[\"{\\n  \\\"success\\\": false,\\n  \\\"message\\\": \\\"File not found: File not found: /Users/joshchou/https:/arxiv.org/pdf/1608.03637\\\",\\n  \\\"metadata\\\": {\\n    \\\"error_type\\\": \\\"file_not_found\\\"\\n  }\\n}\"]",
          "info": {},
          "timestamp": "2025-09-25T16:23:19.014844",
          "success": true,
          "result": [
            {
              "tool_name": "mcp",
              "tool_call_id": "call_qIyaU1zD70diWORoH1tpAiEv",
              "agent_name": "gaia_tracing_agent---uuid4453c8uuid",
              "action_name": "download__mcp_download_file",
              "params": {
                "url": "https://arxiv.org/pdf/1608.03637",
                "output_file_path": "1608.03637.pdf",
                "overwrite": true,
                "timeout": 60,
                "output_format": "json"
              },
              "policy_info": ""
            }
          ],
          "trace_data": {
            "execution_tree": {
              "code": "root",
              "contains_llm_call": true,
              "is_completed": false,
              "is_function_call": false,
              "function_name": null,
              "line_number_start": null,
              "line_number_end": null,
              "children": [
                {
                  "code": "result = Runners.sync_run_task(task=task)",
                  "contains_llm_call": true,
                  "is_completed": false,
                  "is_function_call": true,
                  "function_name": "sync_run_task",
                  "line_number_start": 1,
                  "line_number_end": 1,
                  "children": [
                    {
                      "code": "sync_run_task_execution_block",
                      "contains_llm_call": true,
                      "is_completed": false,
                      "is_function_call": false,
                      "function_name": "sync_run_task",
                      "line_number_start": 59,
                      "line_number_end": 60,
                      "children": []
                    }
                  ]
                }
              ]
            },
            "llm_calls": [
              {
                "function_name": "sync_run_task",
                "code": "result = Runners.sync_run_task(task=task)",
                "line_number": 1
              }
            ],
            "execution_flow": []
          }
        },
        {
          "agent_id": "gaia_tracing_agent---uuid4453c8uuid",
          "observation": "[\"{\\n  \\\"success\\\": true,\\n  \\\"message\\\": \\\"{\\\\n  \\\\\\\"url\\\\\\\": \\\\\\\"https://arxiv.org/pdf/1608.03637\\\\\\\",\\\\n  \\\\\\\"file_path\\\\\\\": \\\\\\\"/Users/joshchou/1608.03637.pdf\\\\\\\",\\\\n  \\\\\\\"success\\\\\\\": true,\\\\n  \\\\\\\"file_size\\\\\\\": 2558166,\\\\n  \\\\\\\"duration\\\\\\\": \\\\\\\"0:00:01.076019\\\\\\\",\\\\n  \\\\\\\"timestamp\\\\\\\": \\\\\\\"2025-09-25T16:23:24.809018\\\\\\\",\\\\n  \\\\\\\"error_message\\\\\\\": null\\\\n}\\\",\\n  \\\"metadata\\\": {\\n    \\\"url\\\": \\\"https://arxiv.org/pdf/1608.03637\\\",\\n    \\\"output_path\\\": \\\"/Users/joshchou/1608.03637.pdf\\\",\\n    \\\"timeout_seconds\\\": 60,\\n    \\\"overwrite_enabled\\\": true,\\n    \\\"execution_time\\\": 1.0786950588226318,\\n    \\\"file_size_bytes\\\": 2558166,\\n    \\\"content_type\\\": null,\\n    \\\"status_code\\\": null,\\n    \\\"error_type\\\": null,\\n    \\\"headers_used\\\": true\\n  }\\n}\"]",
          "info": {},
          "timestamp": "2025-09-25T16:23:27.511116",
          "success": true,
          "result": [
            {
              "tool_name": "mcp",
              "tool_call_id": "call_iFvVURAuiBrQe2HkIaAmA9zW",
              "agent_name": "gaia_tracing_agent---uuid4453c8uuid",
              "action_name": "pdf__mcp_extract_document_content",
              "params": {
                "file_path": "1608.03637.pdf",
                "output_format": "markdown"
              },
              "policy_info": ""
            }
          ],
          "trace_data": {
            "execution_tree": {
              "code": "root",
              "contains_llm_call": true,
              "is_completed": false,
              "is_function_call": false,
              "function_name": null,
              "line_number_start": null,
              "line_number_end": null,
              "children": [
                {
                  "code": "result = Runners.sync_run_task(task=task)",
                  "contains_llm_call": true,
                  "is_completed": false,
                  "is_function_call": true,
                  "function_name": "sync_run_task",
                  "line_number_start": 1,
                  "line_number_end": 1,
                  "children": [
                    {
                      "code": "sync_run_task_execution_block",
                      "contains_llm_call": true,
                      "is_completed": false,
                      "is_function_call": false,
                      "function_name": "sync_run_task",
                      "line_number_start": 59,
                      "line_number_end": 60,
                      "children": []
                    }
                  ]
                }
              ]
            },
            "llm_calls": [
              {
                "function_name": "sync_run_task",
                "code": "result = Runners.sync_run_task(task=task)",
                "line_number": 1
              }
            ],
            "execution_flow": []
          }
        },
        {
          "agent_id": "gaia_tracing_agent---uuid4453c8uuid",
          "observation": "[\"{\\n  \\\"success\\\": true,\\n  \\\"message\\\": \\\"# Phase transition from egalitarian to hierarchical societies driven by competition between cognitive and social constraints\\\\n\\\\nNestor Caticha[∗](#page-0-0) and Rafael Calsaverini[†](#page-0-1) Dept. de F´ısica Geral, Instituto de F´ısica, Universidade de S˜ao Paulo, 05508-090, S˜ao Paulo-SP, Brazil\\\\n\\\\nRenato Vicente[‡](#page-0-2)\\\\n\\\\nDept. Matem´atica Aplicada, Instituto de Matem´atica e Estat´ıstica, Universidade de S˜ao Paulo, 05508-090, S˜ao Paulo-SP, Brazil (Dated: July 9, 2018)\\\\n\\\\nEmpirical evidence suggests that social structure may have changed from hierarchical to egalitarian and back along the evolutionary line of humans. We model a society subject to competing cognitive and social navigation constraints. The theory predicts that the degree of hierarchy decreases with encephalization and increases with group size. Hence hominin groups may have been driven from a phase with hierarchical order to a phase with egalitarian structures by the encephalization during the last two million years, and back to hierarchical due to fast demographical changes during the Neolithic. The dynamics in the perceived social network shows evidence in the egalitarian phase of the observed phenomenon of Reverse Dominance. The theory also predicts for modern hunter-gatherers in mild climates a trend towards an intermediate hierarchy degree and a phase transition for harder ecological conditions. In harsher climates societies would tend to be more egalitarian if organized in small groups but more hierarchical if in large groups. The theoretical model permits organizing the available data in the cross-cultural record (Ethnographic Atlas, N=248 cultures) where the symmetry breaking transition can be clearly seen.\\\\n\\\\n# I. INTRODUCTION\\\\n\\\\nBehavioral phylogenetics makes it plausible that the common ancestor of Homo and Pan genera had a hierarchical social structure [\\\\\\\\[1–](#page-11-0)[5\\\\\\\\]](#page-11-1). Paleolithic humans with a foraging lifestyle, however, most likely had a largely egalitarian society and yet hierarchical structures became again common in the Neolithic period. Contemporary illiterate societies fill the ethological spectrum [\\\\\\\\[6\\\\\\\\]](#page-11-2) from egalitarian to authoritarian and despotic. This non-monotonic journey, a so called U-shaped trajectory, along the egalitarian-hierarchical spectrum during human evolution, was stressed by Knauft [\\\\\\\\[1\\\\\\\\]](#page-11-0) and has defied theory despite several attempts of anthropological explanation [\\\\\\\\[1\\\\\\\\]](#page-11-0). Our approach to the study of social organization uses tools of information theory and statistical mechanics. It is inspired in previous work by Terano et al. [\\\\\\\\[7,](#page-11-3) [8\\\\\\\\]](#page-11-4) on a different problem, the emergence of money in a barter society as a consequence of limited cognitive capacity. We model the perception by each agent of the social network of its society, taking into account cognitive constraints and social navigation demands, which define the informational constraints adequate to a probabilistic description. According to the model, whether an egalitarian-symmetric or hierarchical-broken symmetry state occurs depends on a scaling parameter which grows with cognitive capacity and decreases with group size, modulated by a Lagrange multiplier which can be interpreted as an environmental pressure. The hypothesis that social perceptions mediate motivations and hence possible behaviors (PMB hypothesis), permits making predictions about the effect of these variables in the probable forms of social organization. Since there was a massive increase in encephalic mass in the last\\\\n\\\\n<span id=\\\\\\\"page-0-0\\\\\\\"></span><sup>∗</sup>Electronic address: [nestor@if.usp.br](mailto:nestor@if.usp.br)\\\\n\\\\n<span id=\\\\\\\"page-0-1\\\\\\\"></span>†Electronic address: [rafael.calsaverini@gmail.com](mailto:rafael.calsaverini@gmail.com)\\\\n\\\\n<span id=\\\\\\\"page-0-2\\\\\\\"></span>‡Electronic address: [rvicente@usp.br](mailto:rvicente@usp.br)\\\\n\\\\ntwo million years, our theory expects a phase transition towards a more egalitarian social organization to occur. As food producing and storage methods permitted the populational increase in the Neolithic, the scaling parameter decrease permitted a reversal to hierarchical structures.\\\\n\\\\nFurthermore, the same model makes predictions about a totally different empirical situation, dealing with the influence of ecology on the expected hierarchy of modern human groups. The theory suggests a form of looking at the available ethnographic data [9, 10] and allows a new interpretation of observed patterns involving social structure, community size and environment in terms of a competition between cognitive constraints and social navigation demands and a symmetry breaking phase transition. The bifurcation suggested by the theory is seen in the ethnographic records. The empirical data can be found in the Murdock's Ethnographic Atlas [9], which resulted from the tour de force attempt to compile all ethnographic available knowledge that can be represented in a quantitative form.\\\\n\\\\nWe are studying the properties of finite size groups and so cannot take the thermodynamic limit. The changes in behavior are therefore not singular but we still find that the language of phase transitions is adequate, after all from a technical point of view the infinite size limit is a tool to simplify the mathematical treatment of very large systems.\\\\n\\\\n# II. THE THEORY AND THE MODEL\\\\n\\\\nIn a group of n agents, each agent of the group will have a perceived social web of interactions represented by a graph. An important distinction has to be made between the social network, that say an ethnographer might describe and the perceived social network of a particular agent. Each vertex of a graph stands for a represented agent of the group. In this representation of the social web, undirected edges joining any pair of vertices might be present or not. An edge links two represented agents if their social relation is known by the owner of the graph. Since inference depends on the available information, these graphs might differ from agent to agent. Call  $\\\\\\\\mathbf{S}^i$  the representation of the social web by agent i, given by a set  $\\\\\\\\{s_{jk}^i\\\\\\\\}$  of variables that can take values either zero or one. The indices i, j and k run from 1 to n and every  $s_{jk}^i$  is symmetric with respect to interchange of the lower indices. If  $s_{jk}^i = 1$  then agent i has knowledge of the social relation, the capacity to cooperate and form coalitions or the antagonism between agents j and k, while if  $s_{jk}^i = 0$  this relation is unknown to agent i. Known alliances, feuds or neutral interactions are represented by  $s_{jk}^i = 1$ . The total number of memorized social relations is\\\\n\\\\n$$N_{cog}^{i} = \\\\\\\\sum_{j,k=1}^{n} s_{jk}^{i}/2 \\\\\\\\tag{1}$$\\\\n\\\\nthe number of edges in the social web representation of agent i. This is a cognitive contribution to the cost of a given representation  $S^{i}$ .\\\\n\\\\nNow consider the agent i's social cost for not knowing a given social relationship, when  $s_{jk}^i = 0$ . For two agents j and k there is either a bond or a path of bonds, joining intervening agents, connecting them so that their social relation can be estimated by agent i. We will assume that the representation is a connected graph, what can be accomplished by defining the distance of two unconnected vertices to be infinite. It is reasonable to assume that this lack of direct knowledge will imply in a social cost which increases with the length of the shortest path between the agents. This implements the idea that relying on heuristics to infer the relationship between them (e.g., \\\\\\\"a friend of an enemy is an enemy\\\\\\\", etc.) is more amenable to errors as the number of intermediate agents grows.\\\\n\\\\nCall  $l_{ik}^i$  the social distance in the graph defined by the adjacency matrix  $\\\\\\\\mathbf{S}^i$ . The  $\\\\\\\\lambda$ -th power of  $\\\\\\\\mathbf{S}^i$ ,\\\\n\\\\n$$\\\\\\\\mathbf{M}^i(\\\\\\\\lambda) = [\\\\\\\\mathbf{S}^i]^\\\\\\\\lambda$$\\\\n\\\\npermits verifying whether there is a path joining two agents, and the social distance is\\\\n\\\\n$$l_{jk}^i = \\\\\\\\min \\\\\\\\lambda$$\\\\n, such that  $\\\\\\\\mathbf{M}^i(\\\\\\\\lambda)_{jk} > 0$ \\\\n\\\\n![](_page_2_Picture_1.jpeg)\\\\n\\\\n**FIG. 1.** Each agent has a perceived social web of interactions represented by a graph. Each vertex of a graph stands for a represented agent of the group. An edge in this perceived web links two agents if their social relation is known by the owner of the graph. Using the methods of information theory entropic inference, we attribute a probability  $P(\\\\\\\\mathbf{S}^i|I)$  that agent i perceives a network  $S^i$ , conditional on any available information I.\\\\n\\\\nis the length of the smallest path of bonds linking j and k. We take the social cost of agent i of having a representation  $S^i$  to be just the distance averaged over all pairs of agents\\\\n\\\\n$$\\\\\\\\bar{L}^i = \\\\\\\\frac{2}{n(n-1)} \\\\\\\\sum_{i,k=1}^n l^i_{jk}.$$\\\\n (2)\\\\n\\\\nThe joint cognitive-social cost of the representation is defined as a sum of monotonic functions of  $N_{cog}^i$  and  $\\\\\\\\bar{L}^i$  and the simplest form is just\\\\n\\\\n$$C_0(\\\\\\\\mathbf{S}^i) = N_{cog}^i + \\\\\\\\alpha \\\\\\\\bar{L}^i, \\\\\\\\tag{3}$$\\\\n\\\\nFor high  $\\\\\\\\alpha$ , optimization is obtained by decreasing  $\\\\\\\\bar{L}^i$  independently of  $N_e^i$ . For low  $\\\\\\\\alpha$  the number of edges  $N_{cog}^i$  has to be controlled, independently of  $\\\\\\\\bar{L}^i$ . Hence  $\\\\\\\\alpha$  is a parameter of the theory that measures the relative importance of the social and cognitive components and can be interpreted as a measure of the cognitive capacity of the agent.\\\\n\\\\nWe now attribute a probability  $P(\\\\\\\\mathbf{S}^i|I)$  that agent i perceives a network  $S^i = \\\\\\\\{s^i_{jk}\\\\\\\\}$ , conditional on any available information I, using the methods of information theory entropic inference. Call  $\\\\\\\\mathcal{C} = \\\\\\\\mathbb{E}(C_0)$  the expected value of  $C_0(\\\\\\\\mathbf{S}^i)$  under  $P(\\\\\\\\mathbf{S}^i|I)$ :\\\\n\\\\n$$C = IE(C_0) = \\\\\\\\sum_{\\\\\\\\mathbf{S}^i} C_0 P(\\\\\\\\mathbf{S}^i | I)$$\\\\n(4)\\\\n\\\\nSuppose that either C or equivalently the scale in which fluctuations of  $C_0(\\\\\\\\mathbf{S}^i)$  above its minimum are important, are known. Or possibly we just know that such knowledge would be useful, but we have no access to their specific values at present. The procedure calls for the maximization of the entropy (see e.g [11]) subject to the known constraints,\\\\n\\\\n$$P(\\\\\\\\mathbf{S}^{i}|I) = \\\\\\\\operatorname{argmax}_{P} \\\\\\\\left\\\\\\\\{ -\\\\\\\\sum_{\\\\\\\\mathbf{S}^{i}} P(\\\\\\\\mathbf{S}^{i}) \\\\\\\\log P(\\\\\\\\mathbf{S}^{i}) - \\\\\\\\lambda \\\\\\\\left[ \\\\\\\\sum_{\\\\\\\\mathbf{S}^{i}} P(\\\\\\\\mathbf{S}^{i}) - 1 \\\\\\\\right] - \\\\\\\\beta \\\\\\\\left[ \\\\\\\\sum_{\\\\\\\\mathbf{S}^{i}} P(\\\\\\\\mathbf{S}^{i}) C_{0}(\\\\\\\\mathbf{S}^{i}) - \\\\\\\\mathcal{C} \\\\\\\\right] \\\\\\\\right\\\\\\\\}$$\\\\n(5)\\\\n\\\\nThe result is the standard Boltzmann-Gibbs probability distribution\\\\n\\\\n<span id=\\\\\\\"page-3-0\\\\\\\"></span>\\\\n$$P(\\\\\\\\mathbf{S}^{i}|I) = \\\\\\\\frac{1}{Z}e^{-\\\\\\\\beta C_0(\\\\\\\\mathbf{S}^{i})},\\\\\\\\tag{6}$$\\\\n\\\\nwhere  $\\\\\\\\beta$  is the Lagrange multiplier conjugated variable to  $\\\\\\\\mathcal{C}$  and controls the scale in which the fluctuations are important. The information content in  $\\\\\\\\beta$  is equivalent to that in  $\\\\\\\\mathcal{C}$ . Low  $\\\\\\\\beta$  values means that  $\\\\\\\\mathbf{S}^i$  configurations of high joint cost will not be unlikely. For high  $\\\\\\\\beta$  only configurations near the ground state will be possible. We can interpret  $\\\\\\\\beta$  as an ecological pressure, possibly correlated to a measure of the effort to collect a minimum number of calories in one day. The normalization factor in equation 6, the partition function Z, depends on the number of agents,  $\\\\\\\\alpha$  and  $\\\\\\\\beta$ :  $Z = Z(n, \\\\\\\\alpha, \\\\\\\\beta)$ .\\\\n\\\\nIn order to characterize the state of the system we need appropriate order parameters. In particular we want to probe whether represented agents are considered symmetrically or if distinctions are made. It is useful to introduce the degree of vertex j in a graph  $\\\\\\\\mathbf{S}^i$ ,  $d^i_j = \\\\\\\\sum_k s^i_{jk}$ , the number of edges emerging from the vertex or in the case of the represented social web, the number of memorized social relations of an agent; as well as the maximum degree and the average\\\\n\\\\n$$d_{max}^i = \\\\\\\\max_j d_j^i, \\\\\\\\quad d_{avg}^i = \\\\\\\\frac{1}{n} \\\\\\\\sum_{j=1}^n d_j^i.$$\\\\n\\\\nNatural order parameters are the expectation values  $\\\\\\\\mathbb{E}(d_{max})$  and  $\\\\\\\\mathbb{E}(d_{avg})$  with respect to  $P(\\\\\\\\mathbf{S}^i|I)$ , the Boltzmann distribution in equation 6.\\\\n\\\\n#### III. METHODS\\\\n\\\\nSeveral techniques can be used to obtain estimates of the order parameters and here we present results obtained employing numerical Monte Carlo methods. We first considered isolated agents and the Monte Carlo simulation of the Boltzmann distribution (eq 6). Then we considered 2-body interactions of the n agents, exchanging information about other pairs of individuals, through a mechanism that can be called gossip. The effect of gossip is to generate highly correlated perceived social webs. The advantage of Monte Carlo methods is that a simple extension of the type of dynamics permits incorporating very simply interactions like gossip.\\\\n\\\\nWe now run the simulation for the n agents together. A parameter g (0 < g < 1) measures the intensity of information exchange through gossip. Choose an agent i and pair (j,k), independently of anything else, uniformly at random. With probability 1-g, a MC Metropolis update is performed on the bond of the pair (j,k). Let  $\\\\\\\\bar{s}^i_{jk} = 1 - s^i_{jk}$  be the complementary value of the bond variable  $s^i_{jk}$ . Also independently and uniformly at random, with probability g another agent is chosen, call it l. Its corresponding edge  $s^i_{jk}$  is copied to  $\\\\\\\\bar{s}^i_{jk}$ . Let  $\\\\\\\\bar{C}_0$  be the joint cognitive-social cost with the bond  $s^i_{jk}$  replaced by  $\\\\\\\\bar{s}^i_{jk}$ . With probability min  $\\\\\\\\left\\\\\\\\{\\\\\\\\exp(-\\\\\\\\beta(\\\\\\\\bar{C}_0-C_0)), 1\\\\\\\\right\\\\\\\\}$  let the change of  $s^i_{jk}$  by  $\\\\\\\\bar{s}^i_{jk}$  be accepted. Otherwise  $s^i_{jk}$  is kept fixed.\\\\n\\\\nThe step performed with probability 1-g simulates the update of the social web representation by independent observations, learning new relations and forgetting about previously known relations. The gossip step, done with probability g, simulates the exchange of information where agent l tells and agent i learns or forgets something about the relation of agents j and k. Gossip can be introduced by more elaborate schemes but this is sufficient for our modelling purposes.\\\\n\\\\nAfter all i=1,...N have been considered, a MC sweep has been completed. The  $\\\\\\\\alpha$  range  $4.5 \\\\\\\\le \\\\\\\\alpha \\\\\\\\le 90$  was divided uniformly into 100 intervals; the  $\\\\\\\\beta$  range  $0 < \\\\\\\\beta \\\\\\\\le 20$  was divided into 200 intervals. The values of n varied from 7 to 15. The number of degrees of freedom is  $n\\\\\\\\frac{n(n-1)}{2} = \\\\\\\\mathcal{O}(n^3)$ . We run a MC simulation for each fixed n and for each pair of  $\\\\\\\\alpha$  and  $\\\\\\\\beta$ . One to two million MC steps were made for thermalization, and then data about the order parameters was collected every 4 MC steps for around four million MCS. The results for the order parameters are shown in figures 2 and 3 are discussed below.\\\\n\\\\n![](_page_4_Figure_1.jpeg)\\\\n\\\\n<span id=\\\\\\\"page-4-0\\\\\\\"></span>FIG. 2. Top: Monte Carlo estimates of the maximum degree and the average degree  $(E(d_{avg})/(n-1))$  and  $E(d_{max})/(n-1)$  of the social web representation as a function of the specific cognitive capacity per dyadic relation  $z = 2\\\\\\\\alpha/n(n-1)$  for  $\\\\\\\\beta = 10$ . The shaded areas are bands at  $\\\\\\\\pm 1$  std from the Monte Carlo. Bottom: H = 2(1-D), with  $D = E(d_{avg})/E(d_{max})$ . Roughly three regimes can be seen: for very large z, H goes to zero (symmetric phase), all agents are equal. For very small z, H is  $\\\\\\\\approx 2$ , the broken symmetry phase, where a particular agent occupies the central position of the web. An intermediate z transition region shows intermediate values of H. All agents are statistically but not strictly equals, some occupy, but only temporarily, in the stochastic dynamics a more central position. The different curves are for different values of n(=10,11,...15), note the almost exact colapse when plotted as a function of z. The insets are typical realizations of the inferred web of social interactions by an agent at that z position. Bonds are only drawn if the bond variable is one.\\\\n\\\\nThe average length of the distances in a given graph  $S^i$  has to be measured in each Metropolis step. It was obtained using Dijkstra's algorithm to calculate every pair distance.\\\\n\\\\n# IV. RESULTS\\\\n\\\\n# A. Joint dependence on cognition and band size\\\\n\\\\nAn interesting result is that, given  $\\\\\\\\beta$ , to a good approximation the properties of the system do not depend separately on  $\\\\\\\\alpha$  and n but on the ratio  $z = \\\\\\\\frac{2\\\\\\\\alpha}{n(n-1)}$ , which can be thought of as a measure of the effective cognitive capacity per dyadic relation on a social landscape.\\\\n\\\\n![](_page_5_Figure_1.jpeg)\\\\n\\\\n<span id=\\\\\\\"page-5-0\\\\\\\"></span>**FIG. 3.** Left, Hierarchical-Egalitarian phase transition: phase diagram in the plane of specific cognitive capacity per dyadic relation  $z=\\\\\\\\frac{2\\\\\\\\alpha}{n(n-1)}$  and the inverse ecological pressure  $\\\\\\\\beta^{-1}$ . The color code represents a measure of the social hierarchy measure or symmetry breaking parameter  $H=2-2E(d_{avg})/E(d_{max})$ . The red region is where the symmetry is broken (H near 2) and the maximum degree  $E(d_{max})$  is much larger than the mean  $E(d_{avg})$ . The blue region is the unbroken symmetry phase,  $H\\\\\\\\approx 0$ . Right, same but for constant  $\\\\\\\\alpha$  in the  $\\\\\\\\log n, \\\\\\\\beta$  plane. The white lines divide the phase diagram into regions that can be used for the comparison to the Ethnographic Atlas data. The dark red region is where the symmetry is broken and the maximum degree is much larger than the mean. Dark blue is the symmetrical or egalitarian representation region.\\\\n\\\\n![](_page_5_Figure_3.jpeg)\\\\n\\\\n<span id=\\\\\\\"page-5-1\\\\\\\"></span>**FIG. 4.** The effect of gossip inside the hierarchical phase. Continuous curves: The entropy (essentially a measure of the width (eq. 7)) of the distribution of central agents decreases with the increase of gossip, meaning that there is a particular agent that preferentially occupies the centers of the stars. Dashed lines: Another way of seeing the same ordering: the frequency of the most frequent central agent in their representations.\\\\n\\\\nWe start by considering the case with no gossip g=0 where agents process information in a decoupled way. Larger g gives similar results for the individual web representations but they are no longer independent and correlations of the webs appear. Figure 2 shows the results of Monte Carlo estimates of the order parameters, the expected values of  $d_{max}$  and  $d_{avg}$ , respectively  $E(d_{avg})$  and  $E(d_{max})$ . These are plotted as a function of the scaling variable  $z = 2\\\\\\\\alpha/n(n-1)$ . In the bottom of figure 2 we show the hierarchical order parameter H = 2 - 2D as a function z for  $\\\\\\\\beta$  fixed, where  $D = E(d_{avg})/E(d_{max})$ . For\\\\n\\\\nH = 0 the typical graph is the totally symmetric graph, while for H = 2 the typical graph is the star. Since n is finite, H can't be 2. The maximum value is Hmax = 2(1 − 2/n + 1/n<sup>2</sup> ) ≈ 2. Three different regimes can be identified: low, intermediate and high H regions. In figure [3](#page-5-0) (left) we show H as a heat map in the z − β <sup>−</sup><sup>1</sup> plane. The three phases can be seen again. An intermediate fluid phase has the shape of a wedge that decreases in width as ecological pressure increases.\\\\n\\\\n# B. Gossip and shared perception\\\\n\\\\nFigure [4](#page-5-1) shows how frequent is the most frequent central agent as a function of the level of gossip g. Let P(c = j|i) be the probability that for the social web representation of agent i the central element is j. The spreading of the probability distribution can be measured by the ratio of its entropy to the maximum possible value\\\\n\\\\n<span id=\\\\\\\"page-6-0\\\\\\\"></span>\\\\n$$s_{cf} = \\\\\\\\frac{\\\\\\\\bar{S}}{\\\\\\\\log n} = \\\\\\\\frac{-1}{n \\\\\\\\log n} \\\\\\\\sum_{i,j=1}^{n} P(c=j|i) \\\\\\\\log P(c=j|i)$$\\\\n (7)\\\\n\\\\nThe results indicate that large correlation occurs when gossip dynamics dominates independent dynamics, starting around g ≈ 0.5.\\\\n\\\\n![](_page_6_Figure_6.jpeg)\\\\n\\\\n<span id=\\\\\\\"page-6-1\\\\\\\"></span>FIG. 5. The probability of acceptance of changes P(acc|zβ) from the Monte Carlo simulations measures the tolerance to changes in the social web representations. As a function of z, for different values of β (β = 2., 3. and 10) For high pressure, or harsher environments, (β = 10) changes that would permit upstarts to be different from other agents are not tolerated for large z. This is analogous to counter dominance behavior theory [\\\\\\\\[12\\\\\\\\]](#page-11-8). Changes of the central agent of the star topology are unlikely to be accepted for small z. For milder pressures changes are more easily accepted. Tolerance is measured by the Monte Carlo acceptance probability\\\\n\\\\nAgain we stress the hypothesis that the likelihood of an agent in tolerating inequalities is associated to the perceived inequalities of its social web representation. The three regimes will have strong influence in the possibilities of social organization of the group. In the region where H is close to zero, the interpretation is that no inequalities can be tolerated. These would represent large fluctuations on the cognitive-social cost and the combination of cognitive resources and band size given by z is large enough to permit a representation web given by a full graph.\\\\n\\\\nThe intermediate wedge region could be interpreted as the \\\\\\\"Big Man\\\\\\\" society, where some inequality is possible, but is not solidified and these temporarily more central figures can be though of as \\\\\\\"first among equals\\\\\\\" and their position is liable to changes. Since the wedge decreases for increasing pressure, for extreme ecological pressure, a Big Man organization is not possible. Either there is a stable central figure, e.g. a chief, or symmetry among members of the band.\\\\n\\\\nThe lower left hand part of figure 3 (left) is where the symmetry breakdown of the web representation permits the emergence of tolerance towards inequalities. The exchange of information about the social webs leads to the choice of an almost unique and stable central agent for all agents. This would allow the creation of a society where authority is stable and social egalitarianism is lost. In figure 5 we show the probability of a change in the cognitive representation webs as a function of z, measured by the Monte Carlo (Metropolis) acceptance rate. Only in the intermediate Big Man fluid region a significant rate of changes is acceptable. In both hierarchical and egalitarian phases, the dynamics turns out to be very conservative and change is rare, maintaining status quo for very long times. This prediction of the theory is in accordance to what is expected from anthropology's Reverse Dominance theory [12].\\\\n\\\\n#### C. Knauft's U-shape\\\\n\\\\n![](_page_7_Figure_5.jpeg)\\\\n\\\\n<span id=\\\\\\\"page-7-0\\\\\\\"></span>**FIG. 6.** Schematic (inverted-) U-shape trajectory for the specific cognitive capacity  $z \\\\\\\\propto 2\\\\\\\\alpha/n(n-1)$  as a function of time (thick curve). The higher the value of z, the more symmetrical or egalitarian the society will be. This is just a representation of externally caused changes in the cognitive capacity  $\\\\\\\\alpha(t)$  and the mean size of social groups n(t) as a function of time. The thin lines are the shadows projected onto the respective planes. The surface is  $z(\\\\\\\\alpha, n) \\\\\\\\propto \\\\\\\\frac{2\\\\\\\\alpha}{n(n-1)}$ . The contours are drawn for constant z values.\\\\n\\\\nThe fact that the phase diagram can be drawn using the combination z = 2α/n(n − 1) immediately suggests a scenario that accommodates the U-shape dynamics along the egalitarian-hierarchical spectrum. The schematic drawing in figure [6](#page-7-0) shows the curve z = z(α(t), n(t)) in a parametric representation using some rough measure of time as the parameter. We use a simple model of the growth of the cognitive capacity α in an evolutionary time scale and the fast increase in band sizes n in the transition to the neolithic. For viewing purposes only we use different time scales along the trajectory so that the shape is clearly a nice inverted U, otherwise it would be very skewed, since it takes around 7 million years to go up from hierarchical to egalitarian and few thousands years to go down back to hierarchical. It starts with low z around 7 Mya, in the hierarchical region of left hand side of the phase diagram of figure [3.](#page-5-0) It slowly grows, reaching a peak of z in an egalitarian region due to increased encephalization. Finally it goes back to the region of low z due to increase in band size, in the hierarchical phase of figure [3.](#page-5-0) Of course the specific details of such trajectory would depend on many other conditions, but this furnishes a plausible qualitative scenario for the evolution of z.\\\\n\\\\n# V. ETHNOGRAPHIC DATA AND THEORETICAL PREDICTIONS\\\\n\\\\n![](_page_8_Figure_3.jpeg)\\\\n\\\\nFIG. 7.\\\\n\\\\nCan a signature of this competition between cognitive and social navigation constraints be seen today for modern humans? A clear theoretical prediction about the dependence of social stratification on ecological pressure β and group size (z = z(n), α fixed) can be confronted to data from the ethnographic record. The prediction is divided into two parts. First, for very mild climates intermediate social structures are expected, but, as climates of increasing harshness are considered, different social organizations will occur. Second, this difference depends on group size. Cultures organized in small groups will be more egalitarian, those in large groups more hierarchical.\\\\n\\\\nUsing Murdock's Ethnographic Atlas ([\\\\\\\\[9\\\\\\\\]](#page-11-5)) we see in figure [8](#page-9-0) that this prediction is indeed borne out by\\\\n\\\\n![](_page_9_Figure_1.jpeg)\\\\n\\\\n<span id=\\\\\\\"page-9-0\\\\\\\"></span>FIG. 8. The bifurcation signature of the phase transition. For mild climates the expected hierarchies change little with group size. For harsh climates the expected hierarchy is larger for large groups and smaller for smaller groups. Top Left Ethnographic Atlas data. Top Right: theory. Bottom: The difference in expected hierarchy ∆H between large and small groups decreases for milder climates. Continuous line: EA data, Dashed line: theory. Harsh climates are Tundra (northern areas), Northern coniferous forest, High plateau steppe, Desert (including arctic). Mild: Temperate forest,Temperate grasslands, Mediterranean, Oases and certain restricted river valleys.\\\\n\\\\nthe data. These are not predictions about a specific group becoming more or less hierarchical as climate changes. These are predictions about the expectations we should have about hierarchical organization as different climates and group sizes are considered. Changes in a particular group would not be so easily observed, since the shift of perception of social webs will have an influence on motivations. See [\\\\\\\\[13\\\\\\\\]](#page-11-9) for a description of a system in the process of transition. How changing motivations lead to cultural changes and influence social organizations is outside the scope of the present theory.\\\\n\\\\nFrom the Ethnographic Atlas we extracted the relevant variables: data for social stratification h, climate c and group size s. Each variable range is divided into three regimes, low, intermediate and high (0, 1, 2 respectively, see [\\\\\\\\[14\\\\\\\\]](#page-11-10)). The number of cultures in [\\\\\\\\[9\\\\\\\\]](#page-11-5) with information on those three variables is 248. From the data we obtained the conditional probability P(h|cs) = P(hcs)/P(cs). The empirical expected hierarchy value Hemp = P h hP(h|cs) for each possible combination of climate and size, is shown in the left panel of Figure [8.](#page-9-0) The climate variables describe the type of environment but we need a quantitative description of the climate instead of just its name. We decided that a reasonable conversion could be done by using the idea of Net Primary Production [\\\\\\\\[15\\\\\\\\]](#page-11-11) which is a measure of the amount of calories per day that can be extracted from the environment and therefore correlates negatively to the ecological pressure β.\\\\n\\\\nTo obtain the analogous theoretical predictions, the same is done by dividing the range of theoretical parameters into three intervals as well and calculating the same quantity from the theoretical results, see figure [3](#page-5-0) (right). The theoretical expected value of Hthy = 2 − 2IE(davg)/IE(dmax) is shown in the right panel of Figure [8](#page-9-0) .\\\\n\\\\nThe qualitative agreement between theory and empirical record supports that our methodology is capable of suggesting new ways of looking at the available ethnographic records, which can now come under scrutiny by the community of quantitative ethnography dealing with cross-cultural studies.\\\\n\\\\nThe fact that inequality rises with group size and that there are ecological factors involved, has been previously considered [\\\\\\\\[5,](#page-11-1) [16–](#page-11-12)[20\\\\\\\\]](#page-11-13), but not how the rise is modulated by ecological pressure nor the hypothesis that this is due to the competition of cognitive and social navigation needs and therefore the influence of climatic pressure on hierarchy can be reversed by demographics. This papers are of a theoretical nature in the spirit of the social sciences. Mathematical attempts at modeling are typically absent and at most show the results of regressions between pairs of variables extracted from the ethnographic data.\\\\n\\\\n#### VI. DISCUSSION\\\\n\\\\nOur Statistical Mechanics approach, based on entropic inference through maximum entropy methods, is a methodological approach to the mathematical-physics modeling of systems that incorporates conditioning factors, in this case demographic, ecological, social and cognitive.\\\\n\\\\nOur main hypothesis is that a social-cognitive cost is relevant to characterize probabilistically the perceived social webs. The introduction of the conjugated parameter β, with the same informational content of the average cost is an unavoidable theoretical consequence. It controls the size of fluctuations above the minimum possible value of the cost, prompting its interpretation as a pressure. Gossip, a metaphor for information exchange, correlates the perceived webs. The cognitive capacity and the size of the group combine into a variable z, the specific cognitive capacity, and the perceived social state can be described in a space of just two dimensions (z, β). External to the model, the dynamics of encephalization and band size, determine the historical evolution of z leading to a scenario for non-monotonic hierarchical change [\\\\\\\\[1\\\\\\\\]](#page-11-0). Further changes in z could occur, e.g. due to technological advances which translate into more effective information processing and better social navigation. Also an effective reduction of ecological pressure, following enhanced productivity can occur. Then a more egalitarian perception of the social web will follow. The PMB hypothesis predicts that motivations and behaviors will change, but the theory does not go into the area of predicting how behaviors change, nor what institutions will emerge in order to permit such behaviors, nor the time scales of these changes. Our approach to the transition from hierarchical to egalitarian and back dispenses the issue of whether the hierarchical type of behavior lay dormant (Rodseth in [\\\\\\\\[1\\\\\\\\]](#page-11-0)) and remained present throughout the Pleistocene or whether the resurgence was due to convergent evolution (e.g. [\\\\\\\\[21\\\\\\\\]](#page-11-14)). It can be turned on or off by the joint effects of cognitive resources, social demands, ecology and demography. These transitions resemble the freezing or evaporation of water by changing pressure or temperature. The possibility of being solid ice is not dormant in water when it is heated up. At least that is not a useful metaphor.\\\\n\\\\nWe can speculate that the time spent in the large z egalitarian phase promoted conditions for the fixation of altruistic genes and the emergence of the \\\\\\\"do unto others\\\\\\\" ideas since all are equal under the representation web. It is hard to imagine the fixation of altruistic behavior which arises from punishment and collaboration [\\\\\\\\[22–](#page-11-15)[24\\\\\\\\]](#page-11-16) in other than the symmetric phase, but this should be amenable to model construction and analytic studies.\\\\n\\\\nThis simple model and the particular function we have used to represent the cognitive-social cost are far from complete. We don't claim specific numerical validation by confrontation with empirical data, in any other way than just a qualitative one. More sophisticated forms of coalitions, other than dyadic pairing, should lead to increased richness of the phase diagram, without disrupting the rough overall picture. We have also avoided considering gender issues. Rampant sexual inequalities can exist in an egalitarian organization of males. Nevertheless, if competition between cognitive constraints and social navigation needs indeed occur, then phase transitions from egalitarian to hierarchical perception follows from general arguments. It has been argued [\\\\\\\\[25\\\\\\\\]](#page-12-0) that \\\\\\\"in the history of the human species, there is no more significant transition than the emergence and institutionalization of inequality.\\\\\\\" We expect that these methods, which unify the theoretical analysis of the empirical facts behind the scenario for the Ushape dynamics and the conditions that influence the transformation of perception of social organization, will stimulate the use of information theory methods in the analysis of empirical research in cross-cultural studies.\\\\n\\\\nAcknowledgments: We thank Bruce Knauft for comments on a previous version of this paper and Helena L. Caticha for preparing Figure 1. This work was supported by Fapesp (2008/10830-2) and CNAIPS-USP.\\\\n\\\\n- <span id=\\\\\\\"page-11-0\\\\\\\"></span>[1] Bruce M. Knauft, Thomas S. Abler, Laura Betzig, Christopher Boehm, Robert Knox Dentan, Thomas M. Kiefer, Keith F. Otterbein, Tohn Paddock, and Lars Rodseth. Violence and sociality in human evolution [and comments and replies]. Current Anthropology, 32:391–428, 1991.\\\\n- [2] Christopher Boehm. Hierarchy in the Forest: The Evolution of Egalitarian Behavior. Harvard University Press, 1999.\\\\n- [3] Christopher Boehm. Ancestral hierarchy and conflict. Science, 336:844–847, 2012.\\\\n- [4] Benoit Dubreuil. Paleolithic public goods games: why human culture and cooperation did not evolve in one step. Biol Philos, 25:53–73, 2010.\\\\n- <span id=\\\\\\\"page-11-1\\\\\\\"></span>[5] Benoit Dubreuil. Human Evolution and the Origins of Hierarchies. Cambridge: Cambridge University Press, 2010.\\\\n- <span id=\\\\\\\"page-11-2\\\\\\\"></span>[6] SL Vehrencamp. A model for the evolution of despotic versus egalitarian societies. Animal Behaviour, 31:667–682, 1983.\\\\n- <span id=\\\\\\\"page-11-3\\\\\\\"></span>[7] Satoru Yamadera and Takao Terano. Examining the myth of money with agent-based modelling. In B. Edmonds, K. Troitzsch, and C. Hern´andez Iglesias, editors, Social Simulation: Technologies, Advances and New Discoveries, pages 252–263. Hershey, PA: Information Science Reference, 2008.\\\\n- <span id=\\\\\\\"page-11-4\\\\\\\"></span>[8] Masaaki Kunigami, Masato Kobayashi, Satoru Yamadera, and Takao Terano. On emergence of money in self-organizing doubly structural network model. In Takao Terano, Hajime Kita, Shingo Takahashi, and Hiroshi Deguchi, editors, Agent-Based Approaches in Economic and Social Complex Systems V, volume 6 of Springer Series on Agent Based Social Systems, pages 231–241. Springer Japan, 2009.\\\\n- <span id=\\\\\\\"page-11-5\\\\\\\"></span>[9] G. P. Murdock. Ethnographic atlas. University of Pittsburgh Press, Pittsburgh, PA, 1967.\\\\n- <span id=\\\\\\\"page-11-6\\\\\\\"></span>[10] George P Murdock and Douglas R. White. Standard cross-cultural sample: on-line edition. social dynamics and complexity. uc irvine: Social dynamics and complexity. Ethnology, http://escholarship.org/uc/item/62c5c02n, pages 329–269, 1969.\\\\n- <span id=\\\\\\\"page-11-7\\\\\\\"></span>[11] Ariel Caticha. Lectures on probability, entropy and statistical physics. arxiv:0808.0012 [physics.data-an].\\\\n- <span id=\\\\\\\"page-11-8\\\\\\\"></span>[12] C. Boehm. Egalitarian society and reverse dominance hierarchy. Current Anthropology, 34:227–254, 1993.\\\\n- <span id=\\\\\\\"page-11-9\\\\\\\"></span>[13] Polly Wiessner. The vines of complexity. Current Anthropology, 43(2):233–269, 2002.\\\\n- <span id=\\\\\\\"page-11-10\\\\\\\"></span>[14] Supplementary material.\\\\n- <span id=\\\\\\\"page-11-11\\\\\\\"></span>[15] R H Whittaker and P Stilling. Ecology: Theory and Applications. Prentice-Hall, 1996.\\\\n- <span id=\\\\\\\"page-11-12\\\\\\\"></span>[16] Robert L. Carneiro. On the relationship between size of population and complexity of social organization. Southwestern Journal Anthropology, 23:2–43, 1967.\\\\n- [17] P. Bingham. Human uniqueness: a general theory. Quarterly Review of Biology, 74:133–169, 1999.\\\\n- [18] Roland Fletcher. The Limits of Settlement Growth: A theoretical outline. Cambridge: Cambridge University Press, 2007.\\\\n- [19] Kyle Summers. The evolutionary ecology of despotism. Evolution and Human Behavior, 26(1):106–135, January 2005.\\\\n- <span id=\\\\\\\"page-11-13\\\\\\\"></span>[20] Lawrence H. Keeley. Hunter-gatherer economic complexity and population pressure: A cross-cultural analysis. Journal of Anthropological Archaeology, 7:373–411, 1988.\\\\n- <span id=\\\\\\\"page-11-14\\\\\\\"></span>[21] Daniel L Smail. On Deep History and the Brain. University of California Press, 2008.\\\\n- <span id=\\\\\\\"page-11-15\\\\\\\"></span>[22] R. Boyd and P. J. Richerson. The evolution of reciprocity in sizable groups. J Theor Biol, 132:337–356, 1988.\\\\n- [23] Robert Boyd, Herbert Gintis, and Samuel Bowles. Coordinated punishment of defectors sustains cooperation and can proliferate when rare. Science, 328:617–620, 2010.\\\\n- <span id=\\\\\\\"page-11-16\\\\\\\"></span>[24] Roberto H. Schonmann, Renato Vicente, and Nestor Caticha. Altruism can proliferate through population\\\\n\\\\nviscosity despite high random gene flow. PLoS ONE, 8(8):e72043, 08 2013.\\\\n\\\\n<span id=\\\\\\\"page-12-0\\\\\\\"></span>[25] G. M. Feinman. The emergence of inequality. In T. Douglas Price and G. M. Feinman, editors, Foundations of social inequality, pages 255–279. Plenum Press, 1995.\\\\n\\\\n#### I. APPENDIX\\\\n\\\\n# A. Theory: Conditional Probabilities and order parameters\\\\n\\\\nThe phase diagram in the  $\\\\\\\\beta-z$  is shown right figure in panel 3. We divided the ranges of  $\\\\\\\\beta$  and z into three regions each: harsh, intermediate and mild climates and small medium and large groups respectively. The phase diagram is thus divided into 9 regions. The regions are chosen essentially so that all points in the  $\\\\\\\\beta-z$  space in the harsh-large region are of the same color (blue). The same is done for the region of harsh-small (all red) and for mild-small and mild-large. The white lines show a reasonable choice of what is meant by large, intermediate and small both for  $\\\\\\\\beta$  and n. A reasonable choice for the values separating the three regions are  $\\\\\\\\beta_{HI}^{-1}=0.15$  and  $\\\\\\\\beta_{IM}^{-1}=0.35$ . For  $\\\\\\\\beta^{-1}>\\\\\\\\beta_{IM}^{-1}$ , climate c is mild. For  $\\\\\\\\beta_{HI}^{-1}<\\\\\\\\beta^{-1}<\\\\\\\\beta_{IM}^{-1}$ , climate c is intermediate, and  $\\\\\\\\beta^{-1}<\\\\\\\\beta_{HI}^{-1}$ , c is harsh. For  $z=\\\\\\\\frac{2\\\\\\\\alpha}{n(n-1)}$  the borders are set at  $z_2=0.6$  and  $z_1=1.4$  For  $z>z>z_1$ , z=1 small. For\\\\n\\\\nFor  $z = \\\\\\\\frac{2\\\\\\\\alpha}{n(n-1)}$  the borders are set at  $z_2 = 0.6$  and  $z_1 = 1.4$  For  $2 > z > z_1$ , s = 1 small. For  $z_2 > z > z_1$ , s = 2 intermediate. For  $0 < z < z_2$ , s = 3 large. Then we consider the order parameter D(s,c)\\\\n\\\\n$$\\\\\\\\bar{D}(s,c) = \\\\\\\\frac{\\\\\\\\int_{\\\\\\\\beta \\\\\\\\in c} \\\\\\\\int_{z \\\\\\\\in s} Ddz d\\\\\\\\beta}{\\\\\\\\int_{\\\\\\\\beta \\\\\\\\in c} \\\\\\\\int_{z \\\\\\\\in s} dz d\\\\\\\\beta},\\\\\\\\tag{1}$$\\\\n\\\\nwhere  $D = \\\\\\\\frac{E(d_{avg})}{E(d_{max})}$  and the theoretical hierarchical order parameter that can be compared to the data is  $H_{thy} = 2 - 2\\\\\\\\overline{D}(s, c)$ .\\\\n\\\\n#### B. Data: Source\\\\n\\\\nData was obtained from [9], the Ethnographic Atlas (EA) \\\\\\\"a database on 1167 societies coded by George P. Murdock and published in 29 successive installments in the journal ETHNOLOGY, 1962-1980\\\\\\\", available for download from the site of Douglas R. White\\\\n\\\\nhttp://eclectic.ss.uci.edu/ drwhite/worldcul/world.htm\\\\n\\\\nWe used the file EthnographicAtlasWCRevisedByWorldCultures.sav\\\\n\\\\nThe relevant variables for our study are s, h and c, which stand for size category, hierarchy category and climate category. All variables can take integer values 1, 2 or 3. They are obtained by grouping the EA variables into three groups:\\\\n\\\\n| $\\\\\\\\downarrow$ Category, Value $\\\\\\\\rightarrow$ | 1           | 2                | 3       |\\\\n|--------------------------------------------|-------------|------------------|---------|\\\\n| s: group size (v31)                        | small       | medium           | large   |\\\\n| h: social stratification (v66)             | Egalitarian | Simple structure | Complex |\\\\n| c: Climate (v95)                           | Harsh       | Intermediate     | Mild    |\\\\n\\\\n**TABLE I.** EA variables and categories\\\\n\\\\n#### C. Data: Conditional Probabilities and order parameters\\\\n\\\\nThis values are obtained by grouping the relevant variables of the EA according to tables 1-3SM below, into three categories. The results are presented in table 4SM below. We extract the numbers of cultures\\\\n\\\\n|                         |   |              | Number of cultures in Number of cultures in Number of cultures in |              |\\\\n|-------------------------|---|--------------|-------------------------------------------------------------------|--------------|\\\\n| ↓Stratification Climate |   | Small groups | Medium groups                                                     | Large groups |\\\\n| 1                       | 1 | 12           | 1                                                                 | 0            |\\\\n| 1                       | 2 | 43           | 40                                                                | 2            |\\\\n| 1                       | 3 | 4            | 3                                                                 | 0            |\\\\n| 2                       | 1 | 7            | 5                                                                 | 0            |\\\\n| 2                       | 2 | 11           | 25                                                                | 3            |\\\\n| 2                       | 3 | 4            | 3                                                                 | 6            |\\\\n| 3                       | 1 | 0            | 1                                                                 | 3            |\\\\n| 3                       | 2 | 8            | 23                                                                | 31           |\\\\n| 3                       | 3 | 2            | 6                                                                 | 5            |\\\\n\\\\nTABLE II. Number of Cultures in the different categories in the EA.\\\\n\\\\nN(s, h, c) with a given set of values (s, h, c) and the marginal numbers N(s, c) of cultures with a given pair of values of (s, c) independently of h. These are related by N(s, c) = P <sup>h</sup>=1,2,<sup>3</sup> N(s, h, c). The conditional probabilities are\\\\n\\\\n$$P(h|sc) = \\\\\\\\frac{N(s, h, c)}{N(s, c)},\\\\\\\\tag{2}$$\\\\n\\\\nof a culture having a given class stratification , given its climate and group size.\\\\n\\\\nThen we calculate the average hierarchy of the cultures with the same values of n and c, that is, that belong to the same size and climate categories. We calculate the empirical average hierarchies conditional on size and climate\\\\n\\\\n$$\\\\\\\\bar{H} = I\\\\\\\\!\\\\\\\\!E(h-1|sc) = \\\\\\\\sum_{h=1,2,3} (h-1)P(h|sc), \\\\\\\\tag{3}$$\\\\n\\\\nwhich satisfies 0 ≤ H¯ ≤ 2.\\\\n\\\\nFluctuations around the average\\\\n\\\\n$$\\\\\\\\sigma_{EA}^2 = I\\\\\\\\!\\\\\\\\!E((h - \\\\\\\\bar{h})^2 | nc) = \\\\\\\\sum_{h=1,2,3} (h - \\\\\\\\bar{h})^2 P(h | nc), \\\\\\\\tag{4}$$\\\\n\\\\ncan be calculated to define error bars.\\\\n\\\\n#### D. Numerical results\\\\n\\\\n| ↓Climate, Group size → Small Medium Large groups |     |      |      |\\\\n|--------------------------------------------------|-----|------|------|\\\\n| Harsh                                            | .37 | 1.   | 2.   |\\\\n| Intermediate                                     | .44 | .81  | 1.81 |\\\\n| Mild                                             | .80 | 1.25 | 1.45 |\\\\n\\\\nTABLE III. The results for the empirical stratification H¯\\\\n\\\\n| ↓Climate, Group size → Small Medium Large groups |     |     |      |\\\\n|--------------------------------------------------|-----|-----|------|\\\\n| Harsh                                            | .01 | .64 | 1.58 |\\\\n| Intermediate                                     | .13 | .56 | 1.25 |\\\\n| Mild                                             | .39 | .58 | .77  |\\\\n\\\\nTABLE IV. The results for the theoretical prediction H<sup>T</sup>\\\\n\\\\n#### E. Ethnographic data\\\\n\\\\n|       | N Code | Description v31.                          | Size category |\\\\n|-------|--------|-------------------------------------------|---------------|\\\\n| 681 0 |        | Missing data (code .)                     | 0             |\\\\n| 118 1 |        | Fewer than 50                             | 1             |\\\\n| 107 2 |        | 50-99                                     | 1             |\\\\n| 104 3 |        | 100-199                                   | 2             |\\\\n| 83 4  |        | 200-399                                   | 2             |\\\\n| 60 5  |        | 400-1000                                  | 2             |\\\\n| 16 6  |        | 1,000 without any town of more than 5,000 | 3             |\\\\n| 36 7  |        | Towns of 5,000-50,000 (one or more)       | 3             |\\\\n| 62 8  |        | Cities of more than 50,000 (one or more)  | 3             |\\\\n\\\\nTABLE V. Variable v31 of the Ethnographic Atlas: Mean Size of Local Communities.\\\\n\\\\n|       | N Code | Description v66.                                        | Hierarchy category |\\\\n|-------|--------|---------------------------------------------------------|--------------------|\\\\n| 182 0 |        | Missing data (code .)                                   | 0                  |\\\\n| 533 1 |        | Absence among freemen (O.)                              | 1                  |\\\\n| 206 2 |        | Wealth distinctions (W.)                                | 2                  |\\\\n| 39 3  |        | Elite (based on control of land or other resources (E.) | 2                  |\\\\n| 228 4 |        | Dual (hereditary aristocracy) (D.)                      | 3                  |\\\\n| 79 5  |        | Complex (social classes) (C.)                           | 3                  |\\\\n\\\\nTABLE VI. Variable v66 of the Ethnographic Atlas: Class Stratification.\\\\n\\\\n|        | N Code | Description v95.                                      | Climate category |\\\\n|--------|--------|-------------------------------------------------------|------------------|\\\\n| 869 0  |        | Not coded                                             | 0                |\\\\n|        | 3 51   | Desert (including arctic)                             | 1                |\\\\n|        | 11 23  | Tundra (northern areas)                               | 1                |\\\\n|        | 21 36  | Northern coniferous forest                            | 1                |\\\\n|        | 8 44   | High plateau steppe                                   | 1                |\\\\n|        | 5 65   | Oases and certain restricted river valleys            | 1                |\\\\n|        | 37 52  | Desert grasses and shrubs                             | 2                |\\\\n|        | 16 56  | Temperate woodland                                    | 2                |\\\\n|        | 24 74  | Sub-tropical bush                                     | 2                |\\\\n|        | 27 78  | Sub-tropical rain forest                              | 2                |\\\\n|        | 64 84  | Tropical grassland                                    | 2                |\\\\n|        | 14 87  | Monsoon forest                                        | 2                |\\\\n| 113 88 |        | Tropical rain forest                                  | 2                |\\\\n|        | 25 54  | Temperate grasslands                                  | 3                |\\\\n|        | 19 46  | Temperate forest (mostly mountainous)                 | 3                |\\\\n|        | 11 55  | Mediterranean (dry, deciduous, and evergreen forests) | 3                |\\\\n\\\\nTABLE VII. v95 Climate: Primary Environment. Group 1 is formed by NPP up to 350gC/m2/year Group 2: between 350gC/m2/year and 600gC/m2/year. Group 3: large than 600gC/m2/year.\\\\n\\\\n#### F. Cultures: Size, Class Stratification , Climate\\\\n\\\\nTable 8 List of all cultures with available information in all three categories\\\\n\\\\n| Culture      |   | Size(v31) Stratification(v66) Climate(v95) |   |\\\\n|--------------|---|--------------------------------------------|---|\\\\n| 1 !KUNG      | 1 | 1                                          | 2 |\\\\n| 2 ILA        | 2 | 2                                          | 2 |\\\\n| 3 NYORO      | 2 | 3                                          | 2 |\\\\n| 4 AMBA       | 2 | 1                                          | 2 |\\\\n| 5 KPE        | 1 | 2                                          | 2 |\\\\n| 6 FON        | 3 | 3                                          | 2 |\\\\n| 7 KISSI      | 2 | 1                                          | 2 |\\\\n| 8 BAMBARA    | 3 | 3                                          | 2 |\\\\n| 9 YATENGA    | 3 | 3                                          | 2 |\\\\n| 10 KATAB     | 2 | 1                                          | 2 |\\\\n| 11 KONSO     | 3 | 2                                          | 3 |\\\\n| 12 SOMALI    | 1 | 2                                          | 2 |\\\\n| 13 WOLOF     | 3 | 3                                          | 2 |\\\\n| 14 TEDA      | 1 | 3                                          | 3 |\\\\n| 15 BARABRA   | 1 | 2                                          | 1 |\\\\n| 16 GHEG      | 2 | 1                                          | 1 |\\\\n| 17 NEWENGLAN | 3 | 3                                          | 2 |\\\\n| 18 DUTCH     | 3 | 3                                          | 2 |\\\\n| 19 SERBS     | 3 | 3                                          | 2 |\\\\n| 20 SYRIANS   | 3 | 2                                          | 3 |\\\\n| 21 SINDHI    | 3 | 2                                          | 2 |\\\\n| 22 KAZAK     | 1 | 3                                          | 3 |\\\\n| 23 GILYAK    | 1 | 1                                          | 1 |\\\\n| 24 YAKUT     | 1 | 2                                          | 1 |\\\\n| 25 KOREANS   | 3 | 3                                          | 2 |\\\\n| 26 LOLO      | 2 | 3                                          | 3 |\\\\n| 27 ABOR      | 2 | 2                                          | 2 |\\\\n| 28 CHENCHU   | 1 | 1                                          | 2 |\\\\n| 29 TAMIL     | 3 | 3                                          | 2 |\\\\n| 30 ANDAMANES | 1 | 1                                          | 2 |\\\\n| 31 MERINA    | 3 | 3                                          | 2 |\\\\n| 32 GARO      | 2 | 2                                          | 2 |\\\\n| 33 LAMET     | 1 | 2                                          | 2 |\\\\n| 34 MNONGGAR  | 2 | 2                                          | 2 |\\\\n| 35 ATAYAL    | 2 | 1                                          | 2 |\\\\n| 36 SAGADA    | 3 | 2                                          | 2 |\\\\n| 37 JAVANESE  | 3 | 3                                          | 2 |\\\\n| 38 MACASSARE | 2 | 3                                          | 2 |\\\\n| 39 ARANDA    | 1 | 1                                          | 2 |\\\\n| 40 KAPAUKU   | 1 | 2                                          | 2 |\\\\n|              |   |                                            |   |\\\\n\\\\n| 41 WANTOAT<br>1<br>1<br>2<br>42 TRUKESE<br>2<br>1<br>2<br>43 TROBRIAND<br>2<br>3<br>2<br>44 SAMOANS<br>1<br>3<br>2<br>45 TIKOPIA<br>2<br>3<br>2<br>46 NABESNA<br>1<br>1<br>1<br>47 TAREUMIUT<br>2<br>2<br>1<br>48 TWANA<br>1<br>2<br>1<br>49 NOMLAKI<br>2<br>2<br>3<br>50 TENINO<br>2<br>2<br>1<br>51 OJIBWA<br>1<br>1<br>1<br>52 HURON<br>2<br>2<br>1<br>53 HANO<br>2<br>1<br>2<br>54 CUNA<br>1<br>2<br>2<br>55 WARRAU<br>1<br>1<br>2<br>56 MUNDURUCU<br>1<br>1<br>2<br>57 SIRIONO<br>1<br>1<br>2<br>58 TUCUNA<br>2<br>1<br>2<br>59 INCA<br>3<br>3<br>1<br>60 YAHGAN<br>1<br>1<br>1<br>61 MATACO<br>1<br>1<br>2<br>62 TRUMAI<br>1<br>1<br>2<br>63 DOROBO<br>1<br>1<br>2<br>64 NAMA<br>2<br>2<br>2<br>65 LOZI<br>1<br>3<br>2<br>66 BEMBA<br>2<br>3<br>2<br>67 KUBA<br>2<br>3<br>2<br>68 CHAGGA<br>2<br>3<br>2<br>69 KIKUYU<br>2<br>2<br>2<br>70 FANG<br>1<br>2<br>2<br>71 ASHANTI<br>3<br>3<br>2<br>72 DOGON<br>2<br>2<br>2<br>73 TALLENSI<br>2<br>2<br>2<br>74 TIV<br>2<br>1<br>2<br>75 AZANDE<br>2<br>3<br>2<br>76 MASAI<br>1<br>1<br>2 | Size(v31) Stratification(v66) Climate(v95) |\\\\n|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------|\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |                                            |\\\\n| 77 TIGRINYA<br>3<br>3<br>2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |                                            |\\\\n| 78 SONGHAI<br>3<br>3<br>2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |                                            |\\\\n| 79 SIWANS<br>3<br>2<br>3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |                                            |\\\\n| 80 EGYPTIANS<br>3<br>3<br>3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |                                            |\\\\n\\\\n| Culture       |   | Size(v31) Stratification(v66) Climate(v95) |   |\\\\n|---------------|---|--------------------------------------------|---|\\\\n| 81 RIFFIANS   | 3 | 2                                          | 3 |\\\\n| 82 ROMANS     | 3 | 3                                          | 3 |\\\\n| 83 IRISH      | 3 | 3                                          | 2 |\\\\n| 84 LAPPS      | 1 | 2                                          | 1 |\\\\n| 85 HUTSUL     | 3 | 2                                          | 3 |\\\\n| 86 PATHAN     | 2 | 3                                          | 2 |\\\\n| 87 KHALKA     | 1 | 3                                          | 2 |\\\\n| 88 CHUKCHEE   | 1 | 2                                          | 1 |\\\\n| 89 YURAK      | 1 | 2                                          | 1 |\\\\n| 90 MIAO       | 2 | 1                                          | 2 |\\\\n| 91 BURUSHO    | 2 | 3                                          | 1 |\\\\n| 92 LEPCHA     | 2 | 2                                          | 3 |\\\\n| 93 BENGALI    | 3 | 3                                          | 2 |\\\\n| 94 MARIAGOND  | 1 | 2                                          | 2 |\\\\n| 95 TODA       | 1 | 1                                          | 2 |\\\\n| 96 TANALA     | 2 | 3                                          | 2 |\\\\n| 97 VEDDA      | 1 | 1                                          | 2 |\\\\n| 98 BURMESE    | 3 | 3                                          | 2 |\\\\n| 99 SEMANG     | 1 | 1                                          | 2 |\\\\n| 100 ANNAMESE  | 3 | 3                                          | 2 |\\\\n| 101 IFUGAO    | 2 | 2                                          | 2 |\\\\n| 102 SUBANUN   | 1 | 1                                          | 2 |\\\\n| 103 BALINESE  | 2 | 3                                          | 2 |\\\\n| 104 ALORESE   | 2 | 2                                          | 2 |\\\\n| 105 MURNGIN   | 1 | 1                                          | 2 |\\\\n| 106 TIWI      | 2 | 1                                          | 2 |\\\\n| 107 WOGEO     | 1 | 1                                          | 2 |\\\\n| 108 MAJURO    | 2 | 3                                          | 2 |\\\\n| 109 IFALUK    | 1 | 1                                          | 2 |\\\\n| 110 KURTATCHI | 2 | 3                                          | 2 |\\\\n| 111 LESU      | 2 | 1                                          | 2 |\\\\n| 112 BUNLAP    | 1 | 2                                          | 2 |\\\\n| 113 LAU       | 1 | 2                                          | 2 |\\\\n| 114 PUKAPUKAN | 2 | 1                                          | 2 |\\\\n| 115 MAORI     | 2 | 3                                          | 3 |\\\\n| 116 MARQUESAN | 1 | 3                                          | 2 |\\\\n| 117 COPPERESK | 1 | 1                                          | 1 |\\\\n| 118 KASKA     | 1 | 1                                          | 1 |\\\\n| 119 YUROK     | 1 | 2                                          | 3 |\\\\n| 120 TUBATULAB | 1 | 1                                          | 2 |\\\\n|               |   |                                            |   |\\\\n\\\\n| Culture       |   | Size(v31) Stratification(v66) Climate(v95) |   |\\\\n|---------------|---|--------------------------------------------|---|\\\\n| 121 HAVASUPAI | 2 | 1                                          | 2 |\\\\n| 122 SANPOIL   | 1 | 1                                          | 3 |\\\\n| 123 OMAHA     | 1 | 1                                          | 3 |\\\\n| 124 CREEK     | 2 | 1                                          | 3 |\\\\n| 125 NAVAHO    | 2 | 1                                          | 2 |\\\\n| 126 ZUNI      | 3 | 1                                          | 2 |\\\\n| 127 AZTEC     | 3 | 3                                          | 3 |\\\\n| 128 BARAMACAR | 1 | 1                                          | 2 |\\\\n| 129 TAPIRAPE  | 2 | 1                                          | 2 |\\\\n| 130 JIVARO    | 1 | 1                                          | 1 |\\\\n| 131 YAGUA     | 1 | 1                                          | 2 |\\\\n| 132 AYMARA    | 2 | 2                                          | 1 |\\\\n| 133 CAYAPA    | 2 | 1                                          | 2 |\\\\n| 134 MAPUCHE   | 1 | 2                                          | 3 |\\\\n| 135 BACAIRI   | 1 | 1                                          | 2 |\\\\n| 136 NAMBICUAR | 1 | 1                                          | 2 |\\\\n| 137 AWEIKOMA  | 1 | 1                                          | 2 |\\\\n| 138 RAMCOCAME | 2 | 1                                          | 2 |\\\\n| 139 MBUTI     | 2 | 1                                          | 2 |\\\\n| 140 MBUNDU    | 2 | 3                                          | 2 |\\\\n| 141 VENDA     | 2 | 3                                          | 3 |\\\\n| 142 NYAKYUSA  | 2 | 1                                          | 2 |\\\\n| 143 MENDE     | 2 | 3                                          | 2 |\\\\n| 144 YORUBA    | 3 | 3                                          | 2 |\\\\n| 145 BIRIFOR   | 2 | 1                                          | 2 |\\\\n| 146 MAMBILA   | 2 | 1                                          | 3 |\\\\n| 147 MARGI     | 2 | 1                                          | 2 |\\\\n| 148 MAMVU     | 1 | 1                                          | 2 |\\\\n| 149 SHILLUK   | 2 | 3                                          | 2 |\\\\n| 150 LANGO     | 2 | 2                                          | 2 |\\\\n| 151 IRAQW     | 2 | 2                                          | 2 |\\\\n| 152 MZAB      | 3 | 3                                          | 3 |\\\\n| 153 KABYLE    | 2 | 1                                          | 2 |\\\\n| 154 TRISTAN   | 2 | 1                                          | 3 |\\\\n| 155 WALLOONS  | 3 | 3                                          | 2 |\\\\n| 156 CZECHS    | 3 | 3                                          | 2 |\\\\n| 157 HEBREWS   | 3 | 3                                          | 3 |\\\\n| 158 HAZARA    | 2 | 2                                          | 2 |\\\\n| 159 KORYAK    | 2 | 2                                          | 1 |\\\\n| 160 YUKAGHIR  | 1 | 1                                          | 1 |\\\\n|               |   |                                            |   |\\\\n\\\\n| Culture       |   | Size(v31) Stratification(v66) Climate(v95) |   |\\\\n|---------------|---|--------------------------------------------|---|\\\\n| 161 JAPANESE  | 3 | 3                                          | 2 |\\\\n| 162 MINCHINES | 3 | 3                                          | 2 |\\\\n| 163 TIBETANS  | 3 | 3                                          | 1 |\\\\n| 164 COORG     | 2 | 3                                          | 2 |\\\\n| 165 KERALA    | 3 | 3                                          | 2 |\\\\n| 166 NICOBARES | 1 | 1                                          | 2 |\\\\n| 167 SINHALESE | 3 | 3                                          | 2 |\\\\n| 168 KACHIN    | 2 | 3                                          | 3 |\\\\n| 169 PURUM     | 1 | 2                                          | 2 |\\\\n| 170 CAMBODIAN | 3 | 3                                          | 2 |\\\\n| 171 HANUNOO   | 2 | 1                                          | 2 |\\\\n| 172 DUSUN     | 2 | 2                                          | 2 |\\\\n| 173 DIERI     | 1 | 1                                          | 2 |\\\\n| 174 KARIERA   | 1 | 1                                          | 2 |\\\\n| 175 KERAKI    | 1 | 1                                          | 2 |\\\\n| 176 PONAPEANS | 1 | 3                                          | 2 |\\\\n| 177 YAPESE    | 1 | 3                                          | 2 |\\\\n| 178 ULAWANS   | 2 | 1                                          | 2 |\\\\n| 179 NASKAPI   | 1 | 1                                          | 1 |\\\\n| 180 EYAK      | 1 | 2                                          | 1 |\\\\n| 181 ATSUGEWI  | 1 | 2                                          | 3 |\\\\n| 182 MIAMI     | 2 | 1                                          | 2 |\\\\n| 183 CHEROKEE  | 2 | 1                                          | 2 |\\\\n| 184 DELAWARE  | 2 | 1                                          | 2 |\\\\n| 185 MARICOPA  | 1 | 1                                          | 2 |\\\\n| 186 TAOS      | 2 | 1                                          | 2 |\\\\n| 187 HUICHOL   | 2 | 2                                          | 2 |\\\\n| 188 CHOCO     | 1 | 1                                          | 2 |\\\\n| 189 CARINYA   | 2 | 1                                          | 2 |\\\\n| 190 GUAHIBO   | 1 | 1                                          | 2 |\\\\n| 191 CUBEO     | 1 | 1                                          | 2 |\\\\n| 192 TUNEBO    | 2 | 1                                          | 2 |\\\\n| 193 ONA       | 1 | 1                                          | 1 |\\\\n| 194 CHOROTI   | 1 | 1                                          | 2 |\\\\n| 195 CAMAYURA  | 2 | 1                                          | 2 |\\\\n| 196 BOTOCUDO  | 1 | 1                                          | 2 |\\\\n| 197 SOTHO     | 2 | 3                                          | 3 |\\\\n| 198 YAO       | 2 | 1                                          | 2 |\\\\n| 199 YOMBE     | 2 | 3                                          | 2 |\\\\n| 200 GANDA     | 3 | 3                                          | 2 |\\\\n|               |   |                                            |   |\\\\n\\\\n| 201 BETE<br>2<br>1<br>2<br>202 NUPE<br>2<br>3<br>2<br>203 CONIAGUI<br>1<br>1<br>2<br>204 BAYA<br>2<br>1<br>2<br>205 LUO<br>2<br>2<br>2<br>206 CHEREMIS<br>2<br>2<br>2<br>207 NURI<br>2<br>2<br>2<br>208 AINU<br>1<br>1<br>2<br>209 OKINAWANS<br>3<br>3<br>2<br>210 DARD<br>2<br>3<br>2<br>211 BHIL<br>1<br>3<br>2<br>212 AKHA<br>2<br>1<br>2<br>213 PAIWAN<br>2<br>3<br>2<br>214 WIKMUNKAN<br>1<br>1<br>2<br>215 ENGA<br>2<br>1<br>2<br>216 LAKALAI<br>2<br>2<br>2<br>217 ATTAWAPIS<br>1<br>1<br>1<br>218 DIEGUENO<br>2<br>1<br>2<br>219 WASHO<br>1<br>1<br>3<br>220 PAWNEE<br>2<br>3<br>3<br>221 COCHITI<br>2<br>1<br>2<br>222 YUCATECMA<br>3<br>3<br>2<br>223 WAICA<br>1<br>1<br>2<br>224 TEHUELCHE<br>1<br>1<br>2<br>225 NGONI<br>2<br>3<br>2<br>226 WUTE<br>2<br>3<br>2<br>227 BRAZILIAN<br>3<br>3<br>2<br>228 BULGARIAN<br>3<br>3<br>2<br>229 BASSERI<br>2<br>2<br>2<br>230 KET<br>1<br>1<br>1<br>231 MINCHIA<br>2<br>2<br>3<br>232 KHASI<br>1<br>3<br>2<br>233 SIAMESE<br>3<br>2<br>2<br>234 PURARI<br>2<br>2<br>2<br>235 ONOTOA<br>2<br>2<br>2<br>236 MANUS<br>2<br>2<br>2<br>237 YUKI<br>1<br>2<br>3<br>238 NATCHEZ<br>2<br>2<br>2<br>239 JEMEZ<br>2<br>1<br>2<br>240 BLACKCARI<br>3<br>1<br>2<br>241 MAM<br>3<br>2<br>3<br>242 MISKITO<br>2<br>1<br>2<br>243 GOAJIRO<br>1<br>2<br>2<br>244 YABARANA<br>1<br>1<br>2<br>245 CHIBCHA<br>3<br>3<br>1<br>246 ALACALUF<br>1<br>1<br>3<br>247 APINAYE<br>1<br>1<br>2 | Culture       |   | Size(v31) Stratification(v66) Climate(v95) |   |\\\\n|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|---|--------------------------------------------|---|\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |               |   |                                            |   |\\\\n|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | 248 TUPINAMBA | 2 | 2                                          | 2 |\\\",\\n  \\\"metadata\\\": {\\n    \\\"file_name\\\": \\\"1608.03637.pdf\\\",\\n    \\\"file_size\\\": 2558166,\\n    \\\"file_type\\\": \\\".pdf\\\",\\n    \\\"absolute_path\\\": \\\"/Users/joshchou/1608.03637.pdf\\\",\\n    \\\"page_count\\\": null,\\n    \\\"extracted_images\\\": [\\n      \\\"/Users/joshchou/extracted_media/1608.03637_page__page_2_Picture_1.jpeg_img_0.png\\\",\\n      \\\"/Users/joshchou/extracted_media/1608.03637_page__page_4_Figure_1.jpeg_img_1.png\\\",\\n      \\\"/Users/joshchou/extracted_media/1608.03637_page__page_5_Figure_1.jpeg_img_2.png\\\",\\n      \\\"/Users/joshchou/extracted_media/1608.03637_page__page_5_Figure_3.jpeg_img_3.png\\\",\\n      \\\"/Users/joshchou/extracted_media/1608.03637_page__page_6_Figure_6.jpeg_img_4.png\\\",\\n      \\\"/Users/joshchou/extracted_media/1608.03637_page__page_7_Figure_5.jpeg_img_5.png\\\",\\n      \\\"/Users/joshchou/extracted_media/1608.03637_page__page_8_Figure_3.jpeg_img_6.png\\\",\\n      \\\"/Users/joshchou/extracted_media/1608.03637_page__page_9_Figure_1.jpeg_img_7.png\\\"\\n    ],\\n    \\\"extracted_media\\\": [\\n      {\\n        \\\"type\\\": \\\"image\\\",\\n        \\\"path\\\": \\\"/Users/joshchou/extracted_media/1608.03637_page__page_2_Picture_1.jpeg_img_0.png\\\",\\n        \\\"page\\\": \\\"_page_2_Picture_1.jpeg\\\",\\n        \\\"filename\\\": \\\"1608.03637_page__page_2_Picture_1.jpeg_img_0.png\\\"\\n      },\\n      {\\n        \\\"type\\\": \\\"image\\\",\\n        \\\"path\\\": \\\"/Users/joshchou/extracted_media/1608.03637_page__page_4_Figure_1.jpeg_img_1.png\\\",\\n        \\\"page\\\": \\\"_page_4_Figure_1.jpeg\\\",\\n        \\\"filename\\\": \\\"1608.03637_page__page_4_Figure_1.jpeg_img_1.png\\\"\\n      },\\n      {\\n        \\\"type\\\": \\\"image\\\",\\n        \\\"path\\\": \\\"/Users/joshchou/extracted_media/1608.03637_page__page_5_Figure_1.jpeg_img_2.png\\\",\\n        \\\"page\\\": \\\"_page_5_Figure_1.jpeg\\\",\\n        \\\"filename\\\": \\\"1608.03637_page__page_5_Figure_1.jpeg_img_2.png\\\"\\n      },\\n      {\\n        \\\"type\\\": \\\"image\\\",\\n        \\\"path\\\": \\\"/Users/joshchou/extracted_media/1608.03637_page__page_5_Figure_3.jpeg_img_3.png\\\",\\n        \\\"page\\\": \\\"_page_5_Figure_3.jpeg\\\",\\n        \\\"filename\\\": \\\"1608.03637_page__page_5_Figure_3.jpeg_img_3.png\\\"\\n      },\\n      {\\n        \\\"type\\\": \\\"image\\\",\\n        \\\"path\\\": \\\"/Users/joshchou/extracted_media/1608.03637_page__page_6_Figure_6.jpeg_img_4.png\\\",\\n        \\\"page\\\": \\\"_page_6_Figure_6.jpeg\\\",\\n        \\\"filename\\\": \\\"1608.03637_page__page_6_Figure_6.jpeg_img_4.png\\\"\\n      },\\n      {\\n        \\\"type\\\": \\\"image\\\",\\n        \\\"path\\\": \\\"/Users/joshchou/extracted_media/1608.03637_page__page_7_Figure_5.jpeg_img_5.png\\\",\\n        \\\"page\\\": \\\"_page_7_Figure_5.jpeg\\\",\\n        \\\"filename\\\": \\\"1608.03637_page__page_7_Figure_5.jpeg_img_5.png\\\"\\n      },\\n      {\\n        \\\"type\\\": \\\"image\\\",\\n        \\\"path\\\": \\\"/Users/joshchou/extracted_media/1608.03637_page__page_8_Figure_3.jpeg_img_6.png\\\",\\n        \\\"page\\\": \\\"_page_8_Figure_3.jpeg\\\",\\n        \\\"filename\\\": \\\"1608.03637_page__page_8_Figure_3.jpeg_img_6.png\\\"\\n      },\\n      {\\n        \\\"type\\\": \\\"image\\\",\\n        \\\"path\\\": \\\"/Users/joshchou/extracted_media/1608.03637_page__page_9_Figure_1.jpeg_img_7.png\\\",\\n        \\\"page\\\": \\\"_page_9_Figure_1.jpeg\\\",\\n        \\\"filename\\\": \\\"1608.03637_page__page_9_Figure_1.jpeg_img_7.png\\\"\\n      }\\n    ],\\n    \\\"output_format\\\": \\\"markdown\\\",\\n    \\\"extracted_text_file_path\\\": null\\n  }\\n}\"]",
          "info": {},
          "timestamp": "2025-09-25T16:29:34.959500",
          "success": true,
          "result": [
            {
              "tool_name": null,
              "tool_call_id": null,
              "agent_name": "gaia_tracing_agent---uuid4453c8uuid",
              "action_name": null,
              "params": {},
              "policy_info": "From the Physics and Society article submitted to arXiv.org on August 11, 2016 (\"Phase transition from egalitarian to hierarchical societies driven by competition between cognitive and social constraints\"), the text repeatedly refers to \"egalitarian\" and \"hierarchical\" as types of societies. Specifically, the article discusses transitions between \"egalitarian\" and \"hierarchical\" societies, and the term \"egalitarian\" is used to describe a type of society.\n\nAmong the six axis-end label words from the June 2022 AI regulation paper:\n- Standardization\n- Localization\n- Utilitarianism\n- Egalitarianism\n- Consequential\n- Deontological\n\nThe word \"egalitarian\" (from \"egalitarianism\") is used in the 2016 Physics and Society article to describe a type of society.\n\n---\n\n**Final Answer:**\n\n<answer>egalitarian</answer>"
            }
          ],
          "trace_data": {
            "execution_tree": {
              "code": "root",
              "contains_llm_call": true,
              "is_completed": false,
              "is_function_call": false,
              "function_name": null,
              "line_number_start": null,
              "line_number_end": null,
              "children": [
                {
                  "code": "result = Runners.sync_run_task(task=task)",
                  "contains_llm_call": true,
                  "is_completed": false,
                  "is_function_call": true,
                  "function_name": "sync_run_task",
                  "line_number_start": 1,
                  "line_number_end": 1,
                  "children": [
                    {
                      "code": "sync_run_task_execution_block",
                      "contains_llm_call": true,
                      "is_completed": false,
                      "is_function_call": false,
                      "function_name": "sync_run_task",
                      "line_number_start": 59,
                      "line_number_end": 60,
                      "children": []
                    }
                  ]
                }
              ]
            },
            "llm_calls": [
              {
                "function_name": "sync_run_task",
                "code": "result = Runners.sync_run_task(task=task)",
                "line_number": 1
              }
            ],
            "execution_flow": []
          }
        }
      ],
      "timestamp": "2025-09-25T16:30:00.666289"
    }
  ]
}